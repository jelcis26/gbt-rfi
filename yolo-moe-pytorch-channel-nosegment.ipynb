{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81b1b1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bitshuffle in /mnt_home/jliang/.local/lib/python3.7/site-packages (0.5.1)\n",
      "Requirement already satisfied: h5py>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from bitshuffle) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from bitshuffle) (1.20.3)\n",
      "Requirement already satisfied: setuptools>=0.7 in /opt/conda/lib/python3.7/site-packages (from bitshuffle) (62.3.2)\n",
      "Requirement already satisfied: Cython>=0.19 in /opt/conda/lib/python3.7/site-packages (from bitshuffle) (0.29.30)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py>=2.4.0->bitshuffle) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (7.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bitshuffle\n",
    "%pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fe6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import blimpy as bl\n",
    "#from ultralytics import YOLO\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import psutil\n",
    "import scipy.ndimage\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import cv2\n",
    "from scipy.ndimage import label as connected_components\n",
    "from skimage.filters import sobel\n",
    "from skimage.segmentation import slic\n",
    "from skimage.util import img_as_float\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "from skimage.util import img_as_float\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from skimage.segmentation import slic\n",
    "import scipy.ndimage as ndi\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dba8ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Session</th>\n",
       "      <th>Band</th>\n",
       "      <th>Cadence ID</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>.h5 path</th>\n",
       "      <th>.dat path</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36553</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36554</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36555</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36556</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36557</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36558 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Target          Session Band  Cadence ID  Frequency  \\\n",
       "0       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "1       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "2       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "3       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "4       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "...        ...              ...  ...         ...        ...   \n",
       "36553  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "36554  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "36555  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "36556  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "36557  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "\n",
       "                                                .h5 path  \\\n",
       "0      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "1      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "2      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "3      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "4      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "...                                                  ...   \n",
       "36553  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "36554  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "36555  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "36556  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "36557  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "\n",
       "                                               .dat path                 Time  \n",
       "0      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "1      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "2      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "3      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "4      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "...                                                  ...                  ...  \n",
       "36553  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "36554  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "36555  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "36556  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "36557  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "\n",
       "[36558 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/cgchoza/galaxies/complete_cadences_catalog.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "730aa85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Session</th>\n",
       "      <th>Band</th>\n",
       "      <th>Cadence ID</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>.h5 path</th>\n",
       "      <th>.dat path</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30309</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30310</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30311</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30312</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30313</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30314 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Target          Session Band  Cadence ID  Frequency  \\\n",
       "0       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "1       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "2       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "3       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "4       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "...        ...              ...  ...         ...        ...   \n",
       "30309  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "30310  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "30311  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "30312  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "30313  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "\n",
       "                                                .h5 path  \\\n",
       "0      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "1      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "2      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "3      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "4      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "...                                                  ...   \n",
       "30309  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "30310  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "30311  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "30312  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "30313  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "\n",
       "                                               .dat path                 Time  \n",
       "0      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "1      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "2      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "3      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "4      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "...                                                  ...                  ...  \n",
       "30309  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "30310  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "30311  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "30312  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "30313  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "\n",
       "[30314 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['.h5 path'] = df['.h5 path'].str.replace('0000.h5', '0002.h5', regex=False)\n",
    "df = df.drop_duplicates(subset='.h5 path', keep='first').reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38b7592b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Session</th>\n",
       "      <th>Band</th>\n",
       "      <th>Cadence ID</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>.h5 path</th>\n",
       "      <th>.dat path</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AND_XIV</td>\n",
       "      <td>AGBT18B_999_07</td>\n",
       "      <td>S</td>\n",
       "      <td>30225</td>\n",
       "      <td>3151</td>\n",
       "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
       "      <td>2018-08-18 08:41:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AND_XIV</td>\n",
       "      <td>AGBT18B_999_07</td>\n",
       "      <td>S</td>\n",
       "      <td>30225</td>\n",
       "      <td>3151</td>\n",
       "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
       "      <td>2018-08-18 08:41:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AND_XIV</td>\n",
       "      <td>AGBT18B_999_07</td>\n",
       "      <td>S</td>\n",
       "      <td>30225</td>\n",
       "      <td>3151</td>\n",
       "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
       "      <td>2018-08-18 08:41:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AND_XIV</td>\n",
       "      <td>AGBT18B_999_07</td>\n",
       "      <td>S</td>\n",
       "      <td>30225</td>\n",
       "      <td>3151</td>\n",
       "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
       "      <td>2018-08-18 08:41:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AND_XIV</td>\n",
       "      <td>AGBT18B_999_07</td>\n",
       "      <td>S</td>\n",
       "      <td>30225</td>\n",
       "      <td>3151</td>\n",
       "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
       "      <td>2018-08-18 08:41:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29341</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29342</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29343</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29344</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29345</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29346 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Target         Session Band  Cadence ID  Frequency  \\\n",
       "0      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
       "1      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
       "2      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
       "3      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
       "4      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
       "...        ...             ...  ...         ...        ...   \n",
       "29341  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
       "29342  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
       "29343  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
       "29344  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
       "29345  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
       "\n",
       "                                                .h5 path  \\\n",
       "0      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
       "1      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
       "2      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
       "3      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
       "4      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
       "...                                                  ...   \n",
       "29341  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "29342  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "29343  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "29344  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "29345  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "\n",
       "                                               .dat path                 Time  \n",
       "0      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
       "1      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
       "2      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
       "3      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
       "4      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
       "...                                                  ...                  ...  \n",
       "29341  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "29342  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "29343  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "29344  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "29345  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "\n",
       "[29346 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~df['.h5 path'].str.contains('spliced')].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1451bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index = 17546)\n",
    "import pandas as pd\n",
    "import blimpy as bl\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def scan_file_for_band(\n",
    "    h5_path: str,\n",
    "    band: str,\n",
    "    fmin: float,\n",
    "    fmax: float,\n",
    "    default_nfpc: int = 1024\n",
    "):\n",
    "    \"\"\"\n",
    "    Open one .h5, read header, return list of dicts for all channels\n",
    "    whose freq range lies in [fmin, fmax].\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    fb = bl.Waterfall(h5_path, load_data=False)\n",
    "    hdr = fb.header\n",
    "\n",
    "    # skip if not the right band\n",
    "    # you could also pass row['Band'] in here if you like\n",
    "    # if row['Band'] != band: return []\n",
    "\n",
    "    fch1   = hdr['fch1']\n",
    "    foff   = hdr['foff']\n",
    "    nchans = hdr.get('nchans')\n",
    "    nfpc   = hdr.get('nfpc', default_nfpc)\n",
    "    n_coarse = nchans // nfpc\n",
    "\n",
    "    for ch in range(n_coarse):\n",
    "        f0 = ch * nfpc\n",
    "        f1 = (ch+1) * nfpc\n",
    "        f_start = fch1 + f0 * foff\n",
    "        f_stop  = fch1 + (f1-1) * foff\n",
    "        if (f_start <= fmax) and (f_stop >= fmin):\n",
    "            records.append({\n",
    "                '.h5 path': h5_path,\n",
    "                'channel':    ch,\n",
    "                'Band':       band,\n",
    "                'f_start':    f_start,\n",
    "                'f_stop':     f_stop\n",
    "            })\n",
    "\n",
    "    return records\n",
    "\n",
    "def parallel_filter_df(\n",
    "    df: pd.DataFrame,\n",
    "    band: str = \"L\",\n",
    "    fmin: float = 1500,\n",
    "    fmax: float = 1650,\n",
    "    max_workers: int = 8\n",
    ") -> pd.DataFrame:\n",
    "    # restrict to Band==L first to cut the task list down\n",
    "    df_band = df[df['Band'] == band]\n",
    "    paths   = df_band[\".h5 path\"].unique().tolist()\n",
    "\n",
    "    all_records = []\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as exe:\n",
    "        futures = {\n",
    "            exe.submit(scan_file_for_band, p, band, fmin, fmax): p\n",
    "            for p in paths\n",
    "        }\n",
    "        for fut in tqdm(as_completed(futures), total=len(futures), ascii=True,\n",
    "                        desc=f\"Scanning {band}-band files\"):\n",
    "            try:\n",
    "                recs = fut.result()\n",
    "                all_records.extend(recs)\n",
    "            except Exception as e:\n",
    "                h5 = futures[fut]\n",
    "                print(f\"Error on {h5}: {e!r}\")\n",
    "\n",
    "    return pd.DataFrame.from_records(all_records)\n",
    "\n",
    "# Usage:\n",
    "df = parallel_filter_df(df, band=\"L\", fmin=1500, fmax=1650, max_workers=2)\n",
    "print(f\"Kept {len(df)} channel entries in L-band 1500-1650 MHz\")\n",
    "# # 1) sample, keeping the original index labels\n",
    "# df_old = df.sample(n=1000, random_state=42)\n",
    "# # 2) drop those exact rows from df\n",
    "# df = df.drop(index=df_old.index).reset_index(drop=True)\n",
    "# # 4) finally, sample 10,000 more from the remainder\n",
    "old_df = df.sample(n=10000, random_state=42)\n",
    "df = df.drop(index=old_df.index).reset_index(drop=True)\n",
    "df = df.sample(n=1000, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84164fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- File Info ---\n",
      "DIMENSION_LABELS : [b'time' b'feed_id' b'frequency']\n",
      "        az_start :                              0.0\n",
      "       data_type :                                1\n",
      "            fch1 :               10501.46484375 MHz\n",
      "            foff :         -0.00286102294921875 MHz\n",
      "           ibeam :                               -1\n",
      "      machine_id :                               20\n",
      "          nbeams :                                1\n",
      "           nbits :                               32\n",
      "          nchans :                            65536\n",
      "            nifs :                                1\n",
      "     rawdatafile : guppi_59411_54386_HIP30264_0094.0000.raw\n",
      "     source_name :                         HIP30264\n",
      "         src_dej :                     -8:26:53.228\n",
      "         src_raj :                      6:21:58.451\n",
      "    telescope_id :                                6\n",
      "           tsamp :                1.073741823999999\n",
      "   tstart (ISOT) :          2021-07-16T15:06:26.000\n",
      "    tstart (MJD) :                59411.62946759259\n",
      "        za_start :                              0.0\n",
      "\n",
      "Num ints in file :                              279\n",
      "      File shape :                  (279, 1, 65536)\n",
      "--- Selection Info ---\n",
      "Data selection shape :                  (279, 1, 65536)\n",
      "Minimum freq (MHz) :                10313.96770477295\n",
      "Maximum freq (MHz) :                   10501.46484375\n"
     ]
    }
   ],
   "source": [
    "# fb = bl.Waterfall(df['.h5 path'].iloc[-1], load_data=True)\n",
    "# fb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b073aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import time\n",
    "\n",
    "def ensure_cpu_mem(bytes_needed, safety=0.8):\n",
    "    avail = psutil.virtual_memory().available\n",
    "    if bytes_needed > avail * safety:\n",
    "        time.sleep(120)\n",
    "\n",
    "def ensure_gpu_mem(bytes_needed, safety=0.8):\n",
    "    free, total = cp.cuda.runtime.memGetInfo()\n",
    "    if bytes_needed > free * safety:\n",
    "        time.sleep(120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395191b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_iou(boxA, boxB):\n",
    "    \"\"\"\n",
    "    Compute IoU between two YOLO-format boxes (cx, cy, w, h), normalized [0..1].\n",
    "    \"\"\"\n",
    "    cxA, cyA, wA, hA = boxA\n",
    "    cxB, cyB, wB, hB = boxB\n",
    "\n",
    "    # convert to corner coords\n",
    "    x0A, y0A = cxA - wA/2, cyA - hA/2\n",
    "    x1A, y1A = cxA + wA/2, cyA + hA/2\n",
    "    x0B, y0B = cxB - wB/2, cyB - hB/2\n",
    "    x1B, y1B = cxB + wB/2, cyB + hB/2\n",
    "\n",
    "    # intersection\n",
    "    xi0, yi0 = max(x0A, x0B), max(y0A, y0B)\n",
    "    xi1, yi1 = min(x1A, x1B), min(y1A, y1B)\n",
    "    inter_w  = max(0.0, xi1 - xi0)\n",
    "    inter_h  = max(0.0, yi1 - yi0)\n",
    "    inter    = inter_w * inter_h\n",
    "\n",
    "    # union\n",
    "    areaA = wA * hA\n",
    "    areaB = wB * hB\n",
    "    union = areaA + areaB - inter\n",
    "    if union <= 0:\n",
    "        return 0.0\n",
    "    return inter / union\n",
    "\n",
    "\n",
    "def merge_overlaps(boxes, iou_thresh=0.3):\n",
    "    \"\"\"\n",
    "    Group boxes that overlap above `iou_thresh`, then merge each group\n",
    "    into the tightest bounding rectangle.\n",
    "    Input:\n",
    "      boxes: List of (cx, cy, w, h)\n",
    "    Returns:\n",
    "      merged: List of (cx, cy, w, h)\n",
    "    \"\"\"\n",
    "    clusters = []\n",
    "    used = set()\n",
    "\n",
    "    for i, b in enumerate(boxes):\n",
    "        if i in used:\n",
    "            continue\n",
    "        # start a new cluster with box i\n",
    "        cluster = [b]\n",
    "        used.add(i)\n",
    "\n",
    "        # greedily absorb any box that overlaps any member of the cluster\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            for j, bj in enumerate(boxes):\n",
    "                if j in used:\n",
    "                    continue\n",
    "                if any(yolo_iou(bj, ck) > iou_thresh for ck in cluster):\n",
    "                    cluster.append(bj)\n",
    "                    used.add(j)\n",
    "                    changed = True\n",
    "\n",
    "        clusters.append(cluster)\n",
    "\n",
    "    # now merge each cluster into one box\n",
    "    merged = []\n",
    "    for cl in clusters:\n",
    "        # convert each to (x1,y1,x2,y2)\n",
    "        rects = []\n",
    "        for cx, cy, w, h in cl:\n",
    "            x1, y1 = cx - w/2, cy - h/2\n",
    "            x2, y2 = cx + w/2, cy + h/2\n",
    "            rects.append((x1, y1, x2, y2))\n",
    "\n",
    "        x1 = min(r[0] for r in rects)\n",
    "        y1 = min(r[1] for r in rects)\n",
    "        x2 = max(r[2] for r in rects)\n",
    "        y2 = max(r[3] for r in rects)\n",
    "\n",
    "        # back to (cx,cy,w,h)\n",
    "        merged.append(((x1 + x2)/2, (y1 + y2)/2, x2 - x1, y2 - y1))\n",
    "\n",
    "    return merged\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d1011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def generate_yolo_boxes(binary_mask,\n",
    "                        min_area=100,\n",
    "                        max_frac_area=1.0,\n",
    "                        min_aspect=0.1,\n",
    "                        max_aspect=10.0):\n",
    "    \"\"\"\n",
    "    Extract YOLO-style boxes from a binary mask via contours.\n",
    "\n",
    "    Args:\n",
    "      binary_mask: 2D uint8 array of 0/1\n",
    "      min_area: drop components smaller than this many pixels\n",
    "      max_frac_area: drop components larger than this fraction of image area\n",
    "      min_aspect, max_aspect: drop if w/h not in [min_aspect,max_aspect]\n",
    "    Returns:\n",
    "      List of (cx, cy, w, h) in normalized coords [0..1]\n",
    "    \"\"\"\n",
    "    H, W = binary_mask.shape\n",
    "    total = H * W\n",
    "\n",
    "    # must be uint8 0/255 for findContours\n",
    "    mask8 = (binary_mask.astype(np.uint8) * 255)\n",
    "\n",
    "    # find external contours\n",
    "    contours, _ = cv2.findContours(mask8,\n",
    "                                   cv2.RETR_EXTERNAL,\n",
    "                                   cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    boxes = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        area = w * h\n",
    "        # area filters\n",
    "        if area < min_area or area > max_frac_area * total:\n",
    "            continue\n",
    "\n",
    "        ar = w / float(h) if h>0 else 0\n",
    "        if ar < min_aspect or ar > max_aspect:\n",
    "            continue\n",
    "\n",
    "        # center & size in normalized coords\n",
    "        cx = (x + w/2) / W\n",
    "        cy = (y + h/2) / H\n",
    "        boxes.append((cx, cy, w / W, h / H))\n",
    "\n",
    "    return boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeeb5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tasks(df):\n",
    "    \"\"\"\n",
    "    Build a flat list of (h5_path, channel_idx) from your DataFrame,\n",
    "    skipping any channels that fall into known notch filter frequency ranges.\n",
    "    \"\"\"\n",
    "    GBT_NOTCH_FILTERS = {\n",
    "        \"L\": [(1200, 1340)],\n",
    "        \"S\": [(2300, 2360)],\n",
    "    }\n",
    "\n",
    "    tasks = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        h5 = row[\".h5 path\"]\n",
    "        band = row[\"Band\"]  # e.g., 'L', 'S', etc.\n",
    "        fb = bl.Waterfall(h5, load_data=False)\n",
    "        nfreq = fb.header.get(\"nchans\")\n",
    "        nfpc = fb.header.get(\"nfpc\", 1024)\n",
    "        fch1 = fb.header[\"fch1\"]\n",
    "        foff = fb.header[\"foff\"]\n",
    "        n_coarse = nfreq // nfpc\n",
    "\n",
    "        for ch in range(n_coarse):\n",
    "            f0 = fch1 + ch * nfpc * foff\n",
    "            f1 = fch1 + (ch + 1) * nfpc * foff\n",
    "            f_min, f_max = sorted([f0, f1])\n",
    "\n",
    "            # Check against notch filter exclusion ranges\n",
    "            skip = False\n",
    "            if band in GBT_NOTCH_FILTERS:\n",
    "                for lo, hi in GBT_NOTCH_FILTERS[band]:\n",
    "                    if lo <= f_min <= hi or lo <= f_max <= hi:\n",
    "                        skip = True\n",
    "                        break\n",
    "            if not skip:\n",
    "                tasks.append((h5, ch))\n",
    "\n",
    "    return tasks\n",
    "\n",
    "\n",
    "def split_tasks(tasks, train_frac=0.8, seed=42):\n",
    "    \"\"\"\n",
    "    Shuffle & split the flat task list into train vs. val sets.\n",
    "    Returns two sets of (h5_path, channel_idx).\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    shuffled = tasks.copy()\n",
    "    random.shuffle(shuffled)\n",
    "    cut = int(train_frac * len(shuffled))\n",
    "    train = set(shuffled[:cut])\n",
    "    val   = set(shuffled[cut:])\n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8552a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxes_intersect(boxA, boxB, min_overlap_frac=0.0):\n",
    "    \"\"\"\n",
    "    Returns True if boxA and boxB (cx,cy,w,h normalized) overlap by at least\n",
    "    min_overlap_frac of the smaller box’s area.  If min_overlap_frac=0, any positive\n",
    "    intersection counts.\n",
    "    \"\"\"\n",
    "    cxA, cyA, wA, hA = boxA\n",
    "    cxB, cyB, wB, hB = boxB\n",
    "\n",
    "    # convert to (x1,y1,x2,y2)\n",
    "    x1A, y1A = cxA - wA/2, cyA - hA/2\n",
    "    x2A, y2A = cxA + wA/2, cyA + hA/2\n",
    "    x1B, y1B = cxB - wB/2, cyB - hB/2\n",
    "    x2B, y2B = cxB + wB/2, cyB + hB/2\n",
    "\n",
    "    # find intersection rectangle\n",
    "    xi1, yi1 = max(x1A, x1B), max(y1A, y1B)\n",
    "    xi2, yi2 = min(x2A, x2B), min(y2A, y2B)\n",
    "\n",
    "    inter_w = max(0.0, xi2 - xi1)\n",
    "    inter_h = max(0.0, yi2 - yi1)\n",
    "    inter_area = inter_w * inter_h\n",
    "    if inter_area <= 0:\n",
    "        return False\n",
    "\n",
    "    if min_overlap_frac <= 0:\n",
    "        return True\n",
    "\n",
    "    # else require intersection >= fraction of smaller box\n",
    "    areaA = wA * hA\n",
    "    areaB = wB * hB\n",
    "    smaller = min(areaA, areaB)\n",
    "    return (inter_area / smaller) >= min_overlap_frac\n",
    "\n",
    "\n",
    "def merge_overlaps_by_coords(boxes, overlap_frac=0.0):\n",
    "    \"\"\"\n",
    "    Group boxes that intersect (by at least overlap_frac of the smaller),\n",
    "    then merge each group into one tight rectangle.\n",
    "    \"\"\"\n",
    "    clusters = []\n",
    "    used = set()\n",
    "\n",
    "    for i, b in enumerate(boxes):\n",
    "        if i in used:\n",
    "            continue\n",
    "        cluster = [b]\n",
    "        used.add(i)\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            for j, bj in enumerate(boxes):\n",
    "                if j in used:\n",
    "                    continue\n",
    "                if any(boxes_intersect(bj, ck, overlap_frac) for ck in cluster):\n",
    "                    cluster.append(bj)\n",
    "                    used.add(j)\n",
    "                    changed = True\n",
    "        clusters.append(cluster)\n",
    "\n",
    "    merged = []\n",
    "    for cl in clusters:\n",
    "        # to corner coords\n",
    "        rects = []\n",
    "        for cx, cy, w, h in cl:\n",
    "            x1, y1 = cx - w/2, cy - h/2\n",
    "            x2, y2 = cx + w/2, cy + h/2\n",
    "            rects.append((x1, y1, x2, y2))\n",
    "        x1 = min(r[0] for r in rects)\n",
    "        y1 = min(r[1] for r in rects)\n",
    "        x2 = max(r[2] for r in rects)\n",
    "        y2 = max(r[3] for r in rects)\n",
    "        merged.append(((x1+x2)/2, (y1+y2)/2, x2-x1, y2-y1))\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d029de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw\n",
    "import blimpy as bl\n",
    "from skimage.segmentation import slic\n",
    "from skimage.transform import probabilistic_hough_line\n",
    "import gc\n",
    "import traceback\n",
    "from scipy.stats import kurtosis\n",
    "import imageio\n",
    "#from yolo_moe_pytorch_channel import generate_yolo_boxes\n",
    "\n",
    "# ─── 1) Define your rule-based gate ──────────────────────────────────────\n",
    "class RuleGate(nn.Module):\n",
    "    def __init__(self, in_feats=3, hidden=16):\n",
    "        super().__init__()\n",
    "        # in_feats = number of heuristics per map (e.g. 3: density, alignment, linearity)\n",
    "        # We’ll concatenate all four maps’ heuristics → 4*in_feats inputs\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(4*in_feats, hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, 4)      # one logit per detector\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "                h_sf:    torch.Tensor,  # (B,in_feats)\n",
    "                h_ued:   torch.Tensor,  # (B,in_feats)\n",
    "                h_canny: torch.Tensor,  # (B,in_feats)\n",
    "                h_hough: torch.Tensor   # (B,in_feats)\n",
    "               ):\n",
    "        # 1) concatenate all heuristics\n",
    "        x = torch.cat([h_sf, h_ued, h_canny, h_hough], dim=1)      # (B,4*in_feats)\n",
    "        logits = self.net(x)                                        # (B,4)\n",
    "        weights = torch.softmax(logits, dim=1)                      # (B,4) sums to 1\n",
    "        return weights[:,0], weights[:,1], weights[:,2], weights[:,3]\n",
    "\n",
    "# ─── 2) Heuristic helper (no change) ────────────────────────────────────\n",
    "def compute_heuristics(edge_map, gray):\n",
    "    mask = edge_map > 0.2\n",
    "    density = float(mask.mean())\n",
    "    # alignment\n",
    "    if density > 0:\n",
    "        gx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, 3)\n",
    "        gy = cv2.Sobel(gray, cv2.CV_32F, 0, 1, 3)\n",
    "        alignment = float(np.hypot(gx, gy)[mask].mean())\n",
    "    else:\n",
    "        alignment = 0.0\n",
    "    # entropy\n",
    "    # entropy = float(-np.sum(edge_map * np.log2(edge_map + 1e-8)))\n",
    "    # linearity (aspect‐ratio proxy)\n",
    "    bw = mask.astype(np.uint8)\n",
    "    n, labels = cv2.connectedComponents(bw)\n",
    "    ratios = []\n",
    "    for L in range(1, n):\n",
    "        ys, xs = np.where(labels == L)\n",
    "        if ys.size:\n",
    "            h, w = np.ptp(ys)+1, np.ptp(xs)+1\n",
    "            ratios.append(float(w)/h if h else 0.0)\n",
    "    linearity = float(np.mean(ratios)) if ratios else 0.0\n",
    "\n",
    "    if density < 0.01:\n",
    "        return [0.0, 0.0, 0.0]\n",
    "    return [density, alignment, linearity]\n",
    "\n",
    "\n",
    "# ─── 3) The new process_file ─────────────────────────────────────────────\n",
    "def process_file(job):\n",
    "    (h5_path, channels, gidxs,\n",
    "     base_dir, class_id, train_set, val_set,\n",
    "     pad_width) = job\n",
    "\n",
    "    # Load .h5 once\n",
    "    fb   = bl.Waterfall(h5_path, load_data=True)\n",
    "    data = 10*np.log10(fb.data.squeeze())  # (ntime, nfreq)\n",
    "\n",
    "\n",
    "    # Prepare SF detector and gate\n",
    "    EDGE_MODEL = \"/home/jliang/gbt-rfi/model.yml.gz\"\n",
    "    sf_det     = cv2.ximgproc.createStructuredEdgeDetection(EDGE_MODEL)\n",
    "    # gate       = RuleGate()  # use default w_align/w_ent/bias\n",
    "\n",
    "    for ch_idx, gidx in zip(channels, gidxs):\n",
    "        subset = \"train\" if (h5_path,ch_idx) in train_set else \"val\"\n",
    "        img_dir = Path(base_dir)/subset/\"images\"\n",
    "        lbl_dir = Path(base_dir)/subset/\"labels\"\n",
    "        vis_dir = Path(base_dir)/\"visualization\"/subset\n",
    "        for d in (img_dir,lbl_dir,vis_dir): d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Extract & clean the block\n",
    "        cw = fb.header.get(\"nfpc\",1024)\n",
    "        f0, f1 = ch_idx*cw, (ch_idx+1)*cw\n",
    "        block = data[:,f0:f1]\n",
    "        low, high = int(0.15*cw), int(0.85*cw)\n",
    "        block = block[:,low:high]\n",
    "        h_img, w_img = block.shape\n",
    "\n",
    "        # Remove vertical line artifact\n",
    "        rows, cols = block.shape\n",
    "        # 1) Define a little window around the true center column\n",
    "        mid = cols // 2\n",
    "        half_win = 2                 # look 2 columns on either side\n",
    "        start = max(mid - half_win, 0)\n",
    "        end   = min(mid + half_win + 1, cols)\n",
    "\n",
    "        # 2) Compute the mean of each of those columns\n",
    "        center_window = block[:, start:end]            # shape = (rows, window_width)\n",
    "        vert_means    = center_window.mean(axis=0)     # length = window_width\n",
    "\n",
    "        # 3) Locate the spike RELATIVE to the window, then map back\n",
    "        rel_idx    = np.argmax(vert_means)             # in [0 .. window_width-1]\n",
    "        center_col = start + rel_idx                   # actual column index in block\n",
    "\n",
    "        # 4) Replace that column by the average of its two neighbors (if they exist)\n",
    "        left_col  = center_col - 1\n",
    "        right_col = center_col + 1\n",
    "\n",
    "        if 0 <= left_col < cols and 0 <= right_col < cols:\n",
    "            block[:, center_col] = 0.5*(block[:, left_col] + block[:, right_col])\n",
    "        elif 0 <= left_col < cols:\n",
    "            block[:, center_col] = block[:, left_col]\n",
    "        elif 0 <= right_col < cols:\n",
    "            block[:, center_col] = block[:, right_col]\n",
    "\n",
    "        # Build img for SF\n",
    "        norm = (block - block.min())/(np.ptp(block)+1e-6)\n",
    "        img3 = np.stack([norm]*3, axis=-1).astype(np.float32)\n",
    "        sf_map = sf_det.detectEdges(img3).squeeze()\n",
    "        gray8 = (255*norm).astype(np.uint8)\n",
    "        kurt_val = kurtosis(gray8.flatten(), fisher=False)\n",
    "        if kurt_val < 7.0:\n",
    "            continue\n",
    "        # Build filename\n",
    "        f_start = fb.header['fch1'] + f0 * fb.header['foff']\n",
    "        f_stop  = fb.header['fch1'] + (f1 - 1) * fb.header['foff']\n",
    "        fn = f\"img_{kurt_val:0{pad_width}.2f}_f_{f_start:.4f}_{f_stop:.4f}.png\"\n",
    "        if (img_dir/fn).exists():\n",
    "            continue\n",
    "\n",
    "        # Sobel map\n",
    "        gx = cv2.Sobel(gray8, cv2.CV_32F, 1,0,3)\n",
    "        gy = cv2.Sobel(gray8, cv2.CV_32F, 0,1,3)\n",
    "        ued_map = np.hypot(gx, gy)\n",
    "        ued_map = cv2.normalize(ued_map, None, 0,1, cv2.NORM_MINMAX)\n",
    "\n",
    "        # Canny\n",
    "        low_thresh  = 50\n",
    "        high_thresh = 150\n",
    "        gray_denoised = cv2.medianBlur(gray8, 5)   # or cv2.GaussianBlur(gray8, (5,5), 0)\n",
    "        edges = cv2.Canny(gray_denoised, low_thresh, high_thresh)\n",
    "        contours, _ = cv2.findContours(edges,\n",
    "                                    cv2.RETR_EXTERNAL,\n",
    "                                    cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # after findContours…\n",
    "        contour_mask = np.zeros_like(edges, dtype=np.uint8)\n",
    "        cv2.drawContours(contour_mask, contours, -1, 1, thickness=-1)\n",
    "\n",
    "        # and use contour_mask directly as your “canny_map”\n",
    "        canny_map = contour_mask.astype(np.uint8)\n",
    "\n",
    "\n",
    "        # Hough\n",
    "        hough_map = np.zeros_like(canny_map, dtype=np.float32)\n",
    "        lines = probabilistic_hough_line(\n",
    "            (edges > 0).astype(np.uint8),\n",
    "            threshold=5,\n",
    "            line_length=10,\n",
    "            line_gap=2\n",
    "        )\n",
    "        for (y0, x0), (y1, x1) in lines:\n",
    "            cv2.line(hough_map, (x0, y0), (x1, y1), 1.0, 1)\n",
    "        hough_map = cv2.GaussianBlur(hough_map, (3,3), 0)\n",
    "\n",
    "        # 1) Compute global heuristics on full maps\n",
    "        # h_sf    = compute_heuristics(sf_map,    gray8)\n",
    "        # h_ued   = compute_heuristics(ued_map,   gray8)\n",
    "        # h_canny = compute_heuristics(canny_map, gray8)\n",
    "        # h_hough = compute_heuristics(hough_map, gray8)\n",
    "\n",
    "        # # 2) Run through your gate (batch size = 1)\n",
    "        # h_sf_t    = torch.tensor([h_sf],    dtype=torch.float32)\n",
    "        # h_ued_t   = torch.tensor([h_ued],   dtype=torch.float32)\n",
    "        # h_canny_t = torch.tensor([h_canny], dtype=torch.float32)\n",
    "        # h_hough_t = torch.tensor([h_hough], dtype=torch.float32)\n",
    "        # w_sf, w_ued, w_canny, w_hough = gate(h_sf_t, h_ued_t, h_canny_t, h_hough_t)\n",
    "        # w_sf, w_ued, w_canny, w_hough = [w.item() for w in (w_sf, w_ued, w_canny, w_hough)]\n",
    "        w_sf, w_ued, w_canny, w_hough = [0.25, 0.25, 0.25, 0.25]\n",
    "\n",
    "        # 3) Fuse whole-image maps with those weights\n",
    "        fused_global = (\n",
    "            w_sf    * sf_map +\n",
    "            w_ued   * ued_map +\n",
    "            w_canny * canny_map +\n",
    "            w_hough * hough_map\n",
    "        )\n",
    "\n",
    "        # === Z-score normalize the full map ===\n",
    "        mean = fused_global.mean()\n",
    "        std = fused_global.std()\n",
    "        zmap = (fused_global - mean) / (std + 1e-8)\n",
    "\n",
    "        # === Then threshold on zmap, e.g. ===\n",
    "        binary = (zmap > 2.0)\n",
    "\n",
    "        lbl, num = ndi.label(binary)\n",
    "        sizes = np.bincount(lbl.ravel())\n",
    "        clean = np.zeros_like(binary)\n",
    "        for i, sz in enumerate(sizes):\n",
    "            if i>0 and sz>=50:      # just drop very tiny blobs\n",
    "                clean[lbl==i] = True\n",
    "\n",
    "        # 1.2 Bridge very nearby regions (so that close boxes will fuse)\n",
    "        #    a dilation with a 20×20 square will join components separated by ≤2 pixels\n",
    "        k = 20\n",
    "        # a horizontal line structuring element (bridges gaps up to k pixels left/right)\n",
    "        se_h = np.ones((1, k), bool)\n",
    "\n",
    "        # a vertical line structuring element (bridges gaps up to k pixels up/down)\n",
    "        se_v = np.ones((k, 1), bool)\n",
    "\n",
    "        # dilate separately in each orientation…\n",
    "        bridged_h = ndi.binary_dilation(clean, structure=se_h)\n",
    "        bridged_v = ndi.binary_dilation(clean, structure=se_v)\n",
    "\n",
    "        # …then take their union\n",
    "        bridged = bridged_h | bridged_v\n",
    "        # 1.3 (Optional) re-fill small holes in the newly merged blobs\n",
    "        filled = ndi.binary_closing(bridged, structure=np.ones((3,3),bool))\n",
    "\n",
    "\n",
    "        # YOLO boxes\n",
    "        boxes = generate_yolo_boxes(filled)\n",
    "        if boxes is None:\n",
    "            boxes = []\n",
    "        # Merge overlapping boxes\n",
    "        boxes = merge_overlaps_by_coords(boxes)\n",
    "        # compute global mean brightness once\n",
    "        global_mean = block.mean()\n",
    "\n",
    "        # choose how much darker to allow (e.g. 10% darker)\n",
    "        tol = 0.10\n",
    "\n",
    "        good_boxes = []\n",
    "        for cx, cy, w_n, h_n in boxes:\n",
    "            # map back to pixel coords\n",
    "            x0 = int((cx - w_n/2) * w_img)\n",
    "            x1 = int((cx + w_n/2) * w_img)\n",
    "            y0 = int((cy - h_n/2) * h_img)\n",
    "            y1 = int((cy + h_n/2) * h_img)\n",
    "\n",
    "            # clamp\n",
    "            x0, x1 = max(0, x0), min(w_img, x1)\n",
    "            y0, y1 = max(0, y0), min(h_img, y1)\n",
    "\n",
    "            patch = block[y0:y1, x0:x1]\n",
    "            if patch.size == 0:\n",
    "                continue\n",
    "\n",
    "            patch_mean = patch.mean()\n",
    "            # only keep it if it’s no more than tol below global\n",
    "            if patch_mean >= (1 - tol) * global_mean:\n",
    "                good_boxes.append((cx, cy, w_n, h_n))\n",
    "\n",
    "        boxes = good_boxes\n",
    "\n",
    "        del sf_map, ued_map, canny_map, hough_map\n",
    "        del fused_global, zmap\n",
    "        gc.collect()\n",
    "        # [.. save PNG, write .txt, draw visualization exactly as before ..]\n",
    "        # Calculate frequency range of this coarse channel\n",
    "        f_start = fb.header['fch1'] + f0 * fb.header['foff']\n",
    "        f_stop  = fb.header['fch1'] + (f1 - 1) * fb.header['foff']\n",
    "        \n",
    "        # Build filename\n",
    "        f_start = fb.header['fch1'] + f0 * fb.header['foff']\n",
    "        f_stop  = fb.header['fch1'] + (f1 - 1) * fb.header['foff']\n",
    "        kurt_val = kurtosis(gray8.flatten(), fisher=False)\n",
    "        if kurt_val < 7.0:\n",
    "            continue  # skip if kurtosis is too low (e.g. noise)\n",
    "        fn = f\"img_{kurt_val:0{pad_width}.3f}_f_{f_start:.4f}_{f_stop:.4f}.png\"\n",
    "        img_path = img_dir / fn\n",
    "        txt_path = lbl_dir / fn.replace(\".png\", \".txt\")\n",
    "\n",
    "        if len(boxes) == 0:\n",
    "            continue  # skip if no boxes found\n",
    "\n",
    "        # Save image\n",
    "        arr8 = (255 * (block - block.min()) / (np.ptp(block) + 1e-6)).astype(np.uint8)\n",
    "        img = Image.fromarray(np.stack([arr8]*3, axis=-1))\n",
    "        img.save(img_path)\n",
    "\n",
    "        # Write YOLO labels\n",
    "        with open(txt_path, \"w\") as f:\n",
    "            for x_c, y_c, w_n, h_n in boxes:\n",
    "                f.write(f\"{class_id} {x_c:.6f} {y_c:.6f} {w_n:.6f} {h_n:.6f}\\n\")\n",
    "\n",
    "        # # If empty, log it\n",
    "        # if not boxes:\n",
    "        #     (lbl_dir/\"empty_labels.csv\").open(\"a\").write(f\"{fn},{h5_path},{ch_idx}\\n\")\n",
    "\n",
    "        # Draw & save visualization\n",
    "        vis_img = img.convert(\"RGB\")\n",
    "        draw    = ImageDraw.Draw(vis_img)\n",
    "        for x_c, y_c, w_n, h_n in boxes:\n",
    "            xc, yc = x_c*w_img, y_c*h_img\n",
    "            bw, bh = w_n*w_img, h_n*h_img\n",
    "            x0, y0 = int(xc - bw/2), int(yc - bh/2)\n",
    "            x1, y1 = int(xc + bw/2), int(yc + bh/2)\n",
    "            draw.rectangle([x0, y0, x1, y1], outline=\"red\", width=2)\n",
    "        vis_img.save(vis_dir/fn)\n",
    "        # debug_dir = vis_dir/\"debug_masks\"\n",
    "        # debug_dir.mkdir(exist_ok=True)\n",
    "        # imageio.imwrite(debug_dir/f\"binary_{kurt_val}_{f_start}_{f_stop}.png\",   (binary*255).astype(np.uint8))\n",
    "        del binary\n",
    "    del data, fb, h5_path, channels, gidxs\n",
    "    gc.collect()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tasks = build_tasks(df)\n",
    "    train_set, val_set = split_tasks(tasks)\n",
    "\n",
    "    # 2) build job tuples of exactly what process_file unpacks:\n",
    "    job_args = []\n",
    "    BASE_DIR = \"/datax/scratch/jliang/dataset_final_7\"\n",
    "    NUM_WORKERS = 2\n",
    "    class_id = 0  # Assuming a single class for simplicity\n",
    "    pad_width = 4  # Zero-padding width for gidx in filenames\n",
    "    for idx, (h5_path, ch_idx) in enumerate(tasks):\n",
    "        job = (\n",
    "            h5_path,\n",
    "            [ch_idx],        # channels\n",
    "            [idx],           # gidxs\n",
    "            BASE_DIR,\n",
    "            class_id,\n",
    "            train_set,\n",
    "            val_set,\n",
    "            pad_width\n",
    "        )\n",
    "        job_args.append(job)\n",
    "\n",
    "    # 3) submit each job as a single argument\n",
    "    with ProcessPoolExecutor(max_workers=NUM_WORKERS) as exe:\n",
    "        futures = {\n",
    "            exe.submit(process_file, job): (job[0], job[1])\n",
    "            for job in job_args\n",
    "        }\n",
    "\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), ascii=True):\n",
    "            h5, ch_list = futures[future]\n",
    "            try:\n",
    "                future.result()\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {h5} channel {ch_list}: {e}\")\n",
    "                traceback.print_exc()\n",
    "                raise\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
