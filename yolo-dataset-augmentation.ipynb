{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0017643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install albumentations opencv-python numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b25641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "yolo_hit_augment_split.py\n",
    "\n",
    "Over-sample a single-class (\"hit\") YOLO dataset, preserving an 80/20 train/val split.\n",
    "\n",
    "Layout:\n",
    "  data/\n",
    "    train/\n",
    "      images/\n",
    "      labels/\n",
    "    val/\n",
    "      images/\n",
    "      labels/\n",
    "\n",
    "Outputs into:\n",
    "  augmented/\n",
    "    train/\n",
    "      images/\n",
    "      labels/\n",
    "    val/\n",
    "      images/\n",
    "      labels/\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "\n",
    "# --- USER CONFIG ---\n",
    "DATA_DIR        = \"//datax/scratch/jliang/dataset_final_small\"\n",
    "TRAIN_IMG_DIR   = os.path.join(DATA_DIR, \"train\", \"images\")\n",
    "TRAIN_LBL_DIR   = os.path.join(DATA_DIR, \"train\", \"labels\")\n",
    "VAL_IMG_DIR     = os.path.join(DATA_DIR, \"val\",   \"images\")\n",
    "VAL_LBL_DIR     = os.path.join(DATA_DIR, \"val\",   \"labels\")\n",
    "OUTPUT_DIR      = \"/datax/scratch/jliang/augmented\"\n",
    "TARGET_TOTAL    = 2000      # desired total images (train+val) after augmentation\n",
    "SPLIT_RATIO     = {\"train\": 0.8, \"val\": 0.2}\n",
    "SEED            = 42\n",
    "# ---------------------\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def gather_pairs(img_dir, lbl_dir):\n",
    "    pairs = []\n",
    "    for img_path in glob(os.path.join(img_dir, \"*\")):\n",
    "        stem, ext = os.path.splitext(os.path.basename(img_path))\n",
    "        lbl_path = os.path.join(lbl_dir, stem + \".txt\")\n",
    "        if os.path.exists(lbl_path):\n",
    "            pairs.append((img_path, lbl_path))\n",
    "    return pairs\n",
    "\n",
    "# 1) Gather train/val pairs\n",
    "# train_pairs = gather_pairs(TRAIN_IMG_DIR, TRAIN_LBL_DIR)\n",
    "val_pairs   = gather_pairs(VAL_IMG_DIR,   VAL_LBL_DIR)\n",
    "\n",
    "# if not train_pairs:\n",
    "#     raise RuntimeError(\"No train images+labels found!\")\n",
    "if not val_pairs:\n",
    "    raise RuntimeError(\"No val images+labels found!\")\n",
    "\n",
    "# n_train_orig = len(train_pairs)\n",
    "n_orig_total   = len(val_pairs)\n",
    "# n_orig_total = n_val_orig\n",
    "\n",
    "print(f\"Original counts: {n_orig_total})\")\n",
    "\n",
    "# 2) Compute how many augmentations needed per split\n",
    "needed_total = max(0, TARGET_TOTAL - n_orig_total)\n",
    "n_train_aug  = int(round(needed_total * SPLIT_RATIO[\"train\"]))\n",
    "n_val_aug    = needed_total - n_train_aug\n",
    "\n",
    "print(f\"Will create {n_train_aug} train augmentations and {n_val_aug} val augmentations\")\n",
    "\n",
    "# 3) Prepare output dirs\n",
    "for split, pairs in [(\"train\", train_pairs), (\"val\", val_pairs)]:\n",
    "    for sub in (\"images\", \"labels\"):\n",
    "        od = os.path.join(OUTPUT_DIR, split, sub)\n",
    "        if os.path.exists(od):\n",
    "            shutil.rmtree(od)\n",
    "        os.makedirs(od)\n",
    "    # copy originals\n",
    "    for imgf, lblf in pairs:\n",
    "        stem, ext = os.path.splitext(os.path.basename(imgf))\n",
    "        shutil.copy(imgf, os.path.join(OUTPUT_DIR, split, \"images\", stem + ext))\n",
    "        shutil.copy(lblf, os.path.join(OUTPUT_DIR, split, \"labels\", stem + \".txt\"))\n",
    "\n",
    "# 4) Set up Albumentations pipeline (bbox-aware)\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.RandomScale(scale_limit=0.2, p=0.5),\n",
    "    A.Rotate(limit=15, border_mode=cv2.BORDER_REPLICATE, p=0.5),\n",
    "    A.HueSaturationValue(p=0.5),\n",
    "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "\n",
    "def augment_split(pairs, n_aug, out_dir):\n",
    "    i = 0\n",
    "    while i < n_aug:\n",
    "        # --- pick a random sample + load image ---\n",
    "        img_path, lbl_path = random.choice(pairs)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # --- load all YOLO bboxes from that single-class file ---\n",
    "        bboxes = []\n",
    "        labels = []\n",
    "        with open(lbl_path) as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    continue\n",
    "                _, x_c, y_c, bw, bh = parts\n",
    "                try:\n",
    "                    bboxes.append([float(x_c), float(y_c), float(bw), float(bh)])\n",
    "                    labels.append(0)\n",
    "                except ValueError:\n",
    "                    # malformed line\n",
    "                    continue\n",
    "        if not bboxes:\n",
    "            continue\n",
    "\n",
    "        # --- apply augmentation (skip if Albumentations still blows up) ---\n",
    "        try:\n",
    "            aug = transform(image=img, bboxes=bboxes, class_labels=labels)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        img_aug    = aug[\"image\"]\n",
    "        bboxes_aug = aug[\"bboxes\"]\n",
    "        labels_aug = aug[\"class_labels\"]\n",
    "\n",
    "        # --- clamp tiny out-of-bounds to [0,1] + drop zero-area boxes ---\n",
    "        clamped = []\n",
    "        for (xc, yc, w, h), lbl in zip(bboxes_aug, labels_aug):\n",
    "            xc = min(max(xc, 0.0), 1.0)\n",
    "            yc = min(max(yc, 0.0), 1.0)\n",
    "            w  = min(max(w,  0.0), 1.0)\n",
    "            h  = min(max(h,  0.0), 1.0)\n",
    "            if w <= 0 or h <= 0:\n",
    "                continue\n",
    "            clamped.append((xc, yc, w, h, lbl))\n",
    "        if not clamped:\n",
    "            continue\n",
    "\n",
    "        # --- write out the augmented image & label file ---\n",
    "        stem    = os.path.splitext(os.path.basename(img_path))[0] + f\"_aug_{i}\"\n",
    "        out_img = os.path.join(out_dir, \"images\", stem + os.path.splitext(img_path)[1])\n",
    "        out_lbl = os.path.join(out_dir, \"labels\", stem + \".txt\")\n",
    "\n",
    "        cv2.imwrite(out_img, img_aug)\n",
    "        with open(out_lbl, \"w\") as fw:\n",
    "            for xc, yc, w, h, lbl in clamped:\n",
    "                fw.write(f\"{lbl} {xc:.6f} {yc:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "\n",
    "        i += 1\n",
    "        if i % 50 == 0 or i == n_aug:\n",
    "            print(f\" â†’ {i}/{n_aug} aug in {os.path.basename(out_dir)} done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Run augmentation on each split\n",
    "augment_split(train_pairs,\n",
    "              n_train_aug,\n",
    "              os.path.join(OUTPUT_DIR, \"train\"))\n",
    "augment_split(val_pairs,\n",
    "              n_val_aug,\n",
    "              os.path.join(OUTPUT_DIR, \"val\"))\n",
    "\n",
    "print(\"All done \", OUTPUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
