{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81b1b1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bitshuffle in /mnt_home/jliang/.local/lib/python3.7/site-packages (0.5.1)\n",
      "Requirement already satisfied: h5py>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from bitshuffle) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from bitshuffle) (1.20.3)\n",
      "Requirement already satisfied: setuptools>=0.7 in /opt/conda/lib/python3.7/site-packages (from bitshuffle) (62.3.2)\n",
      "Requirement already satisfied: Cython>=0.19 in /opt/conda/lib/python3.7/site-packages (from bitshuffle) (0.29.30)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py>=2.4.0->bitshuffle) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (7.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bitshuffle\n",
    "%pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fe6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import blimpy as bl\n",
    "#from ultralytics import YOLO\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import psutil\n",
    "import scipy.ndimage\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import cv2\n",
    "from scipy.ndimage import label as connected_components\n",
    "from skimage.filters import sobel\n",
    "from skimage.segmentation import slic\n",
    "from skimage.util import img_as_float\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dba8ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Session</th>\n",
       "      <th>Band</th>\n",
       "      <th>Cadence ID</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>.h5 path</th>\n",
       "      <th>.dat path</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36553</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36554</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36555</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36556</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36557</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36558 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Target          Session Band  Cadence ID  Frequency  \\\n",
       "0       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "1       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "2       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "3       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "4       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "...        ...              ...  ...         ...        ...   \n",
       "36553  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "36554  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "36555  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "36556  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "36557  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "\n",
       "                                                .h5 path  \\\n",
       "0      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "1      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "2      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "3      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "4      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "...                                                  ...   \n",
       "36553  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "36554  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "36555  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "36556  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "36557  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "\n",
       "                                               .dat path                 Time  \n",
       "0      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "1      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "2      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "3      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "4      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "...                                                  ...                  ...  \n",
       "36553  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "36554  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "36555  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "36556  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "36557  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "\n",
       "[36558 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/cgchoza/galaxies/complete_cadences_catalog.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "730aa85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Session</th>\n",
       "      <th>Band</th>\n",
       "      <th>Cadence ID</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>.h5 path</th>\n",
       "      <th>.dat path</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30309</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30310</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30311</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30312</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30313</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30314 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Target          Session Band  Cadence ID  Frequency  \\\n",
       "0       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "1       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "2       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "3       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "4       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "...        ...              ...  ...         ...        ...   \n",
       "30309  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "30310  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "30311  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "30312  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "30313  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "\n",
       "                                                .h5 path  \\\n",
       "0      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "1      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "2      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "3      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "4      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "...                                                  ...   \n",
       "30309  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "30310  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "30311  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "30312  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "30313  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "\n",
       "                                               .dat path                 Time  \n",
       "0      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "1      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "2      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "3      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "4      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "...                                                  ...                  ...  \n",
       "30309  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "30310  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "30311  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "30312  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "30313  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "\n",
       "[30314 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['.h5 path'] = df['.h5 path'].str.replace('0000.h5', '0002.h5', regex=False)\n",
    "df = df.drop_duplicates(subset='.h5 path', keep='first').reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38b7592b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Session</th>\n",
       "      <th>Band</th>\n",
       "      <th>Cadence ID</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>.h5 path</th>\n",
       "      <th>.dat path</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AND_XIV</td>\n",
       "      <td>AGBT18B_999_07</td>\n",
       "      <td>S</td>\n",
       "      <td>30225</td>\n",
       "      <td>3151</td>\n",
       "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
       "      <td>2018-08-18 08:41:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AND_XIV</td>\n",
       "      <td>AGBT18B_999_07</td>\n",
       "      <td>S</td>\n",
       "      <td>30225</td>\n",
       "      <td>3151</td>\n",
       "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
       "      <td>2018-08-18 08:41:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AND_XIV</td>\n",
       "      <td>AGBT18B_999_07</td>\n",
       "      <td>S</td>\n",
       "      <td>30225</td>\n",
       "      <td>3151</td>\n",
       "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
       "      <td>2018-08-18 08:41:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AND_XIV</td>\n",
       "      <td>AGBT18B_999_07</td>\n",
       "      <td>S</td>\n",
       "      <td>30225</td>\n",
       "      <td>3151</td>\n",
       "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
       "      <td>2018-08-18 08:41:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AND_XIV</td>\n",
       "      <td>AGBT18B_999_07</td>\n",
       "      <td>S</td>\n",
       "      <td>30225</td>\n",
       "      <td>3151</td>\n",
       "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
       "      <td>2018-08-18 08:41:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29341</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29342</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29343</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29344</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29345</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29346 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Target         Session Band  Cadence ID  Frequency  \\\n",
       "0      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
       "1      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
       "2      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
       "3      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
       "4      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
       "...        ...             ...  ...         ...        ...   \n",
       "29341  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
       "29342  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
       "29343  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
       "29344  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
       "29345  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
       "\n",
       "                                                .h5 path  \\\n",
       "0      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
       "1      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
       "2      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
       "3      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
       "4      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
       "...                                                  ...   \n",
       "29341  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "29342  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "29343  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "29344  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "29345  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "\n",
       "                                               .dat path                 Time  \n",
       "0      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
       "1      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
       "2      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
       "3      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
       "4      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
       "...                                                  ...                  ...  \n",
       "29341  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "29342  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "29343  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "29344  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "29345  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "\n",
       "[29346 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~df['.h5 path'].str.contains('spliced')].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1451bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index = 17546)\n",
    "df = df.sample(n=1000, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84164fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- File Info ---\n",
      "DIMENSION_LABELS : [b'time' b'feed_id' b'frequency']\n",
      "        az_start :                              0.0\n",
      "       data_type :                                1\n",
      "            fch1 :               10501.46484375 MHz\n",
      "            foff :         -0.00286102294921875 MHz\n",
      "           ibeam :                               -1\n",
      "      machine_id :                               20\n",
      "          nbeams :                                1\n",
      "           nbits :                               32\n",
      "          nchans :                            65536\n",
      "            nifs :                                1\n",
      "     rawdatafile : guppi_59411_54386_HIP30264_0094.0000.raw\n",
      "     source_name :                         HIP30264\n",
      "         src_dej :                     -8:26:53.228\n",
      "         src_raj :                      6:21:58.451\n",
      "    telescope_id :                                6\n",
      "           tsamp :                1.073741823999999\n",
      "   tstart (ISOT) :          2021-07-16T15:06:26.000\n",
      "    tstart (MJD) :                59411.62946759259\n",
      "        za_start :                              0.0\n",
      "\n",
      "Num ints in file :                              279\n",
      "      File shape :                  (279, 1, 65536)\n",
      "--- Selection Info ---\n",
      "Data selection shape :                  (279, 1, 65536)\n",
      "Minimum freq (MHz) :                10313.96770477295\n",
      "Maximum freq (MHz) :                   10501.46484375\n"
     ]
    }
   ],
   "source": [
    "fb = bl.Waterfall(df['.h5 path'].iloc[-1], load_data=True)\n",
    "fb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395191b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_boxes(boxes, iou_thresh=0.1, proximity_thresh=0.05):\n",
    "    \"\"\"\n",
    "    Merge boxes if their centers are close or they have significant IoU overlap.\n",
    "    boxes: list of (cx, cy, w, h, area)\n",
    "    returns: merged list of boxes\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    def iou(b1, b2):\n",
    "        x1_min = b1[0] - b1[2] / 2\n",
    "        x1_max = b1[0] + b1[2] / 2\n",
    "        y1_min = b1[1] - b1[3] / 2\n",
    "        y1_max = b1[1] + b1[3] / 2\n",
    "\n",
    "        x2_min = b2[0] - b2[2] / 2\n",
    "        x2_max = b2[0] + b2[2] / 2\n",
    "        y2_min = b2[1] - b2[3] / 2\n",
    "        y2_max = b2[1] + b2[3] / 2\n",
    "\n",
    "        inter_xmin = max(x1_min, x2_min)\n",
    "        inter_ymin = max(y1_min, y2_min)\n",
    "        inter_xmax = min(x1_max, x2_max)\n",
    "        inter_ymax = min(y1_max, y2_max)\n",
    "\n",
    "        inter_area = max(0, inter_xmax - inter_xmin) * max(0, inter_ymax - inter_ymin)\n",
    "        area1 = b1[2] * b1[3]\n",
    "        area2 = b2[2] * b2[3]\n",
    "        union = area1 + area2 - inter_area\n",
    "\n",
    "        return inter_area / union if union > 0 else 0\n",
    "\n",
    "    def distance(b1, b2):\n",
    "        return np.hypot(b1[0] - b2[0], b1[1] - b2[1])\n",
    "\n",
    "    merged = []\n",
    "    used = [False] * len(boxes)\n",
    "\n",
    "    for i, b1 in enumerate(boxes):\n",
    "        if used[i]:\n",
    "            continue\n",
    "        group = [b1]\n",
    "        used[i] = True\n",
    "        for j, b2 in enumerate(boxes):\n",
    "            if used[j]:\n",
    "                continue\n",
    "            if iou(b1, b2) > iou_thresh or distance(b1, b2) < proximity_thresh:\n",
    "                group.append(b2)\n",
    "                used[j] = True\n",
    "        if len(group) == 1:\n",
    "            merged.append(group[0])\n",
    "        else:\n",
    "            # merge into one big box (average center, min enclosing width/height)\n",
    "            xs = [b[0] for b in group]\n",
    "            ys = [b[1] for b in group]\n",
    "            ws = [b[2] for b in group]\n",
    "            hs = [b[3] for b in group]\n",
    "            xmins = [x - w/2 for x, w in zip(xs, ws)]\n",
    "            xmaxs = [x + w/2 for x, w in zip(xs, ws)]\n",
    "            ymins = [y - h/2 for y, h in zip(ys, hs)]\n",
    "            ymaxs = [y + h/2 for y, h in zip(ys, hs)]\n",
    "            new_x = (min(xmins) + max(xmaxs)) / 2\n",
    "            new_y = (min(ymins) + max(ymaxs)) / 2\n",
    "            new_w = max(xmaxs) - min(xmins)\n",
    "            new_h = max(ymaxs) - min(ymins)\n",
    "            merged.append((new_x, new_y, new_w, new_h, new_w * new_h))\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bde136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_heuristics(image, edge_map):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gradient = sobel(gray)\n",
    "\n",
    "    # Heuristics\n",
    "    edge_density = np.mean(edge_map > 0.2)\n",
    "    edge_gradient_alignment = np.mean(gradient[edge_map > 0.2])\n",
    "    edge_entropy = -np.sum(edge_map * np.log2(edge_map + 1e-8))\n",
    "    if np.mean(edge_map > 0.2) < 0.01:\n",
    "        return [0.0, 0.0, 0.0]\n",
    "    return [edge_density, edge_gradient_alignment, edge_entropy]\n",
    "\n",
    "def pseudo_labels(image, sf_edges, ued_edges):\n",
    "    h_sf = compute_heuristics(image, sf_edges)\n",
    "    h_ued = compute_heuristics(image, ued_edges)\n",
    "    \n",
    "    # Simple rule: if UED has higher gradient alignment and lower entropy, favor it\n",
    "    if h_ued[1] > h_sf[1] and h_ued[2] < h_sf[2]:\n",
    "        return 0  # UED wins\n",
    "    else:\n",
    "        return 1  # SF wins\n",
    "\n",
    "def train_gating_model(images, sf_edge_maps, ued_edge_maps):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for image, sf_edges, ued_edges in zip(images, sf_edge_maps, ued_edge_maps):\n",
    "        segments = slic(img_as_float(image), n_segments=100, compactness=10)\n",
    "        for seg_val in np.unique(segments):\n",
    "            mask = (segments == seg_val)\n",
    "            region = mask.astype(float)\n",
    "            sf_patch = sf_edges * region\n",
    "            ued_patch = ued_edges * region\n",
    "            if np.sum(region) < 50:\n",
    "                continue\n",
    "            signal_strength = np.mean(sf_patch) + np.mean(ued_patch)\n",
    "            if signal_strength < 0.01:\n",
    "                continue  # this segment is likely noise\n",
    "            h_sf = compute_heuristics(image, sf_patch)\n",
    "            h_ued = compute_heuristics(image, ued_patch)\n",
    "            f = np.array(h_sf + h_ued)\n",
    "            label = pseudo_labels(image, sf_patch, ued_patch)\n",
    "            features.append(f)\n",
    "            labels.append(label)\n",
    "\n",
    "    if len(set(labels)) < 2:\n",
    "        return None, None\n",
    "\n",
    "    # Convert to arrays\n",
    "    X = np.array(features)\n",
    "    y = np.array(labels)\n",
    "\n",
    "    # Remove any rows with NaN or inf just in case\n",
    "    mask_valid = np.all(np.isfinite(X), axis=1)\n",
    "    if not np.all(mask_valid):\n",
    "        print(f\"Dropping {np.sum(~mask_valid)} bad rows from training.\")\n",
    "        X = X[mask_valid]\n",
    "        y = y[mask_valid]\n",
    "\n",
    "    # Scale and train\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    clf = LogisticRegression().fit(X_scaled, y)\n",
    "    return clf, scaler\n",
    "\n",
    "def apply_gating_model(image, sf_edges, ued_edges, model, scaler):\n",
    "    segments = slic(img_as_float(image), n_segments=100, compactness=10)\n",
    "    gated_output = np.zeros_like(sf_edges)\n",
    "\n",
    "    for seg_val in np.unique(segments):\n",
    "        mask = (segments == seg_val)\n",
    "        region = mask.astype(float)\n",
    "        sf_patch = sf_edges * region\n",
    "        ued_patch = ued_edges * region\n",
    "        signal_strength = np.mean(sf_patch) + np.mean(ued_patch)\n",
    "        if signal_strength < 0.01:\n",
    "            continue  # this segment is likely noise\n",
    "\n",
    "        h_sf = compute_heuristics(image, sf_patch)\n",
    "        h_ued = compute_heuristics(image, ued_patch)\n",
    "\n",
    "        f = np.array(h_sf + h_ued).reshape(1, -1)\n",
    "\n",
    "        if not np.all(np.isfinite(f)):\n",
    "            continue\n",
    "        if np.allclose(f, 0, atol=1e-3):\n",
    "            continue\n",
    "\n",
    "\n",
    "        try:\n",
    "            f_scaled = scaler.transform(f)\n",
    "            pred = model.predict_proba(f_scaled)[0]\n",
    "        except Exception as e:\n",
    "            print(f\"Model predict failed on segment {seg_val}: {e}\")\n",
    "            continue\n",
    "\n",
    "        weight_sf = pred[1]\n",
    "        weight_ued = pred[0]\n",
    "        combined = weight_sf * sf_patch + weight_ued * ued_patch\n",
    "        gated_output[mask] = combined[mask]\n",
    "\n",
    "    return gated_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c822d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_detection(gray, factor=6, dilation=(3, 3)):\n",
    "        # STEP 1: apply power threshold to suppress background\n",
    "        median = np.median(gray)\n",
    "        mad = np.median(np.abs(gray - median))\n",
    "        power_mask = gray > (median + factor * mad) \n",
    "\n",
    "        # STEP 2: edge detection on filtered signal only\n",
    "        grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "        magnitude *= power_mask  # mask out noise\n",
    "        magnitude = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "        # STEP 3: binary threshold + dilation\n",
    "        binary = magnitude > 50  # you can tune this\n",
    "        binary = scipy.ndimage.binary_dilation(binary, structure=np.ones(dilation))\n",
    "        labeled, n_objs = scipy.ndimage.label(binary)\n",
    "        slices = scipy.ndimage.find_objects(labeled)\n",
    "        return slices\n",
    "\n",
    "EDGE_MODEL_PATH = '/home/jliang/gbt-rfi/model.yml.gz'\n",
    "EDGE_DETECTOR = cv2.ximgproc.createStructuredEdgeDetection(EDGE_MODEL_PATH)\n",
    "\n",
    "def detect_edges(spectrogram):\n",
    "    img = (spectrogram - spectrogram.min()) / (spectrogram.ptp() + 1e-6)\n",
    "    img_3ch = cv2.merge([img.astype(np.float32)] * 3)\n",
    "    return EDGE_DETECTOR.detectEdges(img_3ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fea6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_one_sample(h5_path, ch, edge_model_path='/home/jliang/gbt-rfi/model.yml.gz'):\n",
    "    try:\n",
    "        EDGE_DETECTOR = cv2.ximgproc.createStructuredEdgeDetection(edge_model_path)\n",
    "        fb = bl.Waterfall(h5_path, load_data=True)\n",
    "        data = 10 * np.log10(fb.data.squeeze())\n",
    "\n",
    "        nfpc = fb.header.get(\"nfpc\", 1024)\n",
    "        f0, f1 = ch * nfpc, (ch + 1) * nfpc\n",
    "        block = data[:, f0:f1]\n",
    "\n",
    "        n_cols = block.shape[1]\n",
    "        low, high = int(0.1 * n_cols), int(0.9 * n_cols)\n",
    "        block_middle80 = block[:, low:high]\n",
    "\n",
    "        vert_means = block_middle80.mean(axis=0)\n",
    "        center = np.argmax(vert_means)\n",
    "        left_col, right_col = center - 1, center + 1\n",
    "        if left_col >= 0 and right_col < block_middle80.shape[1]:\n",
    "            block_middle80[:, center] = (block_middle80[:, left_col] + block_middle80[:, right_col]) / 2\n",
    "        elif left_col >= 0:\n",
    "            block_middle80[:, center] = block_middle80[:, left_col]\n",
    "        elif right_col < block_middle80.shape[1]:\n",
    "            block_middle80[:, center] = block_middle80[:, right_col]\n",
    "\n",
    "        img_norm = (block_middle80 - block_middle80.min()) / (block_middle80.ptp() + 1e-6)\n",
    "        img_rgb = cv2.merge([img_norm.astype(np.float32)] * 3)\n",
    "\n",
    "        sf_edges = EDGE_DETECTOR.detectEdges(img_rgb)\n",
    "\n",
    "        gray = (255 * img_norm).astype(np.uint8)\n",
    "        grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "        magnitude = cv2.normalize(magnitude, None, 0, 1, cv2.NORM_MINMAX)\n",
    "\n",
    "        sf_mean = np.mean(sf_edges)\n",
    "        ued_mean = np.mean(magnitude)\n",
    "\n",
    "        if sf_mean + ued_mean < 0.005:  # threshold to skip empty or background-only blocks\n",
    "            return None  # skip empty or background-only blocks\n",
    "\n",
    "\n",
    "        return (img_rgb, sf_edges, magnitude)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {h5_path} ch {ch}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_samples_parallel(df: pd.DataFrame, max_samples=40000, num_workers=2):\n",
    "    from random import shuffle\n",
    "\n",
    "    all_tasks = []\n",
    "    for _, row in df.iterrows():\n",
    "        h5 = row[\".h5 path\"]\n",
    "        fb = bl.Waterfall(h5, load_data=False)\n",
    "        nfreq = fb.header.get(\"nchans\")\n",
    "        nfpc = fb.header.get(\"nfpc\", 1024)\n",
    "        for ch in range(nfreq // nfpc):\n",
    "            all_tasks.append((h5, ch))\n",
    "\n",
    "    shuffle(all_tasks)\n",
    "    selected_tasks = all_tasks[:max_samples]\n",
    "\n",
    "    train_images, train_sf_edges, train_ued_edges = [], [], []\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = [executor.submit(extract_one_sample, h5, ch) for h5, ch in selected_tasks]\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                img_rgb, sf_edge, ued_edge = result\n",
    "                train_images.append(img_rgb)\n",
    "                train_sf_edges.append(sf_edge)\n",
    "                train_ued_edges.append(ued_edge)\n",
    "\n",
    "    return train_images, train_sf_edges, train_ued_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50421249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) SET UP LOGGING\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "def build_tasks(df):\n",
    "    \"\"\"\n",
    "    Build a flat list of (h5_path, channel_idx) from your DataFrame,\n",
    "    skipping any channels that fall into known notch filter frequency ranges.\n",
    "    \"\"\"\n",
    "    GBT_NOTCH_FILTERS = {\n",
    "        \"L\": [(1200, 1340)],\n",
    "        \"S\": [(2300, 2360)],\n",
    "    }\n",
    "\n",
    "    tasks = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        h5 = row[\".h5 path\"]\n",
    "        band = row[\"Band\"]  # e.g., 'L', 'S', etc.\n",
    "        fb = bl.Waterfall(h5, load_data=False)\n",
    "        nfreq = fb.header.get(\"nchans\")\n",
    "        nfpc = fb.header.get(\"nfpc\", 1024)\n",
    "        fch1 = fb.header[\"fch1\"]\n",
    "        foff = fb.header[\"foff\"]\n",
    "        n_coarse = nfreq // nfpc\n",
    "\n",
    "        for ch in range(n_coarse):\n",
    "            f0 = fch1 + ch * nfpc * foff\n",
    "            f1 = fch1 + (ch + 1) * nfpc * foff\n",
    "            f_min, f_max = sorted([f0, f1])\n",
    "\n",
    "            # Check against notch filter exclusion ranges\n",
    "            skip = False\n",
    "            if band in GBT_NOTCH_FILTERS:\n",
    "                for lo, hi in GBT_NOTCH_FILTERS[band]:\n",
    "                    if lo <= f_min <= hi or lo <= f_max <= hi:\n",
    "                        skip = True\n",
    "                        break\n",
    "            if not skip:\n",
    "                tasks.append((h5, ch))\n",
    "\n",
    "    return tasks\n",
    "\n",
    "\n",
    "def split_tasks(tasks, train_frac=0.8, seed=42):\n",
    "    \"\"\"\n",
    "    Shuffle & split the flat task list into train vs. val sets.\n",
    "    Returns two sets of (h5_path, channel_idx).\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    shuffled = tasks.copy()\n",
    "    random.shuffle(shuffled)\n",
    "    cut = int(train_frac * len(shuffled))\n",
    "    train = set(shuffled[:cut])\n",
    "    val   = set(shuffled[cut:])\n",
    "    return train, val\n",
    "\n",
    "def process_file(job):\n",
    "    \"\"\"\n",
    "    job is a tuple:\n",
    "      (h5_path, [ch_idx,...], [global_idx,...],\n",
    "       base_dir, coarse_channel_width, factor, dilation_size,\n",
    "       class_id, train_set, val_set)\n",
    "    \"\"\"\n",
    "    (h5_path,\n",
    "     channels,\n",
    "     global_indices,\n",
    "     base_dir,\n",
    "     factor,\n",
    "     dilation,\n",
    "     class_id,\n",
    "     train_set,\n",
    "     val_set,\n",
    "     pad_width,\n",
    "     model,\n",
    "     scalar) = job\n",
    "\n",
    "    def generate_yolo_boxes(edge_map, threshold=0.1):\n",
    "        binary = (edge_map > threshold).astype(np.uint8)\n",
    "        labeled, n = connected_components(binary)\n",
    "        boxes = []\n",
    "        for i in range(1, n + 1):\n",
    "            coords = np.argwhere(labeled == i)\n",
    "            if coords.shape[0] < 10:\n",
    "                continue\n",
    "            y0, x0 = coords.min(axis=0)\n",
    "            y1, x1 = coords.max(axis=0)\n",
    "            cx = (x0 + x1) / 2 / edge_map.shape[1]\n",
    "            cy = (y0 + y1) / 2 / edge_map.shape[0]\n",
    "            w = (x1 - x0) / edge_map.shape[1]\n",
    "            h = (y1 - y0) / edge_map.shape[0]\n",
    "            boxes.append((cx, cy, w, h, w * h))\n",
    "        return boxes\n",
    "\n",
    "    # 1) load the waterfall once\n",
    "    fb   = bl.Waterfall(h5_path, load_data=True)\n",
    "    data = 10 * np.log10(fb.data.squeeze())   # shape (ntime, nfreq)\n",
    "    nt, nf = data.shape\n",
    "\n",
    "    #  # 2) threshold + dilation\n",
    "    # M, S = np.median(data), np.std(data)\n",
    "    # binary = data > (M + factor * S)\n",
    "    # binary = scipy.ndimage.maximum_filter(binary, size=dilation)\n",
    "\n",
    "    # 3) process each channel\n",
    "    for ch_idx, gidx in zip(channels, global_indices):\n",
    "        cw = fb.header.get(\"nfpc\", 1024)  # default to 1024 if not set\n",
    "        f0, f1 = ch_idx*cw, (ch_idx+1)*cw\n",
    "        block  = data[:, f0:f1]\n",
    "\n",
    "        # decide train vs val\n",
    "        subset = \"train\" if (h5_path, ch_idx) in train_set else \"val\"\n",
    "\n",
    "        # make sure all dirs exist\n",
    "        img_dir = Path(base_dir)/subset/\"images\"\n",
    "        lbl_dir = Path(base_dir)/subset/\"labels\"\n",
    "        vis_dir = Path(base_dir)/\"visualization\"/subset\n",
    "        for d in (img_dir, lbl_dir, vis_dir):\n",
    "            d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Get rid of rolloff\n",
    "        n_cols = block.shape[1]\n",
    "        low = int(0.1 * n_cols)\n",
    "        high = int(0.9 * n_cols)\n",
    "        block_middle80 = block[:, low:high]\n",
    "\n",
    "        # Remove vertical line artifact\n",
    "        rows, cols = block_middle80.shape\n",
    "        vert_means = block_middle80.mean(axis=0)\n",
    "        center = np.argmax(vert_means)\n",
    "        left_col = center - 1\n",
    "        right_col = center + 1\n",
    "        if left_col >= 0 and right_col < cols:\n",
    "            block_middle80[:, center] = (block_middle80[:, left_col] + block_middle80[:, right_col]) / 2\n",
    "        elif left_col >= 0:\n",
    "            block_middle80[:, center] = block_middle80[:, left_col]\n",
    "        elif right_col < cols:\n",
    "            block_middle80[:, center] = block_middle80[:, right_col]\n",
    "\n",
    "        # ====== NOW threshold and dilate on the CLEANED block ======\n",
    "        #import scipy.ndimage\n",
    "\n",
    "        # Normalize for visualization + processing\n",
    "        arr8 = (255 * (block_middle80 - block_middle80.min()) / block_middle80.ptp()).astype(np.uint8)\n",
    "        gray = arr8\n",
    "        h, w = gray.shape\n",
    "\n",
    "        # Normalize the image block\n",
    "        img_norm = (block_middle80 - block_middle80.min()) / (block_middle80.ptp() + 1e-6)\n",
    "\n",
    "        # Compute structured forests edge map\n",
    "        EDGE_MODEL_PATH = '/home/jliang/gbt-rfi/model.yml.gz'\n",
    "        EDGE_DETECTOR = cv2.ximgproc.createStructuredEdgeDetection(EDGE_MODEL_PATH)\n",
    "        img_rgb = cv2.merge([img_norm.astype(np.float32)] * 3)\n",
    "        sf_edge_map = EDGE_DETECTOR.detectEdges(img_rgb)\n",
    "\n",
    "        # Compute unsupervised edge map (e.g., Sobel)\n",
    "        gray = (255 * img_norm).astype(np.uint8)\n",
    "        ued_edge_map = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3) ** 2 + \\\n",
    "                        cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3) ** 2\n",
    "        ued_edge_map = np.sqrt(ued_edge_map)\n",
    "        ued_edge_map = cv2.normalize(ued_edge_map, None, 0, 1, cv2.NORM_MINMAX)\n",
    "\n",
    "\n",
    "        # STEP 3: binary threshold + dilation\n",
    "        if model is None or scaler is None:\n",
    "            return\n",
    "        # Fuse with gating model\n",
    "        fused_edges = apply_gating_model(img_rgb, sf_edge_map, ued_edge_map, model, scaler)\n",
    "\n",
    "        # Generate boxes from fused edges\n",
    "        slices = edge_detection(gray, factor=factor, dilation=dilation)\n",
    "        boxes_from_blobs = []\n",
    "        for sl in slices:\n",
    "            if sl is None:\n",
    "                continue\n",
    "            y1, y2 = sl[0].start, sl[0].stop\n",
    "            x1, x2 = sl[1].start, sl[1].stop\n",
    "            cx = (x1 + x2) / 2 / gray.shape[1]\n",
    "            cy = (y1 + y2) / 2 / gray.shape[0]\n",
    "            bw = (x2 - x1) / gray.shape[1]\n",
    "            bh = (y2 - y1) / gray.shape[0]\n",
    "            if bw * bh > 0.95 or bw * gray.shape[1] < 3 or bh * gray.shape[0] < 3:\n",
    "                continue\n",
    "            boxes_from_blobs.append((cx, cy, bw, bh, bw * bh))\n",
    "\n",
    "        boxes_from_edges = generate_yolo_boxes(fused_edges, threshold=0.1)\n",
    "        all_boxes = boxes_from_blobs + boxes_from_edges\n",
    "\n",
    "        # Calculate frequency range of this coarse channel\n",
    "        f_start = fb.header['fch1'] + f0 * fb.header['foff']\n",
    "        f_stop  = fb.header['fch1'] + (f1 - 1) * fb.header['foff']\n",
    "\n",
    "        # Prepare and save PNG\n",
    "        arr8 = (255 * (block_middle80 - block_middle80.min()) / block_middle80.ptp()).astype(np.uint8)\n",
    "        rgb = np.stack([arr8] * 3, axis=-1)\n",
    "        img = Image.fromarray(rgb)\n",
    "        fn = f\"img_{gidx:0{pad_width}d}_f_{f_start:.4f}_{f_stop:.4f}.png\"\n",
    "        img_path = img_dir / fn\n",
    "        img.save(img_path)\n",
    "\n",
    "                # Save YOLO boxes\n",
    "        txt_path = lbl_dir / fn.replace(\".png\", \".txt\")\n",
    "        min_size = 3\n",
    "        full_image_threshold = 0.95  # percentage of area to reject\n",
    "\n",
    "        # Apply greedy suppression: remove boxes fully inside larger ones\n",
    "        def is_inside(inner, outer):\n",
    "            ix, iy, iw, ih = inner[:4]\n",
    "            ox, oy, ow, oh = outer[:4]\n",
    "            return (\n",
    "                abs(ix - ox) < 0.5 * (ow - iw) and\n",
    "                abs(iy - oy) < 0.5 * (oh - ih)\n",
    "            )\n",
    "        \n",
    "        edge_map = detect_edges(block_middle80)\n",
    "        all_boxes.extend(generate_yolo_boxes(edge_map, threshold=0.1))\n",
    "        all_boxes.sort(key=lambda b: b[4], reverse=True)  # sort by area\n",
    "        merged_boxes = merge_boxes(all_boxes, iou_thresh=0.1, proximity_thresh=0.05)\n",
    "        final_boxes = []\n",
    "        for box in merged_boxes:\n",
    "            if not any(is_inside(box, keep) for keep in final_boxes):\n",
    "                final_boxes.append(box)\n",
    "\n",
    "\n",
    "        # Write to YOLO format\n",
    "        with open(txt_path, \"w\") as ftxt:\n",
    "            for x_c, y_c, w_n, h_n, _ in final_boxes:\n",
    "                if w_n * h_n > full_image_threshold:\n",
    "                    continue\n",
    "                if w_n * w < min_size or h_n * h < min_size:\n",
    "                    continue\n",
    "                ftxt.write(f\"{class_id} {x_c:.6f} {y_c:.6f} {w_n:.6f} {h_n:.6f}\\n\")\n",
    "\n",
    "        if not final_boxes:\n",
    "            if txt_path.exists():\n",
    "                txt_path.unlink()\n",
    "            with open(lbl_dir / 'empty_labels.csv', 'a') as f:\n",
    "                f.write(f\"{fn},{h5_path},{ch_idx}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # —————————————————————————————\n",
    "        # 4) Draw boxes on the saved PNG\n",
    "        # —————————————————————————————\n",
    "        vis_img = Image.open(img_path).convert(\"RGB\")\n",
    "        draw    = ImageDraw.Draw(vis_img)\n",
    "        w_img, h_img = vis_img.size\n",
    "\n",
    "\n",
    "        if txt_path.exists():\n",
    "            with open(txt_path) as ftxt:\n",
    "                for line in ftxt:\n",
    "                    cls, x_c, y_c, bw, bh = map(float, line.split())\n",
    "                    xc = x_c * w_img\n",
    "                    yc = y_c * h_img\n",
    "                    bw_pix = bw * w_img\n",
    "                    bh_pix = bh * h_img\n",
    "                    x0 = int(xc - bw_pix/2)\n",
    "                    y0 = int(yc - bh_pix/2)\n",
    "                    x1 = int(xc + bw_pix/2)\n",
    "                    y1 = int(yc + bh_pix/2)\n",
    "                    draw.rectangle([x0, y0, x1, y1], outline=\"red\", width=2)\n",
    "\n",
    "        vis_img.save(vis_dir/fn)\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    # === your settings ===\n",
    "    BASE_DIR             = \"/datax/scratch/jliang/dataset_moe\"\n",
    "    FACTOR              = 6\n",
    "    DILATION = (30, 30)\n",
    "    CLASS_ID             = 0\n",
    "    TRAIN_FRAC           = 0.8\n",
    "    SEED                 = 42\n",
    "    NUM_WORKERS          = 2\n",
    "\n",
    "    # --- assume you already have a DataFrame `df` with at least 'h5_path' and optionally 'nchans' ---\n",
    "    # df = pd.read_csv(...)  # or however you built it\n",
    "\n",
    "    # 1) Build & split tasks\n",
    "    tasks = build_tasks(df)\n",
    "    train_set, val_set = split_tasks(tasks, TRAIN_FRAC, SEED)\n",
    "\n",
    "    # 2) compute zero-pad width from total images\n",
    "    pad_width = len(str(len(tasks) - 1))\n",
    "\n",
    "    # 3) regroup tasks by file to load each .h5 only once\n",
    "    jobs = {}\n",
    "    for gidx, (h5, ch) in enumerate(tasks):\n",
    "        jobs.setdefault(h5, {\"chs\": [], \"gidxs\": []})\n",
    "        jobs[h5][\"chs\"].append(ch)\n",
    "        jobs[h5][\"gidxs\"].append(gidx)\n",
    "\n",
    "    # 4) prepare job‐tuples\n",
    "    job_list = []\n",
    "    for h5, info in jobs.items():\n",
    "        job_list.append((\n",
    "            h5,\n",
    "            info[\"chs\"],\n",
    "            info[\"gidxs\"],\n",
    "            BASE_DIR,\n",
    "            FACTOR,\n",
    "            DILATION,\n",
    "            CLASS_ID,\n",
    "            train_set,\n",
    "            val_set,\n",
    "            pad_width\n",
    "        ))\n",
    "\n",
    "    # 5) run in parallel, one process per file\n",
    "    # with ProcessPoolExecutor(max_workers=NUM_WORKERS) as exe:\n",
    "    #     for _ in as_completed(exe.map(process_file, job_list)):\n",
    "    #         pass\n",
    "    train_images, train_sf_edges, train_ued_edges = extract_samples_parallel(df, max_samples=40000, num_workers=2)\n",
    "    # Load or train your MoE model here\n",
    "    model, scaler = train_gating_model(train_images, train_sf_edges, train_ued_edges)\n",
    "    if model is None:\n",
    "        logging.warning(\"Skipping inference because model wasn't trained.\")\n",
    "        exit()\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=NUM_WORKERS) as exe:\n",
    "        futures = [exe.submit(process_file, job + (model, scaler)) for job in job_list]\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "\n",
    "    logging.info(\"All done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
