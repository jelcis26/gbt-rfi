{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b1b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install bitshuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fe6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import blimpy as bl\n",
    "#from ultralytics import YOLO\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import psutil\n",
    "import scipy.ndimage\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea18f618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# # Load the image\n",
    "# image = cv2.imread('/home/jliang/gbt-rfi/example.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# # Print shape and number of channels\n",
    "# print(f\"Shape: {image.shape}\")\n",
    "\n",
    "# if len(image.shape) == 2:\n",
    "#     print(\"Image is grayscale (1 channel).\")\n",
    "# elif len(image.shape) == 3:\n",
    "#     print(f\"Image has {image.shape[2]} channels.\")\n",
    "# else:\n",
    "#     print(\"Unexpected image format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dba8ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/cgchoza/galaxies/complete_cadences_catalog.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d4e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_path = df['.h5 path'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730aa85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['.h5 path'] = df['.h5 path'].str.replace('0000.h5', '0002.h5', regex=False)\n",
    "df = df.drop_duplicates(subset='.h5 path', keep='first').reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b7592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['.h5 path'].str.contains('spliced')].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f651ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = df['.h5 path'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ce8eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fb_high = bl.Waterfall(high_path)\n",
    "# high_data = fb_high.data # shape: (279; 1; 65,536)\n",
    "# plt.imshow(10*np.log10(high_data).squeeze(), aspect='auto')\n",
    "# #plt.xlim(1250, 1251)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b37228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fb_mid = bl.Waterfall(path)\n",
    "# mid_data = fb_mid.data # shape: (279; 1; 65,536)\n",
    "# plt.imshow(10*np.log10(mid_data).squeeze(), aspect='auto')\n",
    "# plt.xlim(10000, 10003)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece7326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fb_mid = bl.Waterfall(path)\n",
    "# mid_data = fb_mid.data # shape: (279; 1; 65,536)\n",
    "# plt.imshow(10*np.log10(mid_data).squeeze(), aspect='auto')\n",
    "# plt.xlim(1250, 1251)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1451bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index = 17546)\n",
    "small_df = df.sample(n=100, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ca101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import blimpy as bl\n",
    "# import numpy as np\n",
    "# import scipy.ndimage\n",
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image, ImageDraw\n",
    "\n",
    "# factor = 7\n",
    "\n",
    "# def get_mask(path, factor=7):\n",
    "\n",
    "#     # Load data\n",
    "#     fb = bl.Waterfall(path, load_data=True)\n",
    "#     data = fb.data.squeeze()  # shape: (time, freq)\n",
    "#     data = 10*np.log10(data)\n",
    "\n",
    "#     # Mask = keep everything\n",
    "#     mask = np.ones_like(data, dtype=bool)\n",
    "\n",
    "#     # Stats from masked data\n",
    "#     # Define coarse channel width (depends on your setup; usually 1024 or 128)\n",
    "#     coarse_channel_width = 128  # change if needed\n",
    "#     num_coarse = data.shape[1] // coarse_channel_width\n",
    "\n",
    "#     # Mask out edge channels from each coarse block\n",
    "#     bad_channels = []\n",
    "#     for i in range(num_coarse):\n",
    "#         edge_bins = list(range(i * coarse_channel_width, i * coarse_channel_width + 5))  # 5-bin edge mask\n",
    "#         bad_channels.extend(edge_bins)\n",
    "\n",
    "#     # Apply masking\n",
    "#     data[:, bad_channels] = np.median(data)\n",
    "\n",
    "#     masked_values = data[mask]\n",
    "#     median = np.median(masked_values)\n",
    "#     std = np.std(masked_values)\n",
    "\n",
    "#     # Threshold to identify hits\n",
    "#     threshold = median + factor * std\n",
    "#     binary = data > threshold  # not mask\n",
    "#     # Merge nearby frequency hits (widen horizontally)\n",
    "#     # Fast dilation using a max filter (approximates dilation)\n",
    "#     binary = scipy.ndimage.maximum_filter(binary, size=(10, 300))\n",
    "\n",
    "\n",
    "#     # Label connected regions\n",
    "#     labeled, num_features = scipy.ndimage.label(binary)\n",
    "#     slices = scipy.ndimage.find_objects(labeled)\n",
    "\n",
    "#     # Set YOLO output image size\n",
    "#     target_w, target_h = 640, 640\n",
    "\n",
    "#     # Original image dimensions\n",
    "#     orig_h, orig_w = data.shape\n",
    "\n",
    "#     # Bounding boxes\n",
    "#     labels = []\n",
    "\n",
    "#     for sl in slices:\n",
    "#         t0, t1 = sl[0].start, sl[0].stop  # time axis\n",
    "#         f0, f1 = sl[1].start, sl[1].stop  # frequency axis\n",
    "\n",
    "#         # Rescale to resized image dimensions\n",
    "#         x_center = ((f0 + f1) / 2) * target_w / orig_w\n",
    "#         y_center = ((t0 + t1) / 2) * target_h / orig_h\n",
    "#         #h = 1.0         # full height\n",
    "#         w = (f1 - f0) * target_w / orig_w\n",
    "#         h = (t1 - t0) * target_h / orig_h\n",
    "\n",
    "#         # Normalize for YOLO format (0â€“1 range)\n",
    "#         x_center /= target_w\n",
    "#         y_center /= target_h\n",
    "#         w /= target_w\n",
    "#         h /= target_h\n",
    "\n",
    "#         labels.append(f\"0 {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\")\n",
    "\n",
    "\n",
    "#     # Save labels\n",
    "#     with open(\"example.txt\", \"w\") as f:\n",
    "#         f.write(\"\\n\".join(labels))\n",
    "\n",
    "#     # Save image from data\n",
    "#     img = (255 * (data - data.min()) / data.ptp()).astype(np.uint8)\n",
    "#     img = Image.fromarray(img)\n",
    "\n",
    "#     # Resize to YOLO-compatible shape (e.g., 640x640)\n",
    "#     img = img.resize((640, 640), Image.BICUBIC)\n",
    "#     img.save(f\"example_threshold{factor}.png\")\n",
    "\n",
    "# def draw_boxes(image_path, label_path):\n",
    "#     ## ----------- Visualization ------------##\n",
    "\n",
    "#     # Load image\n",
    "#     img = Image.open(image_path).convert(\"RGB\")\n",
    "#     draw = ImageDraw.Draw(img)\n",
    "#     w, h = img.size\n",
    "\n",
    "#     # Load and draw bounding boxes\n",
    "#     with open(label_path, \"r\") as f:\n",
    "#         for line in f:\n",
    "#             parts = line.strip().split()\n",
    "#             if len(parts) != 5:\n",
    "#                 continue  # skip malformed lines\n",
    "#             cls, x_center, y_center, box_w, box_h = map(float, parts)\n",
    "\n",
    "#             # Convert from normalized to pixel coordinates\n",
    "#             x_center *= w\n",
    "#             y_center *= h\n",
    "#             box_w *= w\n",
    "#             box_h *= h\n",
    "\n",
    "#             x0 = int(x_center - box_w / 2)\n",
    "#             y0 = int(y_center - box_h / 2)\n",
    "#             x1 = int(x_center + box_w / 2)\n",
    "#             y1 = int(y_center + box_h / 2)\n",
    "\n",
    "#             # Draw rectangle (red box)\n",
    "#             draw.rectangle([x0, y0, x1, y1], outline=\"red\", width=2)\n",
    "\n",
    "#     # Save or display the result\n",
    "#     img.save(f\"{image_path}_with_boxes.png\")\n",
    "#     img.show()\n",
    "\n",
    "# Optional visualization\n",
    "# plt.imshow(data.T, origin='lower', aspect='auto')\n",
    "# for sl in slices:\n",
    "#     t0, t1 = sl[0].start, sl[0].stop\n",
    "#     f0, f1 = sl[1].start, sl[1].stop\n",
    "#     plt.gca().add_patch(plt.Rectangle((t0, f0), t1 - t0, f1 - f0,\n",
    "#                                       edgecolor='red', facecolor='none', lw=1))\n",
    "# plt.title(\"Detected Hits\")\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22b9f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem_path = small_df['.h5 path'].iloc[692]\n",
    "# print(df[df['.h5 path'] == problem_path].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55026f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fb = bl.Waterfall(problem_path, load_data=True)\n",
    "# fb.plot_waterfall(cmap='viridis', figsize=(10, 5), title='Waterfall Plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e433b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_to_corners(xc, yc, w, h):\n",
    "    x0 = xc - w / 2\n",
    "    x1 = xc + w / 2\n",
    "    y0 = yc - h / 2\n",
    "    y1 = yc + h / 2\n",
    "    return x0, y0, x1, y1\n",
    "\n",
    "def is_inside(inner, outer, eps=1e-6):\n",
    "    ix0, iy0, ix1, iy1 = inner\n",
    "    ox0, oy0, ox1, oy1 = outer\n",
    "    return (ix0 >= ox0 - eps and iy0 >= oy0 - eps and\n",
    "            ix1 <= ox1 + eps and iy1 <= oy1 + eps)\n",
    "\n",
    "def filter_nested_boxes(yolo_labels):\n",
    "    parsed = []\n",
    "    for s in yolo_labels:\n",
    "        cls, xc, yc, w, h = map(float, s.strip().split())\n",
    "        corners = yolo_to_corners(xc, yc, w, h)\n",
    "        parsed.append((cls, xc, yc, w, h, corners))\n",
    "    keep = []\n",
    "    n = len(parsed)\n",
    "    for i, box in enumerate(parsed):\n",
    "        inner = box[5]\n",
    "        is_nested = False\n",
    "        for j, other in enumerate(parsed):\n",
    "            if i == j:\n",
    "                continue\n",
    "            outer = other[5]\n",
    "            if is_inside(inner, outer):\n",
    "                is_nested = True\n",
    "                break\n",
    "        if not is_nested:\n",
    "            keep.append(f\"{int(box[0])} {box[1]:.6f} {box[2]:.6f} {box[3]:.6f} {box[4]:.6f}\")\n",
    "    return keep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687f0a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split\n",
    "total_indices = list(range(len(small_df)))\n",
    "random.seed(42)\n",
    "random.shuffle(total_indices)\n",
    "\n",
    "split_idx = int(0.8 * len(total_indices))\n",
    "train_indices = set(total_indices[:split_idx])\n",
    "val_indices = set(total_indices[split_idx:])\n",
    "\n",
    "# Create all needed dirs\n",
    "base_dir = '/datax/scratch/jliang/masking_dataset_noresize'\n",
    "image_train_dir = os.path.join(base_dir, 'train/images')\n",
    "label_train_dir = os.path.join(base_dir, 'train/labels')\n",
    "image_val_dir = os.path.join(base_dir, 'val/images')\n",
    "label_val_dir = os.path.join(base_dir, 'val/labels')\n",
    "visualization_train_dir = os.path.join(base_dir, 'visualization/train')\n",
    "visualization_val_dir = os.path.join(base_dir, 'visualization/val')\n",
    "waterfall_train_dir = os.path.join(base_dir, 'waterfall/train')\n",
    "waterfall_val_dir = os.path.join(base_dir, 'waterfall/val')\n",
    "\n",
    "for d in [image_train_dir, label_train_dir, image_val_dir, label_val_dir]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Factor for thresholding\n",
    "factor = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ca5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def process_file(index, row, train_indices, base_dirs):\n",
    "    # Unpack base directories\n",
    "    image_train_dir, label_train_dir, image_val_dir, label_val_dir, visualization_train_dir, visualization_val_dir, waterfall_train_dir, waterfall_val_dir = base_dirs\n",
    "\n",
    "    # Choose correct folder based on split\n",
    "    if index in train_indices:\n",
    "        image_dir = image_train_dir\n",
    "        label_dir = label_train_dir\n",
    "        vis_dir = visualization_train_dir\n",
    "        w_dir = waterfall_train_dir\n",
    "    else:\n",
    "        image_dir = image_val_dir\n",
    "        label_dir = label_val_dir\n",
    "        vis_dir = visualization_val_dir\n",
    "        w_dir = waterfall_val_dir\n",
    "\n",
    "    h5_path = row['.h5 path']\n",
    "\n",
    "    try:\n",
    "        # Load data\n",
    "        fb = bl.Waterfall(h5_path, load_data=True)\n",
    "        data = fb.data.squeeze()  # shape: (time, freq)\n",
    "        data = 10 * np.log10(data)\n",
    "\n",
    "        # Mask = keep everything\n",
    "        mask = np.ones_like(data, dtype=bool)\n",
    "\n",
    "        # Stats from masked data\n",
    "        coarse_channel_width = 1024  # change if needed\n",
    "        num_coarse = data.shape[1] // coarse_channel_width\n",
    "\n",
    "        # Mask out edge channels from each coarse block\n",
    "        bad_channels = []\n",
    "        for i in range(num_coarse):\n",
    "            edge_bins = list(range(i * coarse_channel_width, i * coarse_channel_width + 5))  # 5-bin edge mask\n",
    "            bad_channels.extend(edge_bins)\n",
    "\n",
    "        # Apply masking\n",
    "        data[:, bad_channels] = np.median(data)\n",
    "\n",
    "        masked_values = data[mask]\n",
    "        median = np.median(masked_values)\n",
    "        std = np.std(masked_values)\n",
    "\n",
    "        # Threshold to identify hits\n",
    "        threshold = median + factor * std\n",
    "        binary = data > threshold  # not mask\n",
    "        binary = scipy.ndimage.maximum_filter(binary, size=(10, 300))\n",
    "\n",
    "        # Label connected regions\n",
    "        labeled, num_features = scipy.ndimage.label(binary)\n",
    "        slices = scipy.ndimage.find_objects(labeled)\n",
    "\n",
    "        orig_h, orig_w = data.shape\n",
    "\n",
    "        labels = []\n",
    "        for sl in slices:\n",
    "            t0, t1 = sl[0].start, sl[0].stop\n",
    "            f0, f1 = sl[1].start, sl[1].stop\n",
    "\n",
    "            # Use original coordinates (no scaling needed)\n",
    "            x_center = (f0 + f1) / 2 / orig_w\n",
    "            y_center = (t0 + t1) / 2 / orig_h\n",
    "            w = (f1 - f0) / orig_w\n",
    "            h = (t1 - t0) / orig_h\n",
    "\n",
    "            labels.append(f\"0 {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\")\n",
    "\n",
    "        labels = filter_nested_boxes(labels)\n",
    "\n",
    "        # Save labels\n",
    "        label_name = f'img_{index:05d}.txt'\n",
    "        label_path = os.path.join(label_dir, label_name)\n",
    "        with open(label_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(labels))\n",
    "\n",
    "        # Normalize to 8-bit grayscale\n",
    "        img = (255 * (data - data.min()) / data.ptp()).astype(np.uint8)\n",
    "        img = np.stack([img] * 3, axis=-1)  # shape: (H, W, 3)\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        # Save as 3-channel RGB PNG\n",
    "        img_name = f'img_{index:05d}.png'\n",
    "        out_path = os.path.join(image_dir, img_name)\n",
    "        img.save(out_path)\n",
    "\n",
    "        # Visualization\n",
    "        img = Image.open(out_path).convert(\"RGB\")\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        w, h = img.size\n",
    "\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    continue\n",
    "                cls, x_center, y_center, box_w, box_h = map(float, parts)\n",
    "                x_center *= w\n",
    "                y_center *= h\n",
    "                box_w *= w\n",
    "                box_h *= h\n",
    "                x0 = int(x_center - box_w / 2)\n",
    "                y0 = int(y_center - box_h / 2)\n",
    "                x1 = int(x_center + box_w / 2)\n",
    "                y1 = int(y_center + box_h / 2)\n",
    "                draw.rectangle([x0, y0, x1, y1], outline=\"red\", width=2)\n",
    "\n",
    "        vis_path = os.path.join(vis_dir, f\"img_{index:05d}.png\")\n",
    "        img.save(vis_path)\n",
    "\n",
    "        # Save waterfall plot\n",
    "        w_data = fb.data.squeeze()\n",
    "        w_data = 10 * np.log10(w_data)\n",
    "        w_name = f'img_{index:05d}.jpg'\n",
    "        w_path = os.path.join(w_dir, w_name)\n",
    "        plt.figure(figsize=(6.4, 6.4), dpi=100)\n",
    "        plt.imshow(w_data, aspect='auto', cmap='viridis')\n",
    "        plt.axis('off')\n",
    "        plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "        plt.savefig(w_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "\n",
    "        return index, None  # No error\n",
    "\n",
    "    except Exception as e:\n",
    "        return index, str(e)  # Return error message\n",
    "\n",
    "\n",
    "# Parallel processing\n",
    "if __name__ == \"__main__\":\n",
    "    num_workers = mp.cpu_count()  # Use all available CPUs\n",
    "    pool = mp.Pool(num_workers)\n",
    "\n",
    "    base_dirs = (\n",
    "        image_train_dir, label_train_dir, image_val_dir, label_val_dir,\n",
    "        visualization_train_dir, visualization_val_dir, waterfall_train_dir, waterfall_val_dir\n",
    "    )\n",
    "\n",
    "    results = pool.starmap(\n",
    "        process_file,\n",
    "        [(index, row, train_indices, base_dirs) for index, row in small_df.iterrows()]\n",
    "    )\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    # Handle results\n",
    "    for index, error in results:\n",
    "        if error:\n",
    "            print(f\"Error processing index {index}: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402e3354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shuffle and split\n",
    "# total_indices = list(range(len(small_df)))\n",
    "# random.seed(42)\n",
    "# random.shuffle(total_indices)\n",
    "\n",
    "# split_idx = int(0.8 * len(total_indices))\n",
    "# train_indices = set(total_indices[:split_idx])\n",
    "# val_indices = set(total_indices[split_idx:])\n",
    "\n",
    "# # Create all needed dirs\n",
    "# base_dir = '/datax/scratch/jliang/masking_dataset_noresize'\n",
    "# image_train_dir = os.path.join(base_dir, 'train/images')\n",
    "# label_train_dir = os.path.join(base_dir, 'train/labels')\n",
    "# image_val_dir = os.path.join(base_dir, 'val/images')\n",
    "# label_val_dir = os.path.join(base_dir, 'val/labels')\n",
    "# visualization_train_dir = os.path.join(base_dir, 'visualization/train')\n",
    "# visualization_val_dir = os.path.join(base_dir, 'visualization/val')\n",
    "# waterfall_train_dir = os.path.join(base_dir, 'waterfall/train')\n",
    "# waterfall_val_dir = os.path.join(base_dir, 'waterfall/val')\n",
    "\n",
    "# for d in [image_train_dir, label_train_dir, image_val_dir, label_val_dir]:\n",
    "#     os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# # Factor for thresholding\n",
    "# factor = 7\n",
    "\n",
    "# empty_label_count = 0\n",
    "# empty_label_names = []\n",
    "\n",
    "# for index in range(0, len(small_df)):\n",
    "#     # Wait for memory if needed\n",
    "#     mem_threshold = 20 * (1024 ** 3)  # 20 GB\n",
    "#     while psutil.virtual_memory().available < mem_threshold:\n",
    "#         print('Waiting for memory to free up...')\n",
    "#         time.sleep(180)\n",
    "\n",
    "#     # Choose correct folder based on split\n",
    "#     if index in train_indices:\n",
    "#         image_dir = image_train_dir\n",
    "#         label_dir = label_train_dir\n",
    "#     else:\n",
    "#         image_dir = image_val_dir\n",
    "#         label_dir = label_val_dir\n",
    "#     h5_path = small_df['.h5 path'].iloc[index]\n",
    "    \n",
    "#     # Load data\n",
    "#     fb = bl.Waterfall(h5_path, load_data=True)\n",
    "#     data = fb.data.squeeze()  # shape: (time, freq)\n",
    "#     data = 10*np.log10(data)\n",
    "\n",
    "#     # Mask = keep everything\n",
    "#     mask = np.ones_like(data, dtype=bool)\n",
    "\n",
    "#     # Stats from masked data\n",
    "#     # Define coarse channel width (depends on your setup; usually 1024 or 128)\n",
    "#     coarse_channel_width = 1024  # change if needed\n",
    "#     num_coarse = data.shape[1] // coarse_channel_width\n",
    "\n",
    "#     # Mask out edge channels from each coarse block\n",
    "#     bad_channels = []\n",
    "#     for i in range(num_coarse):\n",
    "#         edge_bins = list(range(i * coarse_channel_width, i * coarse_channel_width + 5))  # 5-bin edge mask\n",
    "#         bad_channels.extend(edge_bins)\n",
    "\n",
    "#     # Apply masking\n",
    "#     data[:, bad_channels] = np.median(data)\n",
    "\n",
    "#     masked_values = data[mask]\n",
    "#     median = np.median(masked_values)\n",
    "#     std = np.std(masked_values)\n",
    "\n",
    "#     # Threshold to identify hits\n",
    "#     threshold = median + factor * std\n",
    "#     binary = data > threshold  # not mask\n",
    "#     # Merge nearby frequency hits (widen horizontally)\n",
    "#     # Fast dilation using a max filter (approximates dilation)\n",
    "#     binary = scipy.ndimage.maximum_filter(binary, size=(10, 300))\n",
    "\n",
    "\n",
    "#     # Label connected regions\n",
    "#     labeled, num_features = scipy.ndimage.label(binary)\n",
    "#     slices = scipy.ndimage.find_objects(labeled)\n",
    "\n",
    "#     orig_h, orig_w = data.shape\n",
    "\n",
    "#     labels = []\n",
    "#     for sl in slices:\n",
    "#         t0, t1 = sl[0].start, sl[0].stop\n",
    "#         f0, f1 = sl[1].start, sl[1].stop\n",
    "\n",
    "#         # Use original coordinates (no scaling needed)\n",
    "#         x_center = (f0 + f1) / 2 / orig_w\n",
    "#         y_center = (t0 + t1) / 2 / orig_h\n",
    "#         w = (f1 - f0) / orig_w\n",
    "#         h = (t1 - t0) / orig_h\n",
    "\n",
    "#         labels.append(f\"0 {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\")\n",
    "\n",
    "#     labels = filter_nested_boxes(labels)\n",
    "\n",
    "\n",
    "#     # Save labels\n",
    "#     label_name = f'img_{index:05d}.txt'\n",
    "#     label_path = os.path.join(label_dir, label_name)\n",
    "#     with open(label_path, \"w\") as f:\n",
    "#         f.write(\"\\n\".join(labels))\n",
    "#     if len(labels) == 0:\n",
    "#         empty_label_count += 1\n",
    "#         empty_label_names.append(label_name)\n",
    "\n",
    "#      # Normalize to 8-bit grayscale\n",
    "#     img = (255 * (data - data.min()) / data.ptp()).astype(np.uint8)\n",
    "\n",
    "#     # Stack into 3 channels to simulate RGB\n",
    "#     img = np.stack([img] * 3, axis=-1)  # shape: (H, W, 3)\n",
    "\n",
    "#     # Convert to PIL image and resize\n",
    "#     img = Image.fromarray(img)\n",
    "\n",
    "#     # Save as 3-channel RGB PNG\n",
    "#     img_name = f'img_{index:05d}.png'\n",
    "#     out_path = os.path.join(image_dir, img_name)\n",
    "#     img.save(out_path)\n",
    "\n",
    "\n",
    "#     ## ----------- Visualization ------------##\n",
    "\n",
    "#     # Load image\n",
    "#     img = Image.open(out_path).convert(\"RGB\")\n",
    "#     draw = ImageDraw.Draw(img)\n",
    "#     w, h = img.size\n",
    "\n",
    "#     # Load and draw bounding boxes\n",
    "#     with open(label_path, \"r\") as f:\n",
    "#         for line in f:\n",
    "#             parts = line.strip().split()\n",
    "#             if len(parts) != 5:\n",
    "#                 continue  # skip malformed lines\n",
    "#             cls, x_center, y_center, box_w, box_h = map(float, parts)\n",
    "\n",
    "#             # Convert from normalized to pixel coordinates\n",
    "#             x_center *= w\n",
    "#             y_center *= h\n",
    "#             box_w *= w\n",
    "#             box_h *= h\n",
    "\n",
    "#             x0 = int(x_center - box_w / 2)\n",
    "#             y0 = int(y_center - box_h / 2)\n",
    "#             x1 = int(x_center + box_w / 2)\n",
    "#             y1 = int(y_center + box_h / 2)\n",
    "\n",
    "#             # Draw rectangle (red box)\n",
    "#             draw.rectangle([x0, y0, x1, y1], outline=\"red\", width=2)\n",
    "\n",
    "#     # Save or display the result\n",
    "#     vis_dir = visualization_train_dir if index in train_indices else visualization_val_dir\n",
    "#     os.makedirs(vis_dir, exist_ok=True)  # just in case\n",
    "#     vis_path = os.path.join(vis_dir, f\"img_{index:05d}.png\")\n",
    "#     img.save(vis_path)\n",
    "\n",
    "#     w_data = fb.data  # shape: (time, 1, freq)\n",
    "#     w_data = 10 * np.log10(w_data).squeeze()  # shape: (time, freq)\n",
    "\n",
    "#     # Set up save path\n",
    "#     w_name = f'img_{index:05d}.jpg'\n",
    "#     w_dir = waterfall_train_dir if index in train_indices else waterfall_val_dir\n",
    "#     os.makedirs(w_dir, exist_ok=True)\n",
    "#     w_path = os.path.join(w_dir, w_name)\n",
    "\n",
    "#     # Plot and save\n",
    "#     plt.figure(figsize=(6.4, 6.4), dpi=100)\n",
    "#     plt.imshow(w_data, aspect='auto', cmap='viridis')  # origin='lower' makes freq go up\n",
    "#     plt.axis('off')\n",
    "#     plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "#     plt.savefig(w_path, bbox_inches='tight', pad_inches=0)\n",
    "#     plt.close()\n",
    "\n",
    "#     print(\"Processed index:\", index)\n",
    "    \n",
    "# # Save summary of empty labels\n",
    "# txt_output_path = os.path.join(base_dir, \"empty_labels_summary.txt\")\n",
    "# with open(txt_output_path, \"w\") as txt_file:\n",
    "#     txt_file.write(f\"Total files with empty labels: {empty_label_count} out of {len(small_df)}\\n\\n\")\n",
    "#     txt_file.write(\"Empty label files:\\n\")\n",
    "#     for name in empty_label_names:\n",
    "#         txt_file.write(f\"- {name}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
