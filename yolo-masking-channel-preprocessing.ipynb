{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81b1b1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bitshuffle in /mnt_home/jliang/.local/lib/python3.7/site-packages (0.5.1)\n",
      "Requirement already satisfied: h5py>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from bitshuffle) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from bitshuffle) (1.20.3)\n",
      "Requirement already satisfied: setuptools>=0.7 in /opt/conda/lib/python3.7/site-packages (from bitshuffle) (62.3.2)\n",
      "Requirement already satisfied: Cython>=0.19 in /opt/conda/lib/python3.7/site-packages (from bitshuffle) (0.29.30)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py>=2.4.0->bitshuffle) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (7.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bitshuffle\n",
    "%pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fe6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import blimpy as bl\n",
    "#from ultralytics import YOLO\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import psutil\n",
    "import scipy.ndimage\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea18f618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# # Load the image\n",
    "# image = cv2.imread('/home/jliang/gbt-rfi/example.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# # Print shape and number of channels\n",
    "# print(f\"Shape: {image.shape}\")\n",
    "\n",
    "# if len(image.shape) == 2:\n",
    "#     print(\"Image is grayscale (1 channel).\")\n",
    "# elif len(image.shape) == 3:\n",
    "#     print(f\"Image has {image.shape[2]} channels.\")\n",
    "# else:\n",
    "#     print(\"Unexpected image format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dba8ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Session</th>\n",
       "      <th>Band</th>\n",
       "      <th>Cadence ID</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>.h5 path</th>\n",
       "      <th>.dat path</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36553</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36554</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36555</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36556</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36557</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36558 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Target          Session Band  Cadence ID  Frequency  \\\n",
       "0       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "1       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "2       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "3       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "4       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "...        ...              ...  ...         ...        ...   \n",
       "36553  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "36554  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "36555  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "36556  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "36557  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "\n",
       "                                                .h5 path  \\\n",
       "0      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "1      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "2      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "3      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "4      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "...                                                  ...   \n",
       "36553  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "36554  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "36555  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "36556  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "36557  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "\n",
       "                                               .dat path                 Time  \n",
       "0      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "1      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "2      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "3      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "4      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "...                                                  ...                  ...  \n",
       "36553  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "36554  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "36555  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "36556  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "36557  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "\n",
       "[36558 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/cgchoza/galaxies/complete_cadences_catalog.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d4e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_path = df['.h5 path'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "730aa85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Session</th>\n",
       "      <th>Band</th>\n",
       "      <th>Cadence ID</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>.h5 path</th>\n",
       "      <th>.dat path</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30309</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30310</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30311</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30312</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30313</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30314 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Target          Session Band  Cadence ID  Frequency  \\\n",
       "0       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "1       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "2       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "3       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "4       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "...        ...              ...  ...         ...        ...   \n",
       "30309  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "30310  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "30311  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "30312  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "30313  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "\n",
       "                                                .h5 path  \\\n",
       "0      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "1      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "2      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "3      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "4      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "...                                                  ...   \n",
       "30309  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "30310  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "30311  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "30312  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "30313  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "\n",
       "                                               .dat path                 Time  \n",
       "0      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "1      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "2      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "3      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "4      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "...                                                  ...                  ...  \n",
       "30309  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "30310  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "30311  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "30312  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "30313  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "\n",
       "[30314 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['.h5 path'] = df['.h5 path'].str.replace('0000.h5', '0002.h5', regex=False)\n",
    "df = df.drop_duplicates(subset='.h5 path', keep='first').reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38b7592b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Session</th>\n",
       "      <th>Band</th>\n",
       "      <th>Cadence ID</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>.h5 path</th>\n",
       "      <th>.dat path</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AND_XIV</td>\n",
       "      <td>AGBT18B_999_07</td>\n",
       "      <td>S</td>\n",
       "      <td>30225</td>\n",
       "      <td>3151</td>\n",
       "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
       "      <td>2018-08-18 08:41:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AND_XIV</td>\n",
       "      <td>AGBT18B_999_07</td>\n",
       "      <td>S</td>\n",
       "      <td>30225</td>\n",
       "      <td>3151</td>\n",
       "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
       "      <td>2018-08-18 08:41:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AND_XIV</td>\n",
       "      <td>AGBT18B_999_07</td>\n",
       "      <td>S</td>\n",
       "      <td>30225</td>\n",
       "      <td>3151</td>\n",
       "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
       "      <td>2018-08-18 08:41:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AND_XIV</td>\n",
       "      <td>AGBT18B_999_07</td>\n",
       "      <td>S</td>\n",
       "      <td>30225</td>\n",
       "      <td>3151</td>\n",
       "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
       "      <td>2018-08-18 08:41:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AND_XIV</td>\n",
       "      <td>AGBT18B_999_07</td>\n",
       "      <td>S</td>\n",
       "      <td>30225</td>\n",
       "      <td>3151</td>\n",
       "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
       "      <td>2018-08-18 08:41:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29341</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29342</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29343</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29344</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29345</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29346 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Target         Session Band  Cadence ID  Frequency  \\\n",
       "0      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
       "1      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
       "2      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
       "3      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
       "4      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
       "...        ...             ...  ...         ...        ...   \n",
       "29341  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
       "29342  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
       "29343  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
       "29344  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
       "29345  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
       "\n",
       "                                                .h5 path  \\\n",
       "0      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
       "1      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
       "2      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
       "3      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
       "4      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
       "...                                                  ...   \n",
       "29341  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "29342  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "29343  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "29344  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "29345  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "\n",
       "                                               .dat path                 Time  \n",
       "0      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
       "1      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
       "2      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
       "3      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
       "4      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
       "...                                                  ...                  ...  \n",
       "29341  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "29342  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "29343  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "29344  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "29345  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "\n",
       "[29346 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~df['.h5 path'].str.contains('spliced')].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f651ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = df['.h5 path'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0ce8eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fb_high = bl.Waterfall(high_path)\n",
    "# high_data = fb_high.data # shape: (279; 1; 65,536)\n",
    "# plt.imshow(10*np.log10(high_data).squeeze(), aspect='auto')\n",
    "# #plt.xlim(1250, 1251)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b37228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fb_mid = bl.Waterfall(path)\n",
    "# mid_data = fb_mid.data # shape: (279; 1; 65,536)\n",
    "# plt.imshow(10*np.log10(mid_data).squeeze(), aspect='auto')\n",
    "# plt.xlim(10000, 10003)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ece7326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fb_mid = bl.Waterfall(path)\n",
    "# mid_data = fb_mid.data # shape: (279; 1; 65,536)\n",
    "# plt.imshow(10*np.log10(mid_data).squeeze(), aspect='auto')\n",
    "# plt.xlim(1250, 1251)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1451bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index = 17546)\n",
    "df = df.sample(n=2000, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bf8c3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_scan_for_yolo(index, h5_path, base_dir,\n",
    "#                           coarse_channel_width=128,\n",
    "#                           factor=7,\n",
    "#                           dilation_size=(10,300),\n",
    "#                           class_id=0):\n",
    "#     \"\"\"\n",
    "#     For each coarse channel:\n",
    "#       - generate a PNG of the waterfall slice,\n",
    "#       - produce a .txt file of YOLO bboxes for each connected hit region.\n",
    "#     \"\"\"\n",
    "#     out_dir = Path(out_dir)\n",
    "#     img_dir = out_dir / \"images\"\n",
    "#     img_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     stem = Path(h5_path).stem\n",
    "\n",
    "#     # 1) load & log-scale\n",
    "#     fb   = bl.Waterfall(h5_path, load_data=True)\n",
    "#     data = 10 * np.log10(fb.data.squeeze())   # shape (ntime, nfreq)\n",
    "#     nt, nf = data.shape\n",
    "#     n_coarse = nf // coarse_channel_width\n",
    "\n",
    "#     # 2) global threshold\n",
    "#     m, s = np.median(data), np.std(data)\n",
    "#     binary = data > (m + factor * s)\n",
    "\n",
    "#     # 3) dilate to merge neighboring hits\n",
    "#     binary = scipy.ndimage.maximum_filter(binary, size=dilation_size)\n",
    "\n",
    "#     # 4) make directories\n",
    "#     img_tr = Path(base_dir)/\"train\"/\"images\"\n",
    "#     lbl_tr = Path(base_dir)/\"train\"/\"labels\"\n",
    "#     img_vl = Path(base_dir)/\"val\"/\"images\"\n",
    "#     lbl_vl = Path(base_dir)/\"val\"/\"labels\"\n",
    "#     for d in (img_tr, lbl_tr, img_vl, lbl_vl):\n",
    "#         d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     stem = Path(h5_path).stem\n",
    "\n",
    "#     # 4) per-block: find components, save image + YOLO .txt\n",
    "#     for i in range(n_coarse):\n",
    "#         f0, f1 = i * coarse_channel_width, (i + 1) * coarse_channel_width\n",
    "#         block = data[:, f0:f1]\n",
    "#         mask  = binary[:, f0:f1]\n",
    "\n",
    "#         # connected components\n",
    "#         labeled, n_objs = scipy.ndimage.label(mask)\n",
    "\n",
    "#         # 1) extract the slice\n",
    "#         block = data[:, f0:f1]   # shape: (ntime, coarse_channel_width)\n",
    "\n",
    "#         # 2) threshold & find connected components as before\n",
    "#         mask  = binary[:, f0:f1]\n",
    "#         labeled, n_objs = scipy.ndimage.label(mask)\n",
    "\n",
    "#         # 3) convert block to 8-bit RGB JPEG\n",
    "#         #    normalize just this block so it fills 0–255\n",
    "#         arr8 = (255 * (block - block.min()) / block.ptp()).astype(np.uint8)\n",
    "#         rgb  = np.stack([arr8]*3, axis=-1)        # (H, W, 3)\n",
    "#         img = Image.fromarray(rgb)\n",
    "#         img_name = f'img_{index:05d}.png'\n",
    "#         out_path = os.path.join(img_dir, img_name)\n",
    "#         img.save(out_path)\n",
    "\n",
    "\n",
    "#     # 4) write the matching .txt with the same basename\n",
    "#     txt_name = img_name.replace(\".png\", \".txt\")\n",
    "#     with open(img_dir / txt_name, \"w\") as ftxt:\n",
    "#         for lab in range(1, n_objs + 1):\n",
    "#             ys, xs = np.where(labeled == lab)\n",
    "#             y_min, y_max = ys.min(), ys.max()\n",
    "#             x_min, x_max = xs.min(), xs.max()\n",
    "#             # normalized YOLO coords\n",
    "#             x_c = ((x_min + x_max) / 2) / coarse_channel_width\n",
    "#             y_c = ((y_min + y_max) / 2) / nt\n",
    "#             w   = (x_max - x_min) / coarse_channel_width\n",
    "#             h   = (y_max - y_min) / nt\n",
    "#             ftxt.write(f\"{class_id} {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "\n",
    "\n",
    "#         # write YOLO .txt (one line per blob)\n",
    "#         txt_fn = img_dir / f\"{stem}_chan{i:03d}.txt\"\n",
    "#         with open(txt_fn, \"w\") as ftxt:\n",
    "#             for lab in range(1, n_objs + 1):\n",
    "#                 ys, xs = np.where(labeled == lab)\n",
    "#                 y_min, y_max = ys.min(), ys.max()\n",
    "#                 x_min, x_max = xs.min(), xs.max()\n",
    "\n",
    "#                 # normalized YOLO coords\n",
    "#                 x_c = ((x_min + x_max) / 2) / coarse_channel_width\n",
    "#                 y_c = ((y_min + y_max) / 2) / nt\n",
    "#                 w   = (x_max - x_min) / coarse_channel_width\n",
    "#                 h   = (y_max - y_min) / nt\n",
    "\n",
    "#                 ftxt.write(f\"0 {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84164fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- File Info ---\n",
      "DIMENSION_LABELS : [b'time' b'feed_id' b'frequency']\n",
      "        az_start :                              0.0\n",
      "       data_type :                                1\n",
      "            fch1 :               10501.46484375 MHz\n",
      "            foff :         -0.00286102294921875 MHz\n",
      "           ibeam :                               -1\n",
      "      machine_id :                               20\n",
      "          nbeams :                                1\n",
      "           nbits :                               32\n",
      "          nchans :                            65536\n",
      "            nifs :                                1\n",
      "     rawdatafile : guppi_59411_54386_HIP30264_0094.0000.raw\n",
      "     source_name :                         HIP30264\n",
      "         src_dej :                     -8:26:53.228\n",
      "         src_raj :                      6:21:58.451\n",
      "    telescope_id :                                6\n",
      "           tsamp :                1.073741823999999\n",
      "   tstart (ISOT) :          2021-07-16T15:06:26.000\n",
      "    tstart (MJD) :                59411.62946759259\n",
      "        za_start :                              0.0\n",
      "\n",
      "Num ints in file :                              279\n",
      "      File shape :                  (279, 1, 65536)\n",
      "--- Selection Info ---\n",
      "Data selection shape :                  (279, 1, 65536)\n",
      "Minimum freq (MHz) :                10313.96770477295\n",
      "Maximum freq (MHz) :                   10501.46484375\n"
     ]
    }
   ],
   "source": [
    "fb = bl.Waterfall(df['.h5 path'].iloc[-1], load_data=True)\n",
    "fb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50421249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) SET UP LOGGING\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "def build_tasks(df, coarse_channel_width):\n",
    "    \"\"\"\n",
    "    Build a flat list of (h5_path, channel_idx) from your DataFrame.\n",
    "    Uses df['nchans'] if present, otherwise reads header to find nfreq.\n",
    "    \"\"\"\n",
    "    tasks = []\n",
    "    for _, row in df.iterrows():\n",
    "        h5 = row[\".h5 path\"]\n",
    "        fb = bl.Waterfall(h5, load_data=False)\n",
    "        nfreq = fb.header.get(\"nchans\")\n",
    "        n_coarse = nfreq // coarse_channel_width\n",
    "\n",
    "        for ch in range(n_coarse):\n",
    "            tasks.append((h5, ch))\n",
    "    return tasks\n",
    "\n",
    "def split_tasks(tasks, train_frac=0.8, seed=42):\n",
    "    \"\"\"\n",
    "    Shuffle & split the flat task list into train vs. val sets.\n",
    "    Returns two sets of (h5_path, channel_idx).\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    shuffled = tasks.copy()\n",
    "    random.shuffle(shuffled)\n",
    "    cut = int(train_frac * len(shuffled))\n",
    "    train = set(shuffled[:cut])\n",
    "    val   = set(shuffled[cut:])\n",
    "    return train, val\n",
    "\n",
    "def process_file(job):\n",
    "    \"\"\"\n",
    "    job is a tuple:\n",
    "      (h5_path, [ch_idx,...], [global_idx,...],\n",
    "       base_dir, coarse_channel_width, factor, dilation_size,\n",
    "       class_id, train_set, val_set)\n",
    "    \"\"\"\n",
    "    (h5_path,\n",
    "     channels,\n",
    "     global_indices,\n",
    "     base_dir,\n",
    "     cw,\n",
    "     factor,\n",
    "     dilation,\n",
    "     class_id,\n",
    "     train_set,\n",
    "     val_set,\n",
    "     pad_width) = job\n",
    "\n",
    "    # 1) load the waterfall once\n",
    "    fb   = bl.Waterfall(h5_path, load_data=True)\n",
    "    data = 10 * np.log10(fb.data.squeeze())   # shape (ntime, nfreq)\n",
    "    nt, nf = data.shape\n",
    "\n",
    "    # 2) threshold + dilation\n",
    "    M, S = np.median(data), np.std(data)\n",
    "    binary = data > (M + factor * S)\n",
    "    binary = scipy.ndimage.maximum_filter(binary, size=dilation)\n",
    "\n",
    "    # 3) process each channel\n",
    "    for ch_idx, gidx in zip(channels, global_indices):\n",
    "        f0, f1 = ch_idx*cw, (ch_idx+1)*cw\n",
    "        block  = data[:, f0:f1]\n",
    "        mask   = binary[:, f0:f1]\n",
    "        edge_bins = 5\n",
    "        mask[:, :edge_bins] = False\n",
    "        mask[:, -edge_bins:] = False\n",
    "        labeled, n_objs = scipy.ndimage.label(mask)\n",
    "\n",
    "        # decide train vs val\n",
    "        subset = \"train\" if (h5_path, ch_idx) in train_set else \"val\"\n",
    "\n",
    "        # make sure all dirs exist\n",
    "        img_dir = Path(base_dir)/subset/\"images\"\n",
    "        lbl_dir = Path(base_dir)/subset/\"labels\"\n",
    "        vis_dir = Path(base_dir)/\"visualization\"/subset\n",
    "        wf_dir  = Path(base_dir)/\"waterfall\"/subset\n",
    "        for d in (img_dir, lbl_dir, vis_dir, wf_dir):\n",
    "            d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # 3a) save the channel PNG\n",
    "        arr8 = (255*(block - block.min())/block.ptp()).astype(np.uint8)\n",
    "        rgb  = np.stack([arr8]*3, axis=-1)\n",
    "        img  = Image.fromarray(rgb)\n",
    "        fn = f\"img_{gidx:0{pad_width}d}.png\"\n",
    "        img_path = img_dir/fn\n",
    "        img.save(img_path)\n",
    "\n",
    "        # 3b) save the YOLO .txt\n",
    "        txt_path = lbl_dir/fn.replace(\".png\", \".txt\")\n",
    "        with open(txt_path, \"w\") as ftxt:\n",
    "            for lab in range(1, n_objs + 1):\n",
    "                ys, xs = np.where(labeled == lab)\n",
    "\n",
    "                # pixel‐perfect extents (inclusive)\n",
    "                ymin, ymax = ys.min(), ys.max()\n",
    "                xmin, xmax = xs.min(), xs.max()\n",
    "\n",
    "                # width/height in pixels\n",
    "                w_pix = (xmax - xmin + 1)\n",
    "                h_pix = (ymax - ymin + 1)\n",
    "\n",
    "                # center in pixel coords\n",
    "                x_center_pix = xmin + w_pix / 2.0\n",
    "                y_center_pix = ymin + h_pix / 2.0\n",
    "\n",
    "                # normalize to [0,1] by true image dims\n",
    "                x_c = x_center_pix / float(cw)\n",
    "                y_c = y_center_pix / float(nt)\n",
    "                w_n = w_pix       / float(cw)\n",
    "                h_n = h_pix       / float(nt)\n",
    "\n",
    "                ftxt.write(f\"{class_id} \"\n",
    "                        f\"{x_c:.6f} {y_c:.6f} \"\n",
    "                        f\"{w_n:.6f} {h_n:.6f}\\n\")\n",
    "\n",
    "        logging.info(f\"[{subset}] {fn}  (ch {ch_idx} of {Path(h5_path).name})\")\n",
    "\n",
    "        # —————————————————————————————\n",
    "        # 4) Draw boxes on the saved PNG\n",
    "        # —————————————————————————————\n",
    "        vis_img = Image.open(img_path).convert(\"RGB\")\n",
    "        draw    = ImageDraw.Draw(vis_img)\n",
    "        w_img, h_img = vis_img.size\n",
    "\n",
    "        with open(txt_path) as ftxt:\n",
    "            for line in ftxt:\n",
    "                cls, x_c, y_c, bw, bh = map(float, line.split())\n",
    "                xc = x_c * w_img\n",
    "                yc = y_c * h_img\n",
    "                bw_pix = bw * w_img\n",
    "                bh_pix = bh * h_img\n",
    "                x0 = int(xc - bw_pix/2)\n",
    "                y0 = int(yc - bh_pix/2)\n",
    "                x1 = int(xc + bw_pix/2)\n",
    "                y1 = int(yc + bh_pix/2)\n",
    "                draw.rectangle([x0, y0, x1, y1], outline=\"red\", width=2)\n",
    "\n",
    "        vis_img.save(vis_dir/fn)\n",
    "\n",
    "        # —————————————————————————————\n",
    "        # 5) Plot and save the full waterfall \n",
    "        # —————————————————————————————\n",
    "        wf_name = f\"{Path(fn).stem}_wf.png\"\n",
    "        wf_path = wf_dir/wf_name\n",
    "\n",
    "        plt.imsave(\n",
    "            wf_path,\n",
    "            data,\n",
    "            origin=\"lower\",\n",
    "            cmap=\"viridis\"\n",
    "        )\n",
    "        logging.info(f\"[{subset}] {wf_name}  (ch {ch_idx} of {Path(h5_path).name})\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    # === your settings ===\n",
    "    BASE_DIR             = \"/datax/scratch/jliang/channel_masking_dataset\"\n",
    "    COARSE_CHANNEL_WIDTH = 512          # for BL MR files\n",
    "    FACTOR               = 7\n",
    "    DILATION_SIZE        = (3, 10)\n",
    "    CLASS_ID             = 0\n",
    "    TRAIN_FRAC           = 0.8\n",
    "    SEED                 = 42\n",
    "    NUM_WORKERS          = 8\n",
    "\n",
    "    # --- assume you already have a DataFrame `df` with at least 'h5_path' and optionally 'nchans' ---\n",
    "    # df = pd.read_csv(...)  # or however you built it\n",
    "\n",
    "    # 1) Build & split tasks\n",
    "    tasks = build_tasks(df, COARSE_CHANNEL_WIDTH)\n",
    "    train_set, val_set = split_tasks(tasks, TRAIN_FRAC, SEED)\n",
    "\n",
    "    # 2) compute zero-pad width from total images\n",
    "    pad_width = len(str(len(tasks) - 1))\n",
    "\n",
    "    # 3) regroup tasks by file to load each .h5 only once\n",
    "    jobs = {}\n",
    "    for gidx, (h5, ch) in enumerate(tasks):\n",
    "        jobs.setdefault(h5, {\"chs\": [], \"gidxs\": []})\n",
    "        jobs[h5][\"chs\"].append(ch)\n",
    "        jobs[h5][\"gidxs\"].append(gidx)\n",
    "\n",
    "    # 4) prepare job‐tuples\n",
    "    job_list = []\n",
    "    for h5, info in jobs.items():\n",
    "        job_list.append((\n",
    "            h5,\n",
    "            info[\"chs\"],\n",
    "            info[\"gidxs\"],\n",
    "            BASE_DIR,\n",
    "            COARSE_CHANNEL_WIDTH,\n",
    "            FACTOR,\n",
    "            DILATION_SIZE,\n",
    "            CLASS_ID,\n",
    "            train_set,\n",
    "            val_set,\n",
    "            pad_width\n",
    "        ))\n",
    "\n",
    "    # 5) run in parallel, one process per file\n",
    "    with ProcessPoolExecutor(max_workers=NUM_WORKERS) as exe:\n",
    "        for _ in as_completed(exe.map(process_file, job_list)):\n",
    "            pass\n",
    "\n",
    "    logging.info(\"All done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd1c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #------------------------------------------------------------------------------\n",
    "# # 1) The per-channel worker\n",
    "# #------------------------------------------------------------------------------\n",
    "# from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# def process_channel(h5_path, ch_idx, global_idx,\n",
    "#                     base_dir,\n",
    "#                     coarse_channel_width,\n",
    "#                     factor,\n",
    "#                     dilation_size,\n",
    "#                     class_id):\n",
    "#     \"\"\"\n",
    "#     Process one coarse channel of one H5\n",
    "#     \"\"\"\n",
    "#     # --- load & log-scale ---\n",
    "#     fb = bl.Waterfall(h5_path, load_data=True)\n",
    "#     data = 10 * np.log10(fb.data.squeeze())  # (ntime, nfreq)\n",
    "#     nt, nf = data.shape\n",
    "\n",
    "#     # --- threshold & dilate ---\n",
    "#     median, std = np.median(data), np.std(data)\n",
    "#     binary = data > (median + factor * std)\n",
    "#     binary = scipy.ndimage.maximum_filter(binary, size=dilation_size)\n",
    "\n",
    "#     # --- extract this channel ---\n",
    "#     f0, f1 = ch_idx*coarse_channel_width, (ch_idx+1)*coarse_channel_width\n",
    "#     block = data[:, f0:f1]\n",
    "#     mask = binary[:, f0:f1]\n",
    "\n",
    "#     # --- connected components to get bboxes ---\n",
    "#     labeled, n_objs = scipy.ndimage.label(mask)\n",
    "\n",
    "#     # --- pick train vs val by global_idx or ch_idx if you prefer ---\n",
    "#     # (example: 80% train by global index)\n",
    "#     n_total = int((nf//coarse_channel_width))\n",
    "#     # you can precompute a train_set instead of this if you like\n",
    "#     split_point = int(0.8 * n_total)\n",
    "#     is_train = (global_idx % n_total) < split_point  # or any rule you choose\n",
    "\n",
    "#     subset = \"train\" if is_train else \"val\"\n",
    "#     img_dir = Path(base_dir)/subset/\"images\"\n",
    "#     lbl_dir = Path(base_dir)/subset/\"labels\"\n",
    "#     img_dir.mkdir(parents=True, exist_ok=True)\n",
    "#     lbl_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     # --- save the PNG ---\n",
    "#     arr8 = (255*(block - block.min())/block.ptp()).astype(np.uint8)\n",
    "#     rgb = np.stack([arr8]*3, axis=-1)\n",
    "#     img = Image.fromarray(rgb)\n",
    "#     img_name = f\"img_{global_idx:04d}.png\"\n",
    "#     img.save(img_dir/img_name)\n",
    "\n",
    "#     # --- save the YOLO .txt ---\n",
    "#     with open(lbl_dir/img_name.replace(\".png\", \".txt\"), \"w\") as f:\n",
    "#         for lab in range(1, n_objs+1):\n",
    "#             ys, xs = np.where(labeled == lab)\n",
    "#             y0, y1 = ys.min(), ys.max()\n",
    "#             x0, x1 = xs.min(), xs.max()\n",
    "#             x_c = ((x0 + x1)/2) / coarse_channel_width\n",
    "#             y_c = ((y0 + y1)/2) / nt\n",
    "#             w = (x1 - x0) / coarse_channel_width\n",
    "#             h = (y1 - y0) / nt\n",
    "#             f.write(f\"{class_id} {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "\n",
    "#     return global_idx\n",
    "\n",
    "\n",
    "# #------------------------------------------------------------------------------\n",
    "# # 2) Build the flat task list\n",
    "# #------------------------------------------------------------------------------\n",
    "# def build_tasks(df, coarse_channel_width):\n",
    "#     \"\"\"\n",
    "#     From your DataFrame df with column 'h5_path',\n",
    "#     returns a list of (h5_path, channel_idx, global_idx).\n",
    "#     \"\"\"\n",
    "#     tasks = []\n",
    "#     idx_counter = 0\n",
    "\n",
    "#     for h5 in df['.h5 path']:\n",
    "#         fb = bl.Waterfall(h5, load_data=False)\n",
    "#         nchans = fb.header['data']['nchans']\n",
    "#         n_coarse = nchans // coarse_channel_width\n",
    "\n",
    "#         for ch in range(n_coarse):\n",
    "#             tasks.append((h5, ch, idx_counter))\n",
    "#             idx_counter += 1\n",
    "\n",
    "#     return tasks\n",
    "\n",
    "\n",
    "# #------------------------------------------------------------------------------#\n",
    "# # 3) Kick off the parallel loop\n",
    "# #------------------------------------------------------------------------------#\n",
    "# def main(df,\n",
    "#          base_dir,\n",
    "#          num_workers=8,\n",
    "#          coarse_channel_width=1024,\n",
    "#          factor=7,\n",
    "#          dilation_size=(10,300),\n",
    "#          class_id=0):\n",
    "#     # build tasks with global indices\n",
    "#     tasks = build_tasks(df, coarse_channel_width)\n",
    "\n",
    "#     # dispatch\n",
    "#     with ProcessPoolExecutor(max_workers=num_workers) as exe:\n",
    "#         futures = [\n",
    "#             exe.submit(\n",
    "#                 process_channel,\n",
    "#                 h5, ch, idx,\n",
    "#                 base_dir,\n",
    "#                 coarse_channel_width,\n",
    "#                 factor,\n",
    "#                 dilation_size,\n",
    "#                 class_id\n",
    "#             )\n",
    "#             for h5, ch, idx in tasks\n",
    "#         ]\n",
    "\n",
    "#         # progress\n",
    "#         for fut in as_completed(futures):\n",
    "#             idx = fut.result()\n",
    "#             print(f\"Done img_{idx:04d}.png\")\n",
    "\n",
    "\n",
    "# #------------------------------------------------------------------------------\n",
    "# # 4) Run it\n",
    "# #------------------------------------------------------------------------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     # assume your notebook already has `df` loaded\n",
    "#     BASE_DIR = \"/datax/scratch/jliang/channel_masking_dataset\"\n",
    "#     main(df,\n",
    "#          base_dir=BASE_DIR,\n",
    "#          num_workers=8,\n",
    "#          coarse_channel_width=1024,\n",
    "#          factor=7,\n",
    "#          dilation_size=(10,300),\n",
    "#          class_id=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9629af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ChannelMaskingDataset:\n",
    "#     def __init__(self,\n",
    "#                  base_dir,\n",
    "#                  coarse_channel_width=128,\n",
    "#                  factor=5,\n",
    "#                  dilation_size=(10,300),\n",
    "#                  class_id=0,\n",
    "#                  train_frac=0.8,\n",
    "#                  seed=42):\n",
    "#         \"\"\"\n",
    "#         base_dir/\n",
    "#           train/images, train/labels\n",
    "#           val/images,   val/labels\n",
    "#           visualization/train, visualization/val\n",
    "#           waterfall/train,     waterfall/val\n",
    "#         \"\"\"\n",
    "#         self.base_dir = Path(base_dir)\n",
    "#         self.cc_width = coarse_channel_width\n",
    "#         self.factor = factor\n",
    "#         self.dilation_size = dilation_size\n",
    "#         self.class_id = class_id\n",
    "#         self.train_frac = train_frac\n",
    "#         self.seed = seed\n",
    "\n",
    "#         # set up all dirs\n",
    "#         self.train_image_dir = self.base_dir/\"train\"/\"images\"\n",
    "#         self.train_label_dir = self.base_dir/\"train\"/\"labels\"\n",
    "#         self.val_image_dir = self.base_dir/\"val\"/\"images\"\n",
    "#         self.val_label_dir = self.base_dir/\"val\"/\"labels\"\n",
    "#         self.vis_train_dir = self.base_dir/\"visualization\"/\"train\"\n",
    "#         self.vis_val_dir = self.base_dir/\"visualization\"/\"val\"\n",
    "#         self.wf_train_dir = self.base_dir/\"waterfall\"/\"train\"\n",
    "#         self.wf_val_dir = self.base_dir/\"waterfall\"/\"val\"\n",
    "\n",
    "#         for d in (self.train_image_dir, self.train_label_dir,\n",
    "#                   self.val_image_dir, self.val_label_dir,\n",
    "#                   self.vis_train_dir, self.vis_val_dir,\n",
    "#                   self.wf_train_dir, self.wf_val_dir):\n",
    "#             d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     def process_scan(self, h5_path, visualize=False):\n",
    "#         fb = bl.Waterfall(h5_path, load_data=True)\n",
    "#         data = 10 * np.log10(fb.data.squeeze())      # (ntime, nfreq)\n",
    "#         nt, nf = data.shape\n",
    "#         n_coarse = nf // self.cc_width\n",
    "\n",
    "#         # threshold + dilation\n",
    "#         M, S = np.median(data), np.std(data)\n",
    "#         binary = data > (M + self.factor * S)\n",
    "#         binary = scipy.ndimage.maximum_filter(binary,\n",
    "#                                              size=self.dilation_size)\n",
    "\n",
    "#         # train/val split\n",
    "#         idxs = list(range(n_coarse))\n",
    "#         random.seed(self.seed)\n",
    "#         random.shuffle(idxs)\n",
    "#         cut = int(self.train_frac * n_coarse)\n",
    "#         train_set = set(idxs[:cut])\n",
    "#         val_set = set(idxs[cut:])\n",
    "\n",
    "#         stem = Path(h5_path).stem\n",
    "\n",
    "#         for i in range(n_coarse):\n",
    "#             # slice out channel\n",
    "#             f0, f1 = i*self.cc_width, (i+1)*self.cc_width\n",
    "#             block  = data[:, f0:f1]\n",
    "#             mask   = binary[:, f0:f1]\n",
    "\n",
    "#             # CC → YOLO bboxes\n",
    "#             labeled, n_objs = scipy.ndimage.label(mask)\n",
    "\n",
    "#             # pick train vs val\n",
    "#             if i in train_set:\n",
    "#                 img_dir = self.train_image_dir\n",
    "#                 lbl_dir = self.train_label_dir\n",
    "#             else:\n",
    "#                 img_dir = self.val_image_dir\n",
    "#                 lbl_dir = self.val_label_dir\n",
    "\n",
    "#             # --- save the channel PNG ---\n",
    "#             arr8 = (255*(block - block.min())/block.ptp()).astype(np.uint8)\n",
    "#             rgb  = np.stack([arr8]*3, axis=-1)\n",
    "#             img  = Image.fromarray(rgb)\n",
    "\n",
    "#             img_name = f\"{stem}_chan{i:05d}.png\"\n",
    "#             img_path = img_dir / img_name\n",
    "#             img.save(img_path)  # PNG by extension\n",
    "\n",
    "#             # --- save the YOLO .txt ---\n",
    "#             txt_path = lbl_dir / img_name.replace(\".png\", \".txt\")\n",
    "#             with open(txt_path, \"w\") as ftxt:\n",
    "#                 for lab in range(1, n_objs+1):\n",
    "#                     ys, xs = np.where(labeled == lab)\n",
    "#                     y0, y1 = ys.min(), ys.max()\n",
    "#                     x0, x1 = xs.min(), xs.max()\n",
    "\n",
    "#                     # normalized coords\n",
    "#                     x_c = ((x0 + x1)/2) / self.cc_width\n",
    "#                     y_c = ((y0 + y1)/2) / nt\n",
    "#                     w   = (x1 - x0)        / self.cc_width\n",
    "#                     h   = (y1 - y0)        / nt\n",
    "\n",
    "#                     ftxt.write(f\"{self.class_id} \"\n",
    "#                                f\"{x_c:.6f} {y_c:.6f} \"\n",
    "#                                f\"{w:.6f} {h:.6f}\\n\")\n",
    "\n",
    "#             if visualize:\n",
    "#                 self._visualize_channel(i, img_path, txt_path, fb, train_set)\n",
    "\n",
    "#     def _visualize_channel(self, i, img_path, txt_path, fb, train_set):\n",
    "#         # pick visualization dirs\n",
    "#         if i in train_set:\n",
    "#             vis_dir = self.vis_train_dir\n",
    "#             wf_dir  = self.wf_train_dir\n",
    "#         else:\n",
    "#             vis_dir = self.vis_val_dir\n",
    "#             wf_dir  = self.wf_val_dir\n",
    "\n",
    "#         # 1) draw boxes onto the saved PNG\n",
    "#         vis_dir.mkdir(parents=True, exist_ok=True)\n",
    "#         img = Image.open(img_path).convert(\"RGB\")\n",
    "#         draw = ImageDraw.Draw(img)\n",
    "#         w, h = img.size\n",
    "\n",
    "#         with open(txt_path) as f:\n",
    "#             for line in f:\n",
    "#                 cls, x_c, y_c, bw, bh = map(float, line.split())\n",
    "#                 xc = x_c * w\n",
    "#                 yc = y_c * h\n",
    "#                 bw *= w\n",
    "#                 bh *= h\n",
    "#                 x0 = int(xc - bw/2)\n",
    "#                 y0 = int(yc - bh/2)\n",
    "#                 x1 = int(xc + bw/2)\n",
    "#                 y1 = int(yc + bh/2)\n",
    "#                 draw.rectangle([x0, y0, x1, y1], outline=\"red\", width=2)\n",
    "\n",
    "#         out_vis = vis_dir / img_path.name\n",
    "#         img.save(out_vis)\n",
    "\n",
    "#         # 2) plot full waterfall\n",
    "#         wf_dir.mkdir(parents=True, exist_ok=True)\n",
    "#         w_data = 10*np.log10(fb.data.squeeze())  # full (ntime, nfreq)\n",
    "#         fig, ax = plt.subplots(figsize=(6.4,6.4), dpi=100)\n",
    "#         ax.imshow(w_data, aspect=\"auto\", origin=\"lower\", cmap=\"viridis\")\n",
    "#         ax.axis(\"off\")\n",
    "#         plt.subplots_adjust(left=0,right=1,top=1,bottom=0)\n",
    "#         wf_path = wf_dir / f\"{img_path.stem}_wf.png\"\n",
    "#         fig.savefig(wf_path, bbox_inches=\"tight\", pad_inches=0)\n",
    "#         plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ad489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processor = ChannelMaskingDataset(\n",
    "#     base_dir=\"/datax/scratch/jliang/channel_masking_dataset\",\n",
    "#     coarse_channel_width=128,\n",
    "#     factor=7,\n",
    "# )\n",
    "\n",
    "# # just build train/val + YOLO files\n",
    "# processor.process_scan(\"my_scan.h5\")\n",
    "\n",
    "# or also dump visualizations & waterfall plots\n",
    "# processor.process_scan(\"my_scan.h5\", visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527f1374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "# def process_one(h5_path, base_dir, **processor_kwargs):\n",
    "#     \"\"\"\n",
    "#     Wrapper so we can catch exceptions per-file and return status.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # initialize per-worker (cheap) \n",
    "#         processor = ChannelMaskingDataset(base_dir, **processor_kwargs)\n",
    "#         processor.process_scan(h5_path, visualize=False)\n",
    "#         return (h5_path, None)\n",
    "#     except Exception as e:\n",
    "#         return (h5_path, e)\n",
    "\n",
    "# def main(base_dir,\n",
    "#          num_workers=4,\n",
    "#          # pass any ChannelMaskingDataset args here:\n",
    "#          coarse_channel_width=128,\n",
    "#          factor=5,\n",
    "#          dilation_size=(10,300),\n",
    "#          class_id=0,\n",
    "#          train_frac=0.8,\n",
    "#          seed=42):\n",
    "\n",
    "#         # 1) extract your list of H5 paths from the DataFrame\n",
    "#         #    assume your df is called `df` and the column is \"h5_path\"\n",
    "#         h5_list = df[\".h5 path\"].astype(str).tolist()\n",
    "\n",
    "#         # 2) prepare shared kwargs for your processor\n",
    "#         processor_kwargs = {\n",
    "#             \"coarse_channel_width\": 128,\n",
    "#             \"factor\": 5,\n",
    "#             \"dilation_size\": (10,300),\n",
    "#             \"class_id\": 0,\n",
    "#             \"train_frac\": 0.8,\n",
    "#             \"seed\": 42,\n",
    "#         }\n",
    "\n",
    "#         # 3) launch parallel processing\n",
    "#         base_dir = \"/datax/scratch/jliang/channel_masking_dataset\"\n",
    "#         num_workers = 8  \n",
    "\n",
    "#         with ProcessPoolExecutor(max_workers=num_workers) as exe:\n",
    "#             # submit one task per H5\n",
    "#             futures = {\n",
    "#                 exe.submit(process_one, h5, base_dir, **processor_kwargs): h5\n",
    "#                 for h5 in h5_list\n",
    "#             }\n",
    "\n",
    "#             # collect results as they finish\n",
    "#             for fut in as_completed(futures):\n",
    "#                 h5_path, error = fut.result()\n",
    "#                 if error is None:\n",
    "#                     print(f\"{h5_path} done\")\n",
    "#                 else:\n",
    "#                     print(f\"{h5_path} failed:\", error)\n",
    "# if __name__ == \"__main__\":\n",
    "#     BASE_DIR = \"/datax/scratch/jliang/channel_masking_dataset\"\n",
    "#     main(BASE_DIR, num_workers=8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
