{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5171f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import blimpy as bl\n",
    "import psutil\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import shutil\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47d71d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/mnt_home/jliang/.local/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/mnt_home/jliang/.local/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (0.29.30)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/mnt_home/jliang/.local/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/mnt_home/jliang/.local/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/mnt_home/jliang/.local/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/mnt_home/jliang/.local/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/mnt_home/jliang/.local/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/mnt_home/jliang/.local/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting hdbscan\n",
      "  Using cached hdbscan-0.8.40.tar.gz (6.9 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[21 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-install-5pnzaeg_/hdbscan_07d48c47495d4108a61abed7c988ae7d/setup.py:10: UserWarning: /tmp/pip-build-env-c29dczkk/overlay/lib/python3.7/site-packages/Cython/Utils.cpython-37m-x86_64-linux-gnu.so: failed to map segment from shared object\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(e.args[0])\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-install-5pnzaeg_/hdbscan_07d48c47495d4108a61abed7c988ae7d/setup.py:97: UserWarning: Due to incompatibilities with Python 3.7 hdbscan nowrequires Cython to be installed in order to build it\n",
      "  \u001b[31m   \u001b[0m   warnings.warn('Due to incompatibilities with Python 3.7 hdbscan now'\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.7/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 363, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.7/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 345, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.7/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 130, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-c29dczkk/overlay/lib/python3.7/site-packages/setuptools/build_meta.py\", line 341, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return self._get_build_requires(config_settings, requirements=['wheel'])\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-c29dczkk/overlay/lib/python3.7/site-packages/setuptools/build_meta.py\", line 323, in _get_build_requires\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-c29dczkk/overlay/lib/python3.7/site-packages/setuptools/build_meta.py\", line 488, in run_setup\n",
      "  \u001b[31m   \u001b[0m     self).run_setup(setup_script=setup_script)\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-c29dczkk/overlay/lib/python3.7/site-packages/setuptools/build_meta.py\", line 338, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 99, in <module>\n",
      "  \u001b[31m   \u001b[0m ImportError: Cython not found! Please install cython and try again\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/mnt_home/jliang/.local/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/mnt_home/jliang/.local/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/mnt_home/jliang/.local/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hdbscan'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b7515d4a2bce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'install cython'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'install hdbscan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhdbscan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hdbscan'"
     ]
    }
   ],
   "source": [
    "%pip install cython\n",
    "%pip install hdbscan\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41e86e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Session</th>\n",
       "      <th>Band</th>\n",
       "      <th>Cadence ID</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>.h5 path</th>\n",
       "      <th>.dat path</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DDO210</td>\n",
       "      <td>AGBT18A_999_103</td>\n",
       "      <td>L</td>\n",
       "      <td>24777</td>\n",
       "      <td>2251</td>\n",
       "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
       "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
       "      <td>2018-07-07 08:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36553</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36554</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36555</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36556</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36557</th>\n",
       "      <td>NGC3226</td>\n",
       "      <td>AGBT22B_999_25</td>\n",
       "      <td>L</td>\n",
       "      <td>411390</td>\n",
       "      <td>1126</td>\n",
       "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
       "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
       "      <td>2022-11-19 06:13:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36558 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Target          Session Band  Cadence ID  Frequency  \\\n",
       "0       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "1       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "2       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "3       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "4       DDO210  AGBT18A_999_103    L       24777       2251   \n",
       "...        ...              ...  ...         ...        ...   \n",
       "36553  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "36554  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "36555  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "36556  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "36557  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
       "\n",
       "                                                .h5 path  \\\n",
       "0      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "1      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "2      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "3      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "4      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
       "...                                                  ...   \n",
       "36553  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "36554  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "36555  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "36556  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "36557  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
       "\n",
       "                                               .dat path                 Time  \n",
       "0      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "1      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "2      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "3      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "4      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
       "...                                                  ...                  ...  \n",
       "36553  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "36554  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "36555  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "36556  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "36557  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
       "\n",
       "[36558 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/cgchoza/galaxies/complete_cadences_catalog.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d1944a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/datax/scratch/jliang/high_data_dat'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_path = df['.dat path'].iloc[-1]\n",
    "dst_dir = '/datax/scratch/jliang/'\n",
    "dst_path = os.path.join(dst_dir, 'high_data_dat')  # Keeps original filename\n",
    "\n",
    "shutil.copy(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e41fe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 36557-36557, available memory: 83.50 GB\n",
      "Data shape: (16, 67108864) n_chunks: 22369\n",
      "Array shape: (22369, 16, 3000)\n",
      "Saved rows 36557-36557 -> /datax/scratch/jliang/high_data_array_rows_36557_36558.npy\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 3000\n",
    "group_size = 6\n",
    "n_rows = len(df)\n",
    "\n",
    "for batch_start in range(n_rows - 1, n_rows, group_size):\n",
    "    batch_end = min(batch_start + group_size, n_rows)\n",
    "    available = psutil.virtual_memory()[1]\n",
    "    print(f\"Processing rows {batch_start}-{batch_end-1}, available memory: {available/1e9:.2f} GB\")\n",
    "\n",
    "    batch_arrays = []\n",
    "    for idx in range(batch_start, batch_end):\n",
    "        # load the waterfall and get its frequency axis\n",
    "        fb = bl.Waterfall(df['.h5 path'].iloc[idx])\n",
    "        # header = fb.header\n",
    "        # n_freq = header['nchans']\n",
    "        # fch1 = header['fch1']     # freq of channel 0 in MHz\n",
    "        # foff = header['foff']     # channel spacing in MHz (often negative)\n",
    "        \n",
    "        # # build the full freq array and grab its min/max\n",
    "        # freqs = fch1 + np.arange(n_freq) * foff\n",
    "        # f_min, f_max = freqs.min(), freqs.max()\n",
    "\n",
    "        # # read hits table\n",
    "        # dat = df['.dat path'].iloc[idx]\n",
    "        # dat_df = pd.read_table(dat, sep='\\s+', names=[\n",
    "        #         'Top_Hit_#','Drift_Rate','SNR','Uncorrected_Frequency',\n",
    "        #         'Corrected_Frequency','Index','freq_start','freq_end',\n",
    "        #         'SEFD','SEFD_freq','Coarse_Channel_Number','Full_number_of_hits'\n",
    "        #     ],\n",
    "        #     skiprows=9\n",
    "        # )\n",
    "\n",
    "        # # set the RFI label if any hit overlaps the band\n",
    "        # overlap = ((dat_df['freq_start'] <= f_max) & (dat_df['freq_end'] >= f_min))\n",
    "        # df.at[idx, 'RFI_label'] = overlap.any()\n",
    "\n",
    "        data = np.squeeze(fb.data) # shape = (time, freq)\n",
    "        n_chunks = data.shape[1] // chunk_size\n",
    "        print('Data shape:', data.shape, 'n_chunks:', n_chunks)\n",
    "\n",
    "        # optional memory check\n",
    "        est_bytes = n_chunks * data.shape[0] * chunk_size * data.dtype.itemsize\n",
    "        if est_bytes > available * 0.9:\n",
    "            raise MemoryError(\n",
    "                f\"Row {idx} needs ~{est_bytes/1e9:.2f} GB but only {available/1e9:.2f} GB free\"\n",
    "            )\n",
    "\n",
    "        arr = np.array([\n",
    "            data[:, j*chunk_size:(j+1)*chunk_size]\n",
    "            for j in range(n_chunks)\n",
    "        ])  # shape = (n_chunks, freq, chunk_size)\n",
    "        batch_arrays.append(arr)\n",
    "        print(\"Array shape:\", arr.shape)\n",
    "\n",
    "    # ensure all batch_arrays have the same second‐dimension before stacking \n",
    "    times = [a.shape[1] for a in batch_arrays]\n",
    "    min_times = min(times)\n",
    "    if len(set(times)) > 1:\n",
    "        print(f\"Trimming each array from {times} chunks down to {min_times} chunks\")\n",
    "        batch_arrays = [a[:, :min_times, :] for a in batch_arrays]\n",
    "\n",
    "    # final memory check for the whole batch\n",
    "    total_bytes = sum(a.nbytes for a in batch_arrays)\n",
    "    available = psutil.virtual_memory()[1]\n",
    "    if total_bytes > available * 0.9:\n",
    "        raise MemoryError(\n",
    "            f\"Batch {batch_start}-{batch_end-1} needs ~{total_bytes/1e9:.2f} GB but only {available/1e9:.2f} GB free\"\n",
    "        )\n",
    "\n",
    "    batch_array = np.stack(batch_arrays, axis=0)\n",
    "    out_path    = f'/datax/scratch/jliang/high_data_array_rows_{batch_start}_{batch_end}.npy'\n",
    "    np.save(out_path, batch_array)\n",
    "    print(f\"Saved rows {batch_start}-{batch_end-1} -> {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c28c228e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc16_guppi_59902_24005_HIP50744_0057.rawspec.0002.h5\n",
      "/home/obs/turboseti/AGBT22B_999_25/blc16_blp06/blc16_guppi_59902_24005_HIP50744_0057.rawspec.0000/blc16_guppi_59902_24005_HIP50744_0057.rawspec.0000.dat\n"
     ]
    }
   ],
   "source": [
    "df['.h5 path'] = df['.h5 path'].str.replace('0000.h5', '0002.h5', regex=False)\n",
    "#df['.dat path'] = df['.dat path'].str.replace('0000.dat', '0002.dat', regex=False)\n",
    "print(df['.h5 path'].iloc[-1])\n",
    "print(df['.dat path'].iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8148712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat = df['.dat path'].iloc[-1]\n",
    "# print(dat)\n",
    "\n",
    "# dat_df = pd.read_table(dat, sep='\\s+', names=['Top_Hit_#','Drift_Rate','SNR','Uncorrected_Frequency','Corrected_Frequency',\n",
    "#                                                 'Index', 'freq_start', 'freq_end', 'SEFD', 'SEFD_freq', 'Coarse_Channel_Number', \n",
    "#                                                 'Full_number_of_hits'], skiprows=9)\n",
    "# dat_df.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ace2f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# snr = 10\n",
    "# outdir  = '/datax/scratch/jliang/'\n",
    "\n",
    "# # threshold of 20 GB in bytes\n",
    "# threshold = 20 * (1024 ** 3)\n",
    "# count = 0\n",
    "\n",
    "# for i, file in df['.h5 path'].items():\n",
    "#     while psutil.virtual_memory().available < threshold:\n",
    "#         print('Waiting for memory to free up…')\n",
    "#         time.sleep(60)\n",
    "\n",
    "#     # build a base name without its extension\n",
    "#     base = os.path.splitext(os.path.basename(file))[0]\n",
    "#     output_path = os.path.join(outdir, f\"{base}_{snr}_seticore.dat\")\n",
    "#     fb = bl.Waterfall(file, load_data=False)\n",
    "#     hdr = fb.header                # contains 'nchans'\n",
    "#     nch = hdr['nchans']\n",
    "#     if 'spliced' in file:\n",
    "#         nfpc = nch\n",
    "#     else:\n",
    "#         nfpc = nch / 64\n",
    "\n",
    "#     # run seticore\n",
    "#     console = 'seticore ' + file + ' -M 4 -s ' + str(snr) + ' --fine_channels ' + str(int(nfpc)) + ' --output ' + outdir + os.path.basename(file)[:-2] + str(snr) + '_seticore.dat'\n",
    "#     exit_code = os.system(console)\n",
    "#     if exit_code != 0:\n",
    "#         print(f\" Error: `seticore` returned non-zero exit code {exit_code} for file {file}\")\n",
    "#         sys.exit(exit_code)\n",
    "\n",
    "#     # safely assign into the DataFrame\n",
    "#     df.loc[i, '.dat path'] = output_path\n",
    "#     print(\"Wrote:\", output_path)\n",
    "\n",
    "#     dat_df = pd.read_table(output_path, sep='\\s+', names=['Top_Hit_#','Drift_Rate','SNR','Uncorrected_Frequency','Corrected_Frequency',\n",
    "#                                                 'Index', 'freq_start', 'freq_end', 'SEFD', 'SEFD_freq', 'Coarse_Channel_Number', \n",
    "#                                                 'Full_number_of_hits'], skiprows=9)\n",
    "#     df['Corrected_Frequency'] = dat_df['Corrected_Frequency']\n",
    "#     df['Drift_Rate'] = dat_df['Drift_Rate']\n",
    "#     df['SNR'] = dat_df['SNR']\n",
    "#     count += 1\n",
    "#     if count == 1000:\n",
    "#         break\n",
    "\n",
    "# # finally, save your CSV\n",
    "# df.to_csv('/datax/scratch/jliang/galaxies_cadences_small.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07da08ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 36557-36557, available memory: 88.28 GB\n",
      "Data shape: (279, 65536) n_chunks: 21\n",
      "Array shape: (21, 279, 3000)\n",
      "Saved rows 36557-36557 -> /datax/scratch/jliang/mid_data_array_rows_36557_36558.npy\n"
     ]
    }
   ],
   "source": [
    "#df['RFI_label'] = False\n",
    "chunk_size = 3000\n",
    "group_size = 6\n",
    "n_rows = len(df)\n",
    "\n",
    "for batch_start in range(n_rows - 1, n_rows, group_size):\n",
    "    batch_end = min(batch_start + group_size, n_rows)\n",
    "    available = psutil.virtual_memory()[1]\n",
    "    print(f\"Processing rows {batch_start}-{batch_end-1}, available memory: {available/1e9:.2f} GB\")\n",
    "\n",
    "    batch_arrays = []\n",
    "    for idx in range(batch_start, batch_end):\n",
    "        # load the waterfall and get its frequency axis\n",
    "        fb = bl.Waterfall(df['.h5 path'].iloc[idx])\n",
    "        # header = fb.header\n",
    "        # n_freq = header['nchans']\n",
    "        # fch1 = header['fch1']     # freq of channel 0 in MHz\n",
    "        # foff = header['foff']     # channel spacing in MHz (often negative)\n",
    "        \n",
    "        # # build the full freq array and grab its min/max\n",
    "        # freqs = fch1 + np.arange(n_freq) * foff\n",
    "        # f_min, f_max = freqs.min(), freqs.max()\n",
    "\n",
    "        # # read hits table\n",
    "        # dat = df['.dat path'].iloc[idx]\n",
    "        # dat_df = pd.read_table(dat, sep='\\s+', names=[\n",
    "        #         'Top_Hit_#','Drift_Rate','SNR','Uncorrected_Frequency',\n",
    "        #         'Corrected_Frequency','Index','freq_start','freq_end',\n",
    "        #         'SEFD','SEFD_freq','Coarse_Channel_Number','Full_number_of_hits'\n",
    "        #     ],\n",
    "        #     skiprows=9\n",
    "        # )\n",
    "\n",
    "        # # set the RFI label if any hit overlaps the band\n",
    "        # overlap = ((dat_df['freq_start'] <= f_max) & (dat_df['freq_end'] >= f_min))\n",
    "        # df.at[idx, 'RFI_label'] = overlap.any()\n",
    "\n",
    "        data = np.squeeze(fb.data) # shape = (time, freq)\n",
    "        n_chunks = data.shape[1] // chunk_size\n",
    "        print('Data shape:', data.shape, 'n_chunks:', n_chunks)\n",
    "\n",
    "        # optional memory check\n",
    "        est_bytes = n_chunks * data.shape[0] * chunk_size * data.dtype.itemsize\n",
    "        if est_bytes > available * 0.9:\n",
    "            raise MemoryError(\n",
    "                f\"Row {idx} needs ~{est_bytes/1e9:.2f} GB but only {available/1e9:.2f} GB free\"\n",
    "            )\n",
    "\n",
    "        arr = np.array([\n",
    "            data[:, j*chunk_size:(j+1)*chunk_size]\n",
    "            for j in range(n_chunks)\n",
    "        ])  # shape = (n_chunks, freq, chunk_size)\n",
    "        batch_arrays.append(arr)\n",
    "        print(\"Array shape:\", arr.shape)\n",
    "\n",
    "    # ensure all batch_arrays have the same second‐dimension before stacking \n",
    "    times = [a.shape[1] for a in batch_arrays]\n",
    "    min_times = min(times)\n",
    "    if len(set(times)) > 1:\n",
    "        print(f\"Trimming each array from {times} chunks down to {min_times} chunks\")\n",
    "        batch_arrays = [a[:, :min_times, :] for a in batch_arrays]\n",
    "\n",
    "    # final memory check for the whole batch\n",
    "    total_bytes = sum(a.nbytes for a in batch_arrays)\n",
    "    available = psutil.virtual_memory()[1]\n",
    "    if total_bytes > available * 0.9:\n",
    "        raise MemoryError(\n",
    "            f\"Batch {batch_start}-{batch_end-1} needs ~{total_bytes/1e9:.2f} GB but only {available/1e9:.2f} GB free\"\n",
    "        )\n",
    "\n",
    "    batch_array = np.stack(batch_arrays, axis=0)\n",
    "    out_path    = f'/datax/scratch/jliang/mid_data_array_rows_{batch_start}_{batch_end}.npy'\n",
    "    np.save(out_path, batch_array)\n",
    "    print(f\"Saved rows {batch_start}-{batch_end-1} -> {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b71ce315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 21, 279, 3000)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(batch_array.shape)\n",
    "print(batch_array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af465163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc16_guppi_59902_22416_NGC3226_0052.rawspec.0002.h5\n",
      "\n",
      "--- File Info ---\n",
      "DIMENSION_LABELS : [b'time' b'feed_id' b'frequency']\n",
      "        az_start :                              0.0\n",
      "       data_type :                                1\n",
      "            fch1 :                1126.46484375 MHz\n",
      "            foff :         -0.00286102294921875 MHz\n",
      "           ibeam :                                1\n",
      "      machine_id :                               20\n",
      "          nbeams :                                1\n",
      "           nbits :                               32\n",
      "          nchans :                            65536\n",
      "            nfpc :                             1024\n",
      "            nifs :                                1\n",
      "     rawdatafile : guppi_59902_22416_NGC3226_0052.0000.raw\n",
      "     source_name :                          NGC3226\n",
      "         src_dej :                      19:53:54.96\n",
      "         src_raj :                     10:23:26.952\n",
      "    telescope_id :                                6\n",
      "           tsamp :                1.073741823999999\n",
      "   tstart (ISOT) :          2022-11-19T06:13:36.000\n",
      "    tstart (MJD) :                59902.25944444445\n",
      "        za_start :                              0.0\n",
      "\n",
      "Num ints in file :                              279\n",
      "      File shape :                  (279, 1, 65536)\n",
      "--- Selection Info ---\n",
      "Data selection shape :                  (279, 1, 65536)\n",
      "Minimum freq (MHz) :                938.9677047729492\n",
      "Maximum freq (MHz) :                    1126.46484375\n"
     ]
    }
   ],
   "source": [
    "file = df['.h5 path'].values[36552]\n",
    "print(file)\n",
    "\n",
    "fb = bl.Waterfall(file)\n",
    "fb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ecf9803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- File Info ---\n",
      "DIMENSION_LABELS : [b'time' b'feed_id' b'frequency']\n",
      "        az_start :                              0.0\n",
      "       data_type :                                1\n",
      "            fch1 :            8438.963413238525 MHz\n",
      "            foff :         -0.00286102294921875 MHz\n",
      "      machine_id :                               20\n",
      "           nbits :                               32\n",
      "          nchans :                          1703936\n",
      "            nifs :                                1\n",
      "     source_name :                       Bol520_off\n",
      "         src_dej :                      34:54:57.96\n",
      "         src_raj :                        0:50:42.6\n",
      "    telescope_id :                                6\n",
      "           tsamp :               1.0737418239999998\n",
      "   tstart (ISOT) :          2018-03-08T16:41:30.000\n",
      "    tstart (MJD) :                58185.69548611111\n",
      "        za_start :                              0.0\n",
      "\n",
      "Num ints in file :                              547\n",
      "      File shape :                (547, 1, 1703936)\n",
      "--- Selection Info ---\n",
      "Data selection shape :                (547, 1, 1703936)\n",
      "Minimum freq (MHz) :               3563.9662742614746\n",
      "Maximum freq (MHz) :                8438.963413238525\n",
      "(547, 1, 1703936)\n"
     ]
    }
   ],
   "source": [
    "fb.info()\n",
    "fb_data = fb.data\n",
    "print(fb_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0048120f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
