{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81b1b1d6",
      "metadata": {
        "id": "81b1b1d6",
        "outputId": "0d3e4507-c77b-4deb-a263-9d5892ebba42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: bitshuffle in /mnt_home/jliang/.local/lib/python3.7/site-packages (0.5.1)\n",
            "Requirement already satisfied: h5py>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from bitshuffle) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from bitshuffle) (1.20.3)\n",
            "Requirement already satisfied: setuptools>=0.7 in /opt/conda/lib/python3.7/site-packages (from bitshuffle) (62.3.2)\n",
            "Requirement already satisfied: Cython>=0.19 in /opt/conda/lib/python3.7/site-packages (from bitshuffle) (0.29.30)\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py>=2.4.0->bitshuffle) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (7.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install bitshuffle\n",
        "%pip install Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2fe6857",
      "metadata": {
        "id": "a2fe6857"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import blimpy as bl\n",
        "#from ultralytics import YOLO\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "import psutil\n",
        "import scipy.ndimage\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "from pathlib import Path\n",
        "import logging\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "import cv2\n",
        "from scipy.ndimage import label as connected_components\n",
        "from skimage.filters import sobel\n",
        "from skimage.segmentation import slic\n",
        "from skimage.util import img_as_float\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from skimage.feature import canny, blob_log\n",
        "from skimage.transform import probabilistic_hough_line\n",
        "from skimage.filters import threshold_otsu\n",
        "from skimage.measure import label, regionprops\n",
        "from skimage.morphology import remove_small_objects\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dba8ef3",
      "metadata": {
        "id": "8dba8ef3",
        "outputId": "b46e3fc1-fdf5-40ae-b857-dfc2f9e0761c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>Session</th>\n",
              "      <th>Band</th>\n",
              "      <th>Cadence ID</th>\n",
              "      <th>Frequency</th>\n",
              "      <th>.h5 path</th>\n",
              "      <th>.dat path</th>\n",
              "      <th>Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DDO210</td>\n",
              "      <td>AGBT18A_999_103</td>\n",
              "      <td>L</td>\n",
              "      <td>24777</td>\n",
              "      <td>2251</td>\n",
              "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
              "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
              "      <td>2018-07-07 08:49:26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DDO210</td>\n",
              "      <td>AGBT18A_999_103</td>\n",
              "      <td>L</td>\n",
              "      <td>24777</td>\n",
              "      <td>2251</td>\n",
              "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
              "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
              "      <td>2018-07-07 08:49:26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DDO210</td>\n",
              "      <td>AGBT18A_999_103</td>\n",
              "      <td>L</td>\n",
              "      <td>24777</td>\n",
              "      <td>2251</td>\n",
              "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
              "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
              "      <td>2018-07-07 08:49:26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DDO210</td>\n",
              "      <td>AGBT18A_999_103</td>\n",
              "      <td>L</td>\n",
              "      <td>24777</td>\n",
              "      <td>2251</td>\n",
              "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
              "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
              "      <td>2018-07-07 08:49:26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DDO210</td>\n",
              "      <td>AGBT18A_999_103</td>\n",
              "      <td>L</td>\n",
              "      <td>24777</td>\n",
              "      <td>2251</td>\n",
              "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
              "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
              "      <td>2018-07-07 08:49:26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36553</th>\n",
              "      <td>NGC3226</td>\n",
              "      <td>AGBT22B_999_25</td>\n",
              "      <td>L</td>\n",
              "      <td>411390</td>\n",
              "      <td>1126</td>\n",
              "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
              "      <td>2022-11-19 06:13:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36554</th>\n",
              "      <td>NGC3226</td>\n",
              "      <td>AGBT22B_999_25</td>\n",
              "      <td>L</td>\n",
              "      <td>411390</td>\n",
              "      <td>1126</td>\n",
              "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
              "      <td>2022-11-19 06:13:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36555</th>\n",
              "      <td>NGC3226</td>\n",
              "      <td>AGBT22B_999_25</td>\n",
              "      <td>L</td>\n",
              "      <td>411390</td>\n",
              "      <td>1126</td>\n",
              "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
              "      <td>2022-11-19 06:13:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36556</th>\n",
              "      <td>NGC3226</td>\n",
              "      <td>AGBT22B_999_25</td>\n",
              "      <td>L</td>\n",
              "      <td>411390</td>\n",
              "      <td>1126</td>\n",
              "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
              "      <td>2022-11-19 06:13:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36557</th>\n",
              "      <td>NGC3226</td>\n",
              "      <td>AGBT22B_999_25</td>\n",
              "      <td>L</td>\n",
              "      <td>411390</td>\n",
              "      <td>1126</td>\n",
              "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
              "      <td>2022-11-19 06:13:36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36558 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Target          Session Band  Cadence ID  Frequency  \\\n",
              "0       DDO210  AGBT18A_999_103    L       24777       2251   \n",
              "1       DDO210  AGBT18A_999_103    L       24777       2251   \n",
              "2       DDO210  AGBT18A_999_103    L       24777       2251   \n",
              "3       DDO210  AGBT18A_999_103    L       24777       2251   \n",
              "4       DDO210  AGBT18A_999_103    L       24777       2251   \n",
              "...        ...              ...  ...         ...        ...   \n",
              "36553  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
              "36554  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
              "36555  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
              "36556  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
              "36557  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
              "\n",
              "                                                .h5 path  \\\n",
              "0      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
              "1      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
              "2      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
              "3      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
              "4      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
              "...                                                  ...   \n",
              "36553  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
              "36554  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
              "36555  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
              "36556  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
              "36557  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
              "\n",
              "                                               .dat path                 Time  \n",
              "0      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
              "1      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
              "2      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
              "3      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
              "4      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
              "...                                                  ...                  ...  \n",
              "36553  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
              "36554  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
              "36555  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
              "36556  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
              "36557  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
              "\n",
              "[36558 rows x 8 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('/home/cgchoza/galaxies/complete_cadences_catalog.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "730aa85b",
      "metadata": {
        "id": "730aa85b",
        "outputId": "005f9da5-d059-4a9a-a328-5bf99965c104"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>Session</th>\n",
              "      <th>Band</th>\n",
              "      <th>Cadence ID</th>\n",
              "      <th>Frequency</th>\n",
              "      <th>.h5 path</th>\n",
              "      <th>.dat path</th>\n",
              "      <th>Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DDO210</td>\n",
              "      <td>AGBT18A_999_103</td>\n",
              "      <td>L</td>\n",
              "      <td>24777</td>\n",
              "      <td>2251</td>\n",
              "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
              "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
              "      <td>2018-07-07 08:49:26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DDO210</td>\n",
              "      <td>AGBT18A_999_103</td>\n",
              "      <td>L</td>\n",
              "      <td>24777</td>\n",
              "      <td>2251</td>\n",
              "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
              "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
              "      <td>2018-07-07 08:49:26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DDO210</td>\n",
              "      <td>AGBT18A_999_103</td>\n",
              "      <td>L</td>\n",
              "      <td>24777</td>\n",
              "      <td>2251</td>\n",
              "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
              "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
              "      <td>2018-07-07 08:49:26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DDO210</td>\n",
              "      <td>AGBT18A_999_103</td>\n",
              "      <td>L</td>\n",
              "      <td>24777</td>\n",
              "      <td>2251</td>\n",
              "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
              "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
              "      <td>2018-07-07 08:49:26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DDO210</td>\n",
              "      <td>AGBT18A_999_103</td>\n",
              "      <td>L</td>\n",
              "      <td>24777</td>\n",
              "      <td>2251</td>\n",
              "      <td>/datag/pipeline/AGBT18A_999_103/collate/splice...</td>\n",
              "      <td>/home/obs/turboseti/AGBT18A_999_103/collate/sp...</td>\n",
              "      <td>2018-07-07 08:49:26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30309</th>\n",
              "      <td>NGC3226</td>\n",
              "      <td>AGBT22B_999_25</td>\n",
              "      <td>L</td>\n",
              "      <td>411390</td>\n",
              "      <td>1126</td>\n",
              "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
              "      <td>2022-11-19 06:13:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30310</th>\n",
              "      <td>NGC3226</td>\n",
              "      <td>AGBT22B_999_25</td>\n",
              "      <td>L</td>\n",
              "      <td>411390</td>\n",
              "      <td>1126</td>\n",
              "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
              "      <td>2022-11-19 06:13:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30311</th>\n",
              "      <td>NGC3226</td>\n",
              "      <td>AGBT22B_999_25</td>\n",
              "      <td>L</td>\n",
              "      <td>411390</td>\n",
              "      <td>1126</td>\n",
              "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
              "      <td>2022-11-19 06:13:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30312</th>\n",
              "      <td>NGC3226</td>\n",
              "      <td>AGBT22B_999_25</td>\n",
              "      <td>L</td>\n",
              "      <td>411390</td>\n",
              "      <td>1126</td>\n",
              "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
              "      <td>2022-11-19 06:13:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30313</th>\n",
              "      <td>NGC3226</td>\n",
              "      <td>AGBT22B_999_25</td>\n",
              "      <td>L</td>\n",
              "      <td>411390</td>\n",
              "      <td>1126</td>\n",
              "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
              "      <td>2022-11-19 06:13:36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30314 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Target          Session Band  Cadence ID  Frequency  \\\n",
              "0       DDO210  AGBT18A_999_103    L       24777       2251   \n",
              "1       DDO210  AGBT18A_999_103    L       24777       2251   \n",
              "2       DDO210  AGBT18A_999_103    L       24777       2251   \n",
              "3       DDO210  AGBT18A_999_103    L       24777       2251   \n",
              "4       DDO210  AGBT18A_999_103    L       24777       2251   \n",
              "...        ...              ...  ...         ...        ...   \n",
              "30309  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
              "30310  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
              "30311  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
              "30312  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
              "30313  NGC3226   AGBT22B_999_25    L      411390       1126   \n",
              "\n",
              "                                                .h5 path  \\\n",
              "0      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
              "1      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
              "2      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
              "3      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
              "4      /datag/pipeline/AGBT18A_999_103/collate/splice...   \n",
              "...                                                  ...   \n",
              "30309  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
              "30310  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
              "30311  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
              "30312  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
              "30313  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
              "\n",
              "                                               .dat path                 Time  \n",
              "0      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
              "1      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
              "2      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
              "3      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
              "4      /home/obs/turboseti/AGBT18A_999_103/collate/sp...  2018-07-07 08:49:26  \n",
              "...                                                  ...                  ...  \n",
              "30309  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
              "30310  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
              "30311  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
              "30312  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
              "30313  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
              "\n",
              "[30314 rows x 8 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['.h5 path'] = df['.h5 path'].str.replace('0000.h5', '0002.h5', regex=False)\n",
        "df = df.drop_duplicates(subset='.h5 path', keep='first').reset_index(drop=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38b7592b",
      "metadata": {
        "id": "38b7592b",
        "outputId": "71f3ee68-e74b-4fef-d7c2-4617a5679e15"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>Session</th>\n",
              "      <th>Band</th>\n",
              "      <th>Cadence ID</th>\n",
              "      <th>Frequency</th>\n",
              "      <th>.h5 path</th>\n",
              "      <th>.dat path</th>\n",
              "      <th>Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AND_XIV</td>\n",
              "      <td>AGBT18B_999_07</td>\n",
              "      <td>S</td>\n",
              "      <td>30225</td>\n",
              "      <td>3151</td>\n",
              "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
              "      <td>2018-08-18 08:41:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AND_XIV</td>\n",
              "      <td>AGBT18B_999_07</td>\n",
              "      <td>S</td>\n",
              "      <td>30225</td>\n",
              "      <td>3151</td>\n",
              "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
              "      <td>2018-08-18 08:41:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AND_XIV</td>\n",
              "      <td>AGBT18B_999_07</td>\n",
              "      <td>S</td>\n",
              "      <td>30225</td>\n",
              "      <td>3151</td>\n",
              "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
              "      <td>2018-08-18 08:41:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AND_XIV</td>\n",
              "      <td>AGBT18B_999_07</td>\n",
              "      <td>S</td>\n",
              "      <td>30225</td>\n",
              "      <td>3151</td>\n",
              "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
              "      <td>2018-08-18 08:41:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AND_XIV</td>\n",
              "      <td>AGBT18B_999_07</td>\n",
              "      <td>S</td>\n",
              "      <td>30225</td>\n",
              "      <td>3151</td>\n",
              "      <td>/datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT18B_999_07/blc40_blp00...</td>\n",
              "      <td>2018-08-18 08:41:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29341</th>\n",
              "      <td>NGC3226</td>\n",
              "      <td>AGBT22B_999_25</td>\n",
              "      <td>L</td>\n",
              "      <td>411390</td>\n",
              "      <td>1126</td>\n",
              "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
              "      <td>2022-11-19 06:13:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29342</th>\n",
              "      <td>NGC3226</td>\n",
              "      <td>AGBT22B_999_25</td>\n",
              "      <td>L</td>\n",
              "      <td>411390</td>\n",
              "      <td>1126</td>\n",
              "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
              "      <td>2022-11-19 06:13:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29343</th>\n",
              "      <td>NGC3226</td>\n",
              "      <td>AGBT22B_999_25</td>\n",
              "      <td>L</td>\n",
              "      <td>411390</td>\n",
              "      <td>1126</td>\n",
              "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
              "      <td>2022-11-19 06:13:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29344</th>\n",
              "      <td>NGC3226</td>\n",
              "      <td>AGBT22B_999_25</td>\n",
              "      <td>L</td>\n",
              "      <td>411390</td>\n",
              "      <td>1126</td>\n",
              "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
              "      <td>2022-11-19 06:13:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29345</th>\n",
              "      <td>NGC3226</td>\n",
              "      <td>AGBT22B_999_25</td>\n",
              "      <td>L</td>\n",
              "      <td>411390</td>\n",
              "      <td>1126</td>\n",
              "      <td>/datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...</td>\n",
              "      <td>/home/obs/turboseti/AGBT22B_999_25/blc16_blp06...</td>\n",
              "      <td>2022-11-19 06:13:36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29346 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Target         Session Band  Cadence ID  Frequency  \\\n",
              "0      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
              "1      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
              "2      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
              "3      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
              "4      AND_XIV  AGBT18B_999_07    S       30225       3151   \n",
              "...        ...             ...  ...         ...        ...   \n",
              "29341  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
              "29342  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
              "29343  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
              "29344  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
              "29345  NGC3226  AGBT22B_999_25    L      411390       1126   \n",
              "\n",
              "                                                .h5 path  \\\n",
              "0      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
              "1      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
              "2      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
              "3      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
              "4      /datag/pipeline/AGBT18B_999_07/blc40_blp00/blc...   \n",
              "...                                                  ...   \n",
              "29341  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
              "29342  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
              "29343  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
              "29344  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
              "29345  /datag/pipeline/AGBT22B_999_25/blc16_blp06/blc...   \n",
              "\n",
              "                                               .dat path                 Time  \n",
              "0      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
              "1      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
              "2      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
              "3      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
              "4      /home/obs/turboseti/AGBT18B_999_07/blc40_blp00...  2018-08-18 08:41:37  \n",
              "...                                                  ...                  ...  \n",
              "29341  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
              "29342  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
              "29343  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
              "29344  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
              "29345  /home/obs/turboseti/AGBT22B_999_25/blc16_blp06...  2022-11-19 06:13:36  \n",
              "\n",
              "[29346 rows x 8 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df[~df['.h5 path'].str.contains('spliced')].reset_index(drop=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f1451bd",
      "metadata": {
        "id": "2f1451bd"
      },
      "outputs": [],
      "source": [
        "df = df.drop(index = 17546)\n",
        "df = df.sample(n=1000, random_state=42).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84164fd0",
      "metadata": {
        "id": "84164fd0",
        "outputId": "c4cb4965-ba82-48ad-f7d3-6e505436744c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- File Info ---\n",
            "DIMENSION_LABELS : [b'time' b'feed_id' b'frequency']\n",
            "        az_start :                              0.0\n",
            "       data_type :                                1\n",
            "            fch1 :               10501.46484375 MHz\n",
            "            foff :         -0.00286102294921875 MHz\n",
            "           ibeam :                               -1\n",
            "      machine_id :                               20\n",
            "          nbeams :                                1\n",
            "           nbits :                               32\n",
            "          nchans :                            65536\n",
            "            nifs :                                1\n",
            "     rawdatafile : guppi_59411_54386_HIP30264_0094.0000.raw\n",
            "     source_name :                         HIP30264\n",
            "         src_dej :                     -8:26:53.228\n",
            "         src_raj :                      6:21:58.451\n",
            "    telescope_id :                                6\n",
            "           tsamp :                1.073741823999999\n",
            "   tstart (ISOT) :          2021-07-16T15:06:26.000\n",
            "    tstart (MJD) :                59411.62946759259\n",
            "        za_start :                              0.0\n",
            "\n",
            "Num ints in file :                              279\n",
            "      File shape :                  (279, 1, 65536)\n",
            "--- Selection Info ---\n",
            "Data selection shape :                  (279, 1, 65536)\n",
            "Minimum freq (MHz) :                10313.96770477295\n",
            "Maximum freq (MHz) :                   10501.46484375\n"
          ]
        }
      ],
      "source": [
        "fb = bl.Waterfall(df['.h5 path'].iloc[-1], load_data=True)\n",
        "fb.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "395191b3",
      "metadata": {
        "id": "395191b3"
      },
      "outputs": [],
      "source": [
        "def merge_boxes(boxes, iou_thresh=0.1, proximity_thresh=0.05):\n",
        "    \"\"\"\n",
        "    Merge boxes if their centers are close or they have significant IoU overlap.\n",
        "    boxes: list of (cx, cy, w, h, area)\n",
        "    returns: merged list of boxes\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    def iou(b1, b2):\n",
        "        x1_min = b1[0] - b1[2] / 2\n",
        "        x1_max = b1[0] + b1[2] / 2\n",
        "        y1_min = b1[1] - b1[3] / 2\n",
        "        y1_max = b1[1] + b1[3] / 2\n",
        "\n",
        "        x2_min = b2[0] - b2[2] / 2\n",
        "        x2_max = b2[0] + b2[2] / 2\n",
        "        y2_min = b2[1] - b2[3] / 2\n",
        "        y2_max = b2[1] + b2[3] / 2\n",
        "\n",
        "        inter_xmin = max(x1_min, x2_min)\n",
        "        inter_ymin = max(y1_min, y2_min)\n",
        "        inter_xmax = min(x1_max, x2_max)\n",
        "        inter_ymax = min(y1_max, y2_max)\n",
        "\n",
        "        inter_area = max(0, inter_xmax - inter_xmin) * max(0, inter_ymax - inter_ymin)\n",
        "        area1 = b1[2] * b1[3]\n",
        "        area2 = b2[2] * b2[3]\n",
        "        union = area1 + area2 - inter_area\n",
        "\n",
        "        return inter_area / union if union > 0 else 0\n",
        "\n",
        "    def distance(b1, b2):\n",
        "        return np.hypot(b1[0] - b2[0], b1[1] - b2[1])\n",
        "\n",
        "    merged = []\n",
        "    used = [False] * len(boxes)\n",
        "\n",
        "    for i, b1 in enumerate(boxes):\n",
        "        if used[i]:\n",
        "            continue\n",
        "        group = [b1]\n",
        "        used[i] = True\n",
        "        for j, b2 in enumerate(boxes):\n",
        "            if used[j]:\n",
        "                continue\n",
        "            if iou(b1, b2) > iou_thresh or distance(b1, b2) < proximity_thresh:\n",
        "                group.append(b2)\n",
        "                used[j] = True\n",
        "        if len(group) == 1:\n",
        "            merged.append(group[0])\n",
        "        else:\n",
        "            # merge into one big box (average center, min enclosing width/height)\n",
        "            xs = [b[0] for b in group]\n",
        "            ys = [b[1] for b in group]\n",
        "            ws = [b[2] for b in group]\n",
        "            hs = [b[3] for b in group]\n",
        "            xmins = [x - w/2 for x, w in zip(xs, ws)]\n",
        "            xmaxs = [x + w/2 for x, w in zip(xs, ws)]\n",
        "            ymins = [y - h/2 for y, h in zip(ys, hs)]\n",
        "            ymaxs = [y + h/2 for y, h in zip(ys, hs)]\n",
        "            new_x = (min(xmins) + max(xmaxs)) / 2\n",
        "            new_y = (min(ymins) + max(ymaxs)) / 2\n",
        "            new_w = max(xmaxs) - min(xmins)\n",
        "            new_h = max(ymaxs) - min(ymins)\n",
        "            merged.append((new_x, new_y, new_w, new_h, new_w * new_h))\n",
        "    return merged\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c822d4e5",
      "metadata": {
        "id": "c822d4e5"
      },
      "outputs": [],
      "source": [
        "# def edge_detection(gray, factor=6, dilation=(3, 3)):\n",
        "#         # STEP 1: apply power threshold to suppress background\n",
        "#         median = np.median(gray)\n",
        "#         mad = np.median(np.abs(gray - median))\n",
        "#         power_mask = gray > (median + factor * mad)\n",
        "\n",
        "#         # STEP 2: edge detection on filtered signal only\n",
        "#         grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "#         grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "#         magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
        "#         magnitude *= power_mask  # mask out noise\n",
        "#         magnitude = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "#         # STEP 3: binary threshold + dilation\n",
        "#         binary = magnitude > 50  # you can tune this\n",
        "#         binary = scipy.ndimage.binary_dilation(binary, structure=np.ones(dilation))\n",
        "#         labeled, n_objs = scipy.ndimage.label(binary)\n",
        "#         slices = scipy.ndimage.find_objects(labeled)\n",
        "#         return slices\n",
        "\n",
        "# EDGE_MODEL_PATH = '/home/jliang/gbt-rfi/model.yml.gz'\n",
        "# EDGE_DETECTOR = cv2.ximgproc.createStructuredEdgeDetection(EDGE_MODEL_PATH)\n",
        "\n",
        "# def detect_edges(spectrogram):\n",
        "#     img = (spectrogram - spectrogram.min()) / (spectrogram.ptp() + 1e-6)\n",
        "#     img_3ch = cv2.merge([img.astype(np.float32)] * 3)\n",
        "#     return EDGE_DETECTOR.detectEdges(img_3ch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06fea6ff",
      "metadata": {
        "id": "06fea6ff"
      },
      "outputs": [],
      "source": [
        "# def extract_one_sample(h5_path, ch):\n",
        "#     try:\n",
        "#         EDGE_DETECTOR = cv2.ximgproc.createStructuredEdgeDetection(edge_model_path)\n",
        "#         fb = bl.Waterfall(h5_path, load_data=True)\n",
        "#         data = 10 * np.log10(fb.data.squeeze())\n",
        "\n",
        "#         nfpc = fb.header.get(\"nfpc\", 1024)\n",
        "#         f0, f1 = ch * nfpc, (ch + 1) * nfpc\n",
        "#         block = data[:, f0:f1]\n",
        "\n",
        "#         n_cols = block.shape[1]\n",
        "#         low, high = int(0.1 * n_cols), int(0.9 * n_cols)\n",
        "#         block_middle80 = block[:, low:high]\n",
        "\n",
        "#         vert_means = block_middle80.mean(axis=0)\n",
        "#         center = np.argmax(vert_means)\n",
        "#         left_col, right_col = center - 1, center + 1\n",
        "#         if left_col >= 0 and right_col < block_middle80.shape[1]:\n",
        "#             block_middle80[:, center] = (block_middle80[:, left_col] + block_middle80[:, right_col]) / 2\n",
        "#         elif left_col >= 0:\n",
        "#             block_middle80[:, center] = block_middle80[:, left_col]\n",
        "#         elif right_col < block_middle80.shape[1]:\n",
        "#             block_middle80[:, center] = block_middle80[:, right_col]\n",
        "\n",
        "#         img_norm = (block_middle80 - block_middle80.min()) / (block_middle80.ptp() + 1e-6)\n",
        "#         img_rgb = cv2.merge([img_norm.astype(np.float32)] * 3)\n",
        "\n",
        "#         sf_edges = EDGE_DETECTOR.detectEdges(img_rgb)\n",
        "\n",
        "#         gray = (255 * img_norm).astype(np.uint8)\n",
        "#         grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "#         grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "#         magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
        "#         magnitude = cv2.normalize(magnitude, None, 0, 1, cv2.NORM_MINMAX)\n",
        "\n",
        "#         sf_mean = np.mean(sf_edges)\n",
        "#         ued_mean = np.mean(magnitude)\n",
        "\n",
        "#         if sf_mean + ued_mean < 0.005:  # threshold to skip empty or background-only blocks\n",
        "#             return None  # skip empty or background-only blocks\n",
        "\n",
        "\n",
        "#         return (img_rgb, sf_edges, magnitude)\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error processing {h5_path} ch {ch}: {e}\")\n",
        "#         return None\n",
        "\n",
        "# def extract_samples_parallel(df: pd.DataFrame, max_samples=500, num_workers=8):\n",
        "#     from random import shuffle\n",
        "\n",
        "#     all_tasks = []\n",
        "#     for _, row in df.iterrows():\n",
        "#         h5 = row[\".h5 path\"]\n",
        "#         fb = bl.Waterfall(h5, load_data=False)\n",
        "#         nfreq = fb.header.get(\"nchans\")\n",
        "#         nfpc = fb.header.get(\"nfpc\", 1024)\n",
        "#         for ch in range(nfreq // nfpc):\n",
        "#             all_tasks.append((h5, ch))\n",
        "\n",
        "#     shuffle(all_tasks)\n",
        "#     selected_tasks = all_tasks[:max_samples]\n",
        "\n",
        "#     train_images, train_sf_edges, train_ued_edges = [], [], []\n",
        "\n",
        "#     with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
        "#         futures = [executor.submit(extract_one_sample, h5, ch) for h5, ch in selected_tasks]\n",
        "#         for future in as_completed(futures):\n",
        "#             result = future.result()\n",
        "#             if result:\n",
        "#                 img_rgb, sf_edge, ued_edge = result\n",
        "#                 train_images.append(img_rgb)\n",
        "#                 train_sf_edges.append(sf_edge)\n",
        "#                 train_ued_edges.append(ued_edge)\n",
        "\n",
        "#     return train_images, train_sf_edges, train_ued_edges\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "muN55kyFiP98",
      "metadata": {
        "id": "muN55kyFiP98"
      },
      "outputs": [],
      "source": [
        "# 4) SET UP LOGGING\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        ")\n",
        "\n",
        "\n",
        "def build_tasks(df):\n",
        "    \"\"\"\n",
        "    Build a flat list of (h5_path, channel_idx) from your DataFrame.\n",
        "    \"\"\"\n",
        "    tasks = []\n",
        "    for _, row in df.iterrows():\n",
        "        h5 = row[\".h5 path\"]\n",
        "        fb = bl.Waterfall(h5, load_data=False)\n",
        "        nfreq = fb.header[\"nchans\"]\n",
        "        nfpc = fb.header.get(\"nfpc\", 1024)\n",
        "        n_coarse = nfreq // nfpc\n",
        "\n",
        "        for ch in range(n_coarse):\n",
        "            tasks.append((h5, ch))\n",
        "    return tasks\n",
        "\n",
        "\n",
        "def split_tasks(tasks, train_frac=0.8, seed=42):\n",
        "    \"\"\"\n",
        "    Shuffle & split the flat task list into train vs. val sets.\n",
        "    Returns two sets of (h5_path, channel_idx).\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    shuffled = tasks.copy()\n",
        "    random.shuffle(shuffled)\n",
        "    cut = int(train_frac * len(shuffled))\n",
        "    train = set(shuffled[:cut])\n",
        "    val = set(shuffled[cut:])\n",
        "    return train, val\n",
        "\n",
        "\n",
        "def generate_yolo_boxes(edge_map, threshold=0.1):\n",
        "    \"\"\"\n",
        "    Turn an edge map into YOLO‐style boxes + area.\n",
        "    \"\"\"\n",
        "    binary = (edge_map > threshold).astype(np.uint8)\n",
        "    # label connected components\n",
        "    labeled = label(binary)\n",
        "    boxes = []\n",
        "    for region in regionprops(labeled):\n",
        "        if region.area < 10:\n",
        "            continue\n",
        "        y0, x0, y1, x1 = region.bbox\n",
        "        cx = (x0 + x1) / 2 / edge_map.shape[1]\n",
        "        cy = (y0 + y1) / 2 / edge_map.shape[0]\n",
        "        w = (x1 - x0) / edge_map.shape[1]\n",
        "        h = (y1 - y0) / edge_map.shape[0]\n",
        "        boxes.append((cx, cy, w, h, w * h))\n",
        "    return boxes\n",
        "\n",
        "\n",
        "def is_inside(inner, outer):\n",
        "    \"\"\"\n",
        "    Return True if box `inner` lies (mostly) inside box `outer`.\n",
        "    Boxes are (cx, cy, w, h, area).\n",
        "    \"\"\"\n",
        "    ix, iy, iw, ih, _ = inner\n",
        "    ox, oy, ow, oh, _ = outer\n",
        "    return (\n",
        "        abs(ix - ox) < 0.5 * (ow - iw)\n",
        "        and abs(iy - oy) < 0.5 * (oh - ih)\n",
        "    )\n",
        "\n",
        "\n",
        "def process_file(job):\n",
        "    \"\"\"\n",
        "    job is a tuple of:\n",
        "      (h5_path, channels, global_indices,\n",
        "       base_dir, factor, dilation_size,\n",
        "       class_id, train_set, val_set,\n",
        "       pad_width, model, scaler)\n",
        "    \"\"\"\n",
        "    (\n",
        "        h5_path,\n",
        "        channels,\n",
        "        global_indices,\n",
        "        base_dir,\n",
        "        factor,\n",
        "        dilation_size,\n",
        "        class_id,\n",
        "        train_set,\n",
        "        val_set,\n",
        "        pad_width\n",
        "    ) = job\n",
        "\n",
        "    # load once per file\n",
        "    fb = bl.Waterfall(h5_path, load_data=True)\n",
        "    data = 10 * np.log10(fb.data.squeeze())  # (ntime, nfreq)\n",
        "\n",
        "    for ch_idx, gidx in zip(channels, global_indices):\n",
        "        # split train vs val\n",
        "        subset = \"train\" if (h5_path, ch_idx) in train_set else \"val\"\n",
        "\n",
        "        # setup directories\n",
        "        img_dir = Path(base_dir) / subset / \"images\"\n",
        "        lbl_dir = Path(base_dir) / subset / \"labels\"\n",
        "        vis_dir = Path(base_dir) / \"visualization\" / subset\n",
        "        for d in (img_dir, lbl_dir, vis_dir):\n",
        "            d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # extract the coarse channel block\n",
        "        cw = fb.header.get(\"nfpc\", 1024)\n",
        "        f0, f1 = ch_idx * cw, (ch_idx + 1) * cw\n",
        "        block = data[:, f0:f1]\n",
        "\n",
        "        # crop out the roll-off edges\n",
        "        n_cols = block.shape[1]\n",
        "        lo, hi = int(0.1 * n_cols), int(0.9 * n_cols)\n",
        "        block = block[:, lo:hi]\n",
        "\n",
        "        # remove a vertical artifact\n",
        "        means = block.mean(axis=0)\n",
        "        center = np.argmax(means)\n",
        "        L, R = center - 1, center + 1\n",
        "        if 0 <= L < n_cols and 0 <= R < n_cols:\n",
        "            block[:, center] = 0.5 * (block[:, L] + block[:, R])\n",
        "\n",
        "        # normalize for processing\n",
        "        norm = (block - block.min()) / (block.ptp() + 1e-6)\n",
        "\n",
        "        # —— DETECTION STEPS —— #\n",
        "        edges = canny(norm, sigma=2)\n",
        "        spec_norm = (norm - norm.min()) / (norm.ptp() + 1e-6)\n",
        "        th = threshold_otsu(norm)\n",
        "        mask = remove_small_objects(norm > th, min_size=100)\n",
        "\n",
        "        # run detectors\n",
        "        lines   = probabilistic_hough_line(edges, threshold=10, line_length=30, line_gap=3)\n",
        "        blobs   = blob_log(spec_norm, min_sigma=2, max_sigma=20, num_sigma=25, threshold=0.03, overlap=0.5)\n",
        "        regions = [r for r in regionprops(label(mask)) if r.area > 40]\n",
        "\n",
        "        # generate YOLO boxes\n",
        "        all_boxes = generate_yolo_boxes(edges, threshold=0.1)\n",
        "        all_boxes.sort(key=lambda b: b[4], reverse=True)\n",
        "        final_boxes = []\n",
        "        for box in all_boxes:\n",
        "            if not any(is_inside(box, kept) for kept in final_boxes):\n",
        "                final_boxes.append(box)\n",
        "\n",
        "        # —— SAVE IMAGE & LABELS —— #\n",
        "        # image filename\n",
        "        fn = f\"img_{gidx:0{pad_width}d}.png\"\n",
        "        img_path = img_dir / fn\n",
        "\n",
        "        # save greyscale block as RGB PNG\n",
        "        arr8 = (255 * norm).astype(np.uint8)\n",
        "        img = Image.fromarray(np.stack([arr8]*3, axis=-1))\n",
        "        img.save(img_path)\n",
        "\n",
        "        # save YOLO label file\n",
        "        txt_path = lbl_dir / fn.replace(\".png\", \".txt\")\n",
        "        if final_boxes:\n",
        "            with open(txt_path, \"w\") as fout:\n",
        "                for cx, cy, w, h, _ in final_boxes:\n",
        "                    if w * h < 0.95 and min(w, h) * block.shape[1] > 3:\n",
        "                        fout.write(f\"{class_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\\n\")\n",
        "        elif txt_path.exists():\n",
        "            txt_path.unlink()\n",
        "\n",
        "        # overlay and save visualization\n",
        "        vis = img.convert(\"RGB\")\n",
        "        draw = ImageDraw.Draw(vis)\n",
        "        for cx, cy, w, h, _ in final_boxes:\n",
        "            x0 = int((cx - w/2) * vis.width)\n",
        "            y0 = int((cy - h/2) * vis.height)\n",
        "            x1 = int((cx + w/2) * vis.width)\n",
        "            y1 = int((cy + h/2) * vis.height)\n",
        "            draw.rectangle([x0, y0, x1, y1], outline=\"red\", width=2)\n",
        "        vis.save(vis_dir / fn)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # your settings\n",
        "    BASE_DIR    = \"/datax/scratch/jliang/dataset_hough\"\n",
        "    FACTOR      = 6\n",
        "    DILATION    = (30, 30)\n",
        "    CLASS_ID    = 0\n",
        "    TRAIN_FRAC  = 0.8\n",
        "    SEED        = 42\n",
        "    NUM_WORKERS = 8\n",
        "\n",
        "    # build & split\n",
        "    tasks    = build_tasks(df)\n",
        "    train_set, val_set = split_tasks(tasks, TRAIN_FRAC, SEED)\n",
        "\n",
        "    # zero-pad width\n",
        "    pad_width = len(str(len(tasks)))\n",
        "\n",
        "    # group by file so we only open each .h5 once\n",
        "    jobs = {}\n",
        "    for gidx, (h5, ch) in enumerate(tasks):\n",
        "        jobs.setdefault(h5, {\"chs\": [], \"gidxs\": []})\n",
        "        jobs[h5][\"chs\"].append(ch)\n",
        "        jobs[h5][\"gidxs\"].append(gidx)\n",
        "\n",
        "    # prepare job tuples (we’ll append model & scaler below)\n",
        "    job_list = []\n",
        "    for h5, info in jobs.items():\n",
        "        job_list.append((\n",
        "            h5,\n",
        "            info[\"chs\"],\n",
        "            info[\"gidxs\"],\n",
        "            BASE_DIR,\n",
        "            FACTOR,\n",
        "            DILATION,\n",
        "            CLASS_ID,\n",
        "            train_set,\n",
        "            val_set,\n",
        "            pad_width\n",
        "        ))\n",
        "\n",
        "\n",
        "    \n",
        "    with ProcessPoolExecutor(max_workers=NUM_WORKERS) as exe:\n",
        "        futures = [exe.submit(process_file, job) for job in job_list]\n",
        "        for _ in as_completed(futures):\n",
        "            pass\n",
        "\n",
        "    logging.info(\"All done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50421249",
      "metadata": {
        "id": "50421249"
      },
      "outputs": [],
      "source": [
        "# # 4) SET UP LOGGING\n",
        "# logging.basicConfig(\n",
        "#     level=logging.INFO,\n",
        "#     format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "#     datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        "# )\n",
        "\n",
        "# def build_tasks(df):\n",
        "#     \"\"\"\n",
        "#     Build a flat list of (h5_path, channel_idx) from your DataFrame.\n",
        "#     Uses df['nchans'] if present, otherwise reads header to find nfreq.\n",
        "#     \"\"\"\n",
        "#     tasks = []\n",
        "#     for _, row in df.iterrows():\n",
        "#         h5 = row[\".h5 path\"]\n",
        "#         fb = bl.Waterfall(h5, load_data=False)\n",
        "#         nfreq = fb.header.get(\"nchans\")\n",
        "#         nfpc = fb.header.get(\"nfpc\", 1024)  # default to 1024 if not set\n",
        "#         n_coarse = nfreq // nfpc\n",
        "\n",
        "#         for ch in range(n_coarse):\n",
        "#             tasks.append((h5, ch))\n",
        "#     return tasks\n",
        "\n",
        "# def split_tasks(tasks, train_frac=0.8, seed=42):\n",
        "#     \"\"\"\n",
        "#     Shuffle & split the flat task list into train vs. val sets.\n",
        "#     Returns two sets of (h5_path, channel_idx).\n",
        "#     \"\"\"\n",
        "#     random.seed(seed)\n",
        "#     shuffled = tasks.copy()\n",
        "#     random.shuffle(shuffled)\n",
        "#     cut = int(train_frac * len(shuffled))\n",
        "#     train = set(shuffled[:cut])\n",
        "#     val   = set(shuffled[cut:])\n",
        "#     return train, val\n",
        "\n",
        "# def process_file(job):\n",
        "#     \"\"\"\n",
        "#     job is a tuple:\n",
        "#       (h5_path, [ch_idx,...], [global_idx,...],\n",
        "#        base_dir, coarse_channel_width, factor, dilation_size,\n",
        "#        class_id, train_set, val_set)\n",
        "#     \"\"\"\n",
        "#     (h5_path,\n",
        "#      channels,\n",
        "#      global_indices,\n",
        "#      base_dir,\n",
        "#      factor,\n",
        "#      dilation,\n",
        "#      class_id,\n",
        "#      train_set,\n",
        "#      val_set,\n",
        "#      pad_width,\n",
        "#      model,\n",
        "#      scalar) = job\n",
        "\n",
        "#     def generate_yolo_boxes(edge_map, threshold=0.1):\n",
        "#         binary = (edge_map > threshold).astype(np.uint8)\n",
        "#         labeled, n = connected_components(binary)\n",
        "#         boxes = []\n",
        "#         for i in range(1, n + 1):\n",
        "#             coords = np.argwhere(labeled == i)\n",
        "#             if coords.shape[0] < 10:\n",
        "#                 continue\n",
        "#             y0, x0 = coords.min(axis=0)\n",
        "#             y1, x1 = coords.max(axis=0)\n",
        "#             cx = (x0 + x1) / 2 / edge_map.shape[1]\n",
        "#             cy = (y0 + y1) / 2 / edge_map.shape[0]\n",
        "#             w = (x1 - x0) / edge_map.shape[1]\n",
        "#             h = (y1 - y0) / edge_map.shape[0]\n",
        "#             boxes.append((cx, cy, w, h, w * h))\n",
        "#         return boxes\n",
        "\n",
        "#     # 1) load the waterfall once\n",
        "#     fb   = bl.Waterfall(h5_path, load_data=True)\n",
        "#     data = 10 * np.log10(fb.data.squeeze())   # shape (ntime, nfreq)\n",
        "#     nt, nf = data.shape\n",
        "\n",
        "#     #  # 2) threshold + dilation\n",
        "#     # M, S = np.median(data), np.std(data)\n",
        "#     # binary = data > (M + factor * S)\n",
        "#     # binary = scipy.ndimage.maximum_filter(binary, size=dilation)\n",
        "\n",
        "#     # 3) process each channel\n",
        "#     for ch_idx, gidx in zip(channels, global_indices):\n",
        "#         cw = fb.header.get(\"nfpc\", 1024)  # default to 1024 if not set\n",
        "#         f0, f1 = ch_idx*cw, (ch_idx+1)*cw\n",
        "#         block  = data[:, f0:f1]\n",
        "\n",
        "#         # decide train vs val\n",
        "#         subset = \"train\" if (h5_path, ch_idx) in train_set else \"val\"\n",
        "\n",
        "#         # make sure all dirs exist\n",
        "#         img_dir = Path(base_dir)/subset/\"images\"\n",
        "#         lbl_dir = Path(base_dir)/subset/\"labels\"\n",
        "#         vis_dir = Path(base_dir)/\"visualization\"/subset\n",
        "#         for d in (img_dir, lbl_dir, vis_dir):\n",
        "#             d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "#         # Get rid of rolloff\n",
        "#         n_cols = block.shape[1]\n",
        "#         low = int(0.1 * n_cols)\n",
        "#         high = int(0.9 * n_cols)\n",
        "#         block_middle80 = block[:, low:high]\n",
        "\n",
        "#         # Remove vertical line artifact\n",
        "#         rows, cols = block_middle80.shape\n",
        "#         vert_means = block_middle80.mean(axis=0)\n",
        "#         center = np.argmax(vert_means)\n",
        "#         left_col = center - 1\n",
        "#         right_col = center + 1\n",
        "#         if left_col >= 0 and right_col < cols:\n",
        "#             block_middle80[:, center] = (block_middle80[:, left_col] + block_middle80[:, right_col]) / 2\n",
        "#         elif left_col >= 0:\n",
        "#             block_middle80[:, center] = block_middle80[:, left_col]\n",
        "#         elif right_col < cols:\n",
        "#             block_middle80[:, center] = block_middle80[:, right_col]\n",
        "\n",
        "#         # ====== NOW threshold and dilate on the CLEANED block ======\n",
        "#         #import scipy.ndimage\n",
        "\n",
        "#         # Normalize for visualization + processing\n",
        "#         arr8 = (255 * (block_middle80 - block_middle80.min()) / block_middle80.ptp()).astype(np.uint8)\n",
        "#         gray = arr8\n",
        "#         h, w = gray.shape\n",
        "\n",
        "#         # Normalize the image block\n",
        "#         img_norm = (block_middle80 - block_middle80.min()) / (block_middle80.ptp() + 1e-6)\n",
        "\n",
        "#         # Common precomputations\n",
        "#         # 1) Edge map for Hough & (if desired) for Generalized Hough\n",
        "#         edges = canny(img_norm, sigma=2)\n",
        "\n",
        "#         # 2) Normalized spec for LoG\n",
        "#         spec_norm = (img_norm - img_norm.min()) / img_norm.ptp()\n",
        "\n",
        "#         # 3) Mask for connected components\n",
        "#         thresh = threshold_otsu(img_norm)\n",
        "#         mask = img_norm > thresh\n",
        "#         mask = remove_small_objects(mask, min_size=100)\n",
        "\n",
        "#         # Define each detector as its own function\n",
        "#         def detect_lines(edges):\n",
        "#             return probabilistic_hough_line(\n",
        "#                 edges,\n",
        "#                 threshold=10,\n",
        "#                 line_length=50,\n",
        "#                 line_gap=3\n",
        "#             )\n",
        "\n",
        "#         def detect_blobs(spec_norm):\n",
        "#             # returns array of (y, x, sigma)\n",
        "#             return blob_log(\n",
        "#                 spec_norm,\n",
        "#                 min_sigma=2,\n",
        "#                 max_sigma=20,\n",
        "#                 num_sigma=10,\n",
        "#                 threshold=0.03\n",
        "#             )\n",
        "\n",
        "#         def detect_regions(mask):\n",
        "#             labels = label(mask)\n",
        "#             # filter out tiny regions\n",
        "#             return [r for r in regionprops(labels) if r.area > 200]\n",
        "\n",
        "#         # Run all three in parallel\n",
        "#         with ProcessPoolExecutor() as exe:\n",
        "#             future_lines   = exe.submit(detect_lines, edges)\n",
        "#             future_blobs   = exe.submit(detect_blobs, spec_norm)\n",
        "#             future_regions = exe.submit(detect_regions, mask)\n",
        "\n",
        "#             lines   = future_lines.result()\n",
        "#             blobs   = future_blobs.result()\n",
        "#             regions = future_regions.result()\n",
        "\n",
        "#         # Visualization (serial)\n",
        "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
        "#         ax.imshow(img_norm, cmap='gray', origin='lower')\n",
        "\n",
        "#         # overlay Hough lines in red\n",
        "#         for (x0, y0), (x1, y1) in lines:\n",
        "#             ax.plot((x0, x1), (y0, y1), '-r', linewidth=1)\n",
        "\n",
        "#         # overlay LoG blobs in yellow circles\n",
        "#         for y, x, sigma in blobs:\n",
        "#             circ = plt.Circle((x, y), sigma * np.sqrt(2),\n",
        "#                               edgecolor='yellow', facecolor='none', linewidth=1)\n",
        "#             ax.add_patch(circ)\n",
        "\n",
        "#         # overlay connected‐component boxes in lime\n",
        "#         for region in regions:\n",
        "#             minr, minc, maxr, maxc = region.bbox\n",
        "#             rect = plt.Rectangle((minc, minr),\n",
        "#                                 maxc - minc,\n",
        "#                                 maxr - minr,\n",
        "#                                 edgecolor='lime',\n",
        "#                                 facecolor='none',\n",
        "#                                 linewidth=1)\n",
        "#             ax.add_patch(rect)\n",
        "\n",
        "#         ax.set_axis_off()\n",
        "#         plt.tight_layout()\n",
        "#         plt.show()\n",
        "\n",
        "#         # Calculate frequency range of this coarse channel\n",
        "#         f_start = fb.header['fch1'] + f0 * fb.header['foff']\n",
        "#         f_stop  = fb.header['fch1'] + (f1 - 1) * fb.header['foff']\n",
        "\n",
        "#         # Prepare and save PNG\n",
        "#         arr8 = (255 * (block_middle80 - block_middle80.min()) / block_middle80.ptp()).astype(np.uint8)\n",
        "#         rgb = np.stack([arr8] * 3, axis=-1)\n",
        "#         img = Image.fromarray(rgb)\n",
        "#         fn = f\"img_{gidx:0{pad_width}d}_f_{f_start:.4f}_{f_stop:.4f}.png\"\n",
        "#         img_path = img_dir / fn\n",
        "#         img.save(img_path)\n",
        "\n",
        "#                 # Save YOLO boxes\n",
        "#         txt_path = lbl_dir / fn.replace(\".png\", \".txt\")\n",
        "#         min_size = 3\n",
        "#         full_image_threshold = 0.95  # percentage of area to reject\n",
        "\n",
        "#         # Apply greedy suppression: remove boxes fully inside larger ones\n",
        "#         def is_inside(inner, outer):\n",
        "#             ix, iy, iw, ih = inner[:4]\n",
        "#             ox, oy, ow, oh = outer[:4]\n",
        "#             return (\n",
        "#                 abs(ix - ox) < 0.5 * (ow - iw) and\n",
        "#                 abs(iy - oy) < 0.5 * (oh - ih)\n",
        "#             )\n",
        "\n",
        "#         edge_map = detect_edges(block_middle80)\n",
        "#         all_boxes.extend(generate_yolo_boxes(edge_map, threshold=0.1))\n",
        "#         all_boxes.sort(key=lambda b: b[4], reverse=True)  # sort by area\n",
        "#         merged_boxes = merge_boxes(all_boxes, iou_thresh=0.1, proximity_thresh=0.05)\n",
        "#         final_boxes = []\n",
        "#         for box in merged_boxes:\n",
        "#             if not any(is_inside(box, keep) for keep in final_boxes):\n",
        "#                 final_boxes.append(box)\n",
        "\n",
        "\n",
        "#         # Write to YOLO format\n",
        "#         with open(txt_path, \"w\") as ftxt:\n",
        "#             for x_c, y_c, w_n, h_n, _ in final_boxes:\n",
        "#                 if w_n * h_n > full_image_threshold:\n",
        "#                     continue\n",
        "#                 if w_n * w < min_size or h_n * h < min_size:\n",
        "#                     continue\n",
        "#                 ftxt.write(f\"{class_id} {x_c:.6f} {y_c:.6f} {w_n:.6f} {h_n:.6f}\\n\")\n",
        "\n",
        "#         if not final_boxes:\n",
        "#             if txt_path.exists():\n",
        "#                 txt_path.unlink()\n",
        "#             with open(lbl_dir / 'empty_labels.csv', 'a') as f:\n",
        "#                 f.write(f\"{fn},{h5_path},{ch_idx}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#         # —————————————————————————————\n",
        "#         # 4) Draw boxes on the saved PNG\n",
        "#         # —————————————————————————————\n",
        "#         vis_img = Image.open(img_path).convert(\"RGB\")\n",
        "#         draw    = ImageDraw.Draw(vis_img)\n",
        "#         w_img, h_img = vis_img.size\n",
        "\n",
        "\n",
        "#         if txt_path.exists():\n",
        "#             with open(txt_path) as ftxt:\n",
        "#                 for line in ftxt:\n",
        "#                     cls, x_c, y_c, bw, bh = map(float, line.split())\n",
        "#                     xc = x_c * w_img\n",
        "#                     yc = y_c * h_img\n",
        "#                     bw_pix = bw * w_img\n",
        "#                     bh_pix = bh * h_img\n",
        "#                     x0 = int(xc - bw_pix/2)\n",
        "#                     y0 = int(yc - bh_pix/2)\n",
        "#                     x1 = int(xc + bw_pix/2)\n",
        "#                     y1 = int(yc + bh_pix/2)\n",
        "#                     draw.rectangle([x0, y0, x1, y1], outline=\"red\", width=2)\n",
        "\n",
        "#         vis_img.save(vis_dir/fn)\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     # === your settings ===\n",
        "#     BASE_DIR             = \"/datax/scratch/jliang/dataset_moe\"\n",
        "#     FACTOR              = 6\n",
        "#     DILATION = (30, 30)\n",
        "#     CLASS_ID             = 0\n",
        "#     TRAIN_FRAC           = 0.8\n",
        "#     SEED                 = 42\n",
        "#     NUM_WORKERS          = 8\n",
        "\n",
        "#     # --- assume you already have a DataFrame `df` with at least 'h5_path' and optionally 'nchans' ---\n",
        "#     # df = pd.read_csv(...)  # or however you built it\n",
        "\n",
        "#     # 1) Build & split tasks\n",
        "#     tasks = build_tasks(df)\n",
        "#     train_set, val_set = split_tasks(tasks, TRAIN_FRAC, SEED)\n",
        "\n",
        "#     # 2) compute zero-pad width from total images\n",
        "#     pad_width = len(str(len(tasks) - 1))\n",
        "\n",
        "#     # 3) regroup tasks by file to load each .h5 only once\n",
        "#     jobs = {}\n",
        "#     for gidx, (h5, ch) in enumerate(tasks):\n",
        "#         jobs.setdefault(h5, {\"chs\": [], \"gidxs\": []})\n",
        "#         jobs[h5][\"chs\"].append(ch)\n",
        "#         jobs[h5][\"gidxs\"].append(gidx)\n",
        "\n",
        "#     # 4) prepare job‐tuples\n",
        "#     job_list = []\n",
        "#     for h5, info in jobs.items():\n",
        "#         job_list.append((\n",
        "#             h5,\n",
        "#             info[\"chs\"],\n",
        "#             info[\"gidxs\"],\n",
        "#             BASE_DIR,\n",
        "#             FACTOR,\n",
        "#             DILATION,\n",
        "#             CLASS_ID,\n",
        "#             train_set,\n",
        "#             val_set,\n",
        "#             pad_width\n",
        "#         ))\n",
        "\n",
        "#     # 5) run in parallel, one process per file\n",
        "#     # with ProcessPoolExecutor(max_workers=NUM_WORKERS) as exe:\n",
        "#     #     for _ in as_completed(exe.map(process_file, job_list)):\n",
        "#     #         pass\n",
        "#     train_images, train_sf_edges, train_ued_edges = extract_samples_parallel(df, max_samples=500, num_workers=8)\n",
        "#     # Load or train your MoE model here\n",
        "#     model, scaler = train_gating_model(train_images, train_sf_edges, train_ued_edges)\n",
        "\n",
        "#     with ProcessPoolExecutor(max_workers=NUM_WORKERS) as exe:\n",
        "#         futures = [exe.submit(process_file, job + (model, scaler)) for job in job_list]\n",
        "#         for future in as_completed(futures):\n",
        "#             result = future.result()\n",
        "\n",
        "#     logging.info(\"All done.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
