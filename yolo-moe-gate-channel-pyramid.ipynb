{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fd40639",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "# print(cv2.__version__)                # should be 4.8.0 or similar\n",
        "from cv2.ximgproc import createStructuredEdgeDetection\n",
        "# # sf_det = createStructuredEdgeDetection(EDGE_MODEL)  # should now work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81b1b1d6",
      "metadata": {
        "id": "81b1b1d6",
        "outputId": "c49a5694-57c3-431a-cb64-32661851a528"
      },
      "outputs": [],
      "source": [
        "%pip install bitshuffle\n",
        "%pip install Pillow\n",
        "%pip install scikit-image\n",
        "%pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2fe6857",
      "metadata": {
        "id": "a2fe6857"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import blimpy as bl\n",
        "#from ultralytics import YOLO\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "import psutil\n",
        "import scipy.ndimage\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "from pathlib import Path\n",
        "import logging\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "import cv2\n",
        "from scipy.ndimage import label as connected_components\n",
        "from skimage.filters import sobel\n",
        "from skimage.segmentation import slic\n",
        "from skimage.util import img_as_float\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "from skimage.util import img_as_float\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from skimage.segmentation import slic\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dba8ef3",
      "metadata": {
        "id": "8dba8ef3",
        "outputId": "afb83b76-0ae6-4e68-8c1d-42593d2d9e2a"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/home/cgchoza/galaxies/complete_cadences_catalog.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "730aa85b",
      "metadata": {
        "id": "730aa85b",
        "outputId": "67aee906-65d3-4e1e-bdb1-77408418462b"
      },
      "outputs": [],
      "source": [
        "df['.h5 path'] = df['.h5 path'].str.replace('0000.h5', '0002.h5', regex=False)\n",
        "df = df.drop_duplicates(subset='.h5 path', keep='first').reset_index(drop=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38b7592b",
      "metadata": {
        "id": "38b7592b",
        "outputId": "9914de53-3dfa-4a3a-d891-1752d649ade3"
      },
      "outputs": [],
      "source": [
        "df = df[~df['.h5 path'].str.contains('spliced')].reset_index(drop=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f1451bd",
      "metadata": {
        "id": "2f1451bd"
      },
      "outputs": [],
      "source": [
        "df = df.drop(index = 17546)\n",
        "#df = df[df['Band'] == 'L']\n",
        "# df = df.sample(n=1000, random_state=42).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6802a3bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import blimpy as bl\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "from tqdm import tqdm\n",
        "\n",
        "def scan_file_for_band(\n",
        "    h5_path: str,\n",
        "    band: str,\n",
        "    fmin: float,\n",
        "    fmax: float,\n",
        "    default_nfpc: int = 1024\n",
        "):\n",
        "    \"\"\"\n",
        "    Open one .h5, read header, return list of dicts for all channels\n",
        "    whose freq range lies in [fmin, fmax].\n",
        "    \"\"\"\n",
        "    records = []\n",
        "    fb = bl.Waterfall(h5_path, load_data=False)\n",
        "    hdr = fb.header\n",
        "\n",
        "    # skip if not the right band\n",
        "    # you could also pass row['Band'] in here if you like\n",
        "    # if row['Band'] != band: return []\n",
        "\n",
        "    fch1   = hdr['fch1']\n",
        "    foff   = hdr['foff']\n",
        "    nchans = hdr.get('nchans')\n",
        "    nfpc   = hdr.get('nfpc', default_nfpc)\n",
        "    n_coarse = nchans // nfpc\n",
        "\n",
        "    for ch in range(n_coarse):\n",
        "        f0 = ch * nfpc\n",
        "        f1 = (ch+1) * nfpc\n",
        "        f_start = fch1 + f0 * foff\n",
        "        f_stop  = fch1 + (f1-1) * foff\n",
        "        if (f_start <= fmax) and (f_stop >= fmin):\n",
        "            records.append({\n",
        "                '.h5 path': h5_path,\n",
        "                'channel':    ch,\n",
        "                'Band':       band,\n",
        "                'f_start':    f_start,\n",
        "                'f_stop':     f_stop\n",
        "            })\n",
        "\n",
        "    return records\n",
        "\n",
        "def parallel_filter_df(\n",
        "    df: pd.DataFrame,\n",
        "    band: str = \"L\",\n",
        "    fmin: float = 1500,\n",
        "    fmax: float = 1650,\n",
        "    max_workers: int = 8\n",
        ") -> pd.DataFrame:\n",
        "    # restrict to Band==L first to cut the task list down\n",
        "    df_band = df[df['Band'] == band]\n",
        "    paths   = df_band[\".h5 path\"].unique().tolist()\n",
        "\n",
        "    all_records = []\n",
        "    with ProcessPoolExecutor(max_workers=max_workers) as exe:\n",
        "        futures = {\n",
        "            exe.submit(scan_file_for_band, p, band, fmin, fmax): p\n",
        "            for p in paths\n",
        "        }\n",
        "        for fut in tqdm(as_completed(futures), total=len(futures),\n",
        "                        desc=f\"Scanning {band}-band files\"):\n",
        "            try:\n",
        "                recs = fut.result()\n",
        "                all_records.extend(recs)\n",
        "            except Exception as e:\n",
        "                h5 = futures[fut]\n",
        "                print(f\"Error on {h5}: {e!r}\")\n",
        "\n",
        "    return pd.DataFrame.from_records(all_records)\n",
        "\n",
        "# Usage:\n",
        "df = parallel_filter_df(df, band=\"L\", fmin=1500, fmax=1650, max_workers=2)\n",
        "print(f\"Kept {len(df)} channel entries in L-band 1500-1650 MHz\")\n",
        "df = df.sample(n=20, random_state=42).reset_index(drop=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84164fd0",
      "metadata": {
        "id": "84164fd0",
        "outputId": "1805d3f3-922d-48ec-8192-de3fd9753d90"
      },
      "outputs": [],
      "source": [
        "fb = bl.Waterfall(df['.h5 path'].iloc[-1], load_data=True)\n",
        "fb.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51b073aa",
      "metadata": {
        "id": "51b073aa"
      },
      "outputs": [],
      "source": [
        "import psutil\n",
        "import time\n",
        "\n",
        "def ensure_cpu_mem(bytes_needed, safety=0.8):\n",
        "    avail = psutil.virtual_memory().available\n",
        "    if bytes_needed > avail * safety:\n",
        "        time.sleep(120)\n",
        "\n",
        "def ensure_gpu_mem(bytes_needed, safety=0.8):\n",
        "    free, total = cp.cuda.runtime.memGetInfo()\n",
        "    if bytes_needed > free * safety:\n",
        "        time.sleep(120)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e069be5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def iou(box1, box2):\n",
        "    # box = (xc, yc, w, h) in normalized coords\n",
        "    x10 = box1[0] - box1[2]/2; x11 = box1[0] + box1[2]/2\n",
        "    y10 = box1[1] - box1[3]/2; y11 = box1[1] + box1[3]/2\n",
        "    x20 = box2[0] - box2[2]/2; x21 = box2[0] + box2[2]/2\n",
        "    y20 = box2[1] - box2[3]/2; y21 = box2[1] + box2[3]/2\n",
        "\n",
        "    xi0 = max(x10, x20);  yi0 = max(y10, y20)\n",
        "    xi1 = min(x11, x21);  yi1 = min(y11, y21)\n",
        "    inter_w = max(0, xi1 - xi0)\n",
        "    inter_h = max(0, yi1 - yi0)\n",
        "    inter = inter_w * inter_h\n",
        "\n",
        "    area1 = box1[2] * box1[3]\n",
        "    area2 = box2[2] * box2[3]\n",
        "    union = area1 + area2 - inter\n",
        "    return inter/union if union>0 else 0\n",
        "\n",
        "def non_max_suppression(boxes, scores=None, iou_thresh=0.3):\n",
        "    \"\"\"\n",
        "    boxes: list of (xc, yc, w, h)\n",
        "    scores: optional list of same length; if None we sort by box area (bigger first)\n",
        "    iou_thresh: IoU above which we suppress duplicates\n",
        "    \"\"\"\n",
        "    if len(boxes) == 0:\n",
        "        return []\n",
        "    if scores is None:\n",
        "        scores = [w*h for (_,_,w,h) in boxes]\n",
        "\n",
        "    # sort indices by descending score\n",
        "    idxs = np.argsort(scores)[::-1]\n",
        "    keep = []\n",
        "    for i in idxs:\n",
        "        b = boxes[i]\n",
        "        if all(iou(b, boxes[j]) < iou_thresh for j in keep):\n",
        "            keep.append(i)\n",
        "    return [boxes[i] for i in keep]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb678c08",
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_nested_boxes(boxes, scores):\n",
        "    \"\"\"\n",
        "    Drop any box that fully contains another, choosing the higher‐score box\n",
        "    when deciding which to keep. Returns (boxes_kept, scores_kept).\n",
        "    \"\"\"\n",
        "    def to_corners(b):\n",
        "        xc, yc, w, h = b\n",
        "        x0, x1 = xc - w/2, xc + w/2\n",
        "        y0, y1 = yc - h/2, yc + h/2\n",
        "        return x0, y0, x1, y1\n",
        "\n",
        "    corners = [to_corners(b) for b in boxes]\n",
        "    keep = [True]*len(boxes)\n",
        "\n",
        "    for i in range(len(boxes)):\n",
        "        if not keep[i]:\n",
        "            continue\n",
        "        x0_i,y0_i,x1_i,y1_i = corners[i]\n",
        "        for j in range(len(boxes)):\n",
        "            if i==j or not keep[j]:\n",
        "                continue\n",
        "            x0_j,y0_j,x1_j,y1_j = corners[j]\n",
        "            # if box i fully contains box j\n",
        "            if x0_i <= x0_j and x1_i >= x1_j and y0_i <= y0_j and y1_i >= y1_j:\n",
        "                # keep only the higher‐scoring one\n",
        "                if scores[i] >= scores[j]:\n",
        "                    keep[j] = False\n",
        "                else:\n",
        "                    keep[i] = False\n",
        "\n",
        "    boxes_kept  = [b for b,k in zip(boxes, keep) if k]\n",
        "    scores_kept = [s for s,k in zip(scores,keep) if k]\n",
        "    return boxes_kept, scores_kept\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9629b5e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# def tighten_boxes_locally(boxes, fused, pctile=80, min_pixels=1):\n",
        "#     \"\"\"\n",
        "#     Take YOLO‐boxes over `fused` and shrink each to the bounding box\n",
        "#     of its top‐pctile core.  pctile=75 means keep only pixels ≥ the\n",
        "#     75th percentile within each box.\n",
        "#     \"\"\"\n",
        "#     H, W = fused.shape\n",
        "#     tight = []\n",
        "#     for xc, yc, w_n, h_n in boxes:\n",
        "#         # 1) map back to pixel coords\n",
        "#         x0 = max(0, int((xc - w_n/2) * W))\n",
        "#         x1 = min(W, int((xc + w_n/2) * W))\n",
        "#         y0 = max(0, int((yc - h_n/2) * H))\n",
        "\n",
        "\n",
        "        \n",
        "#         y1 = min(H, int((yc + h_n/2) * H))\n",
        "#         patch = fused[y0:y1, x0:x1]\n",
        "\n",
        "#         # 2) compute local threshold at pctile\n",
        "#         if patch.size < min_pixels:\n",
        "#             continue\n",
        "#         thr = np.percentile(patch, pctile)\n",
        "\n",
        "#         # 3) mask & find core coords\n",
        "#         core = (patch >= thr)\n",
        "#         ys, xs = np.nonzero(core)\n",
        "#         if len(ys) < min_pixels:\n",
        "#             continue\n",
        "\n",
        "#         # 4) build new normalized box\n",
        "#         y0c, y1c = ys.min(), ys.max()\n",
        "#         x0c, x1c = xs.min(), xs.max()\n",
        "#         bw = (x1c - x0c + 1)\n",
        "#         bh = (y1c - y0c + 1)\n",
        "#         cx_new = (x0 + x0c + bw/2) / W\n",
        "#         cy_new = (y0 + y0c + bh/2) / H\n",
        "#         w_new  = bw / W\n",
        "#         h_new  = bh / H\n",
        "\n",
        "#         tight.append((cx_new, cy_new, w_new, h_new))\n",
        "\n",
        "#     return tight\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "395191b3",
      "metadata": {
        "id": "395191b3"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "\n",
        "# def merge_boxes_uf(\n",
        "#     boxes: list[tuple[float,float,float,float]],\n",
        "#     iou_thresh: float = 0.3,\n",
        "#     prox_thresh: float = 0.05\n",
        "# ) -> list[tuple[float,float,float,float]]:\n",
        "#     \"\"\"\n",
        "#     boxes: list of (xc, yc, w, h) in normalized coords\n",
        "#     Returns merged list of (xc, yc, w, h).\n",
        "#     \"\"\"\n",
        "#     def iou(b1, b2):\n",
        "#         x1, y1, w1, h1 = b1\n",
        "#         x2, y2, w2, h2 = b2\n",
        "#         x1min, x1max = x1 - w1/2, x1 + w1/2\n",
        "#         y1min, y1max = y1 - h1/2, y1 + h1/2\n",
        "#         x2min, x2max = x2 - w2/2, x2 + w2/2\n",
        "#         y2min, y2max = y2 - h2/2, y2 + h2/2\n",
        "\n",
        "#         inter_w = max(0, min(x1max, x2max) - max(x1min, x2min))\n",
        "#         inter_h = max(0, min(y1max, y2max) - max(y1min, y2min))\n",
        "#         inter   = inter_w * inter_h\n",
        "#         union   = w1*h1 + w2*h2 - inter\n",
        "#         return inter/union if union>0 else 0\n",
        "\n",
        "#     def distance(b1, b2):\n",
        "#         return np.hypot(b1[0]-b2[0], b1[1]-b2[1])\n",
        "\n",
        "#     # union-find setup\n",
        "#     n = len(boxes)\n",
        "#     parent = list(range(n))\n",
        "#     def find(i):\n",
        "#         while parent[i] != i:\n",
        "#             parent[i] = parent[parent[i]]\n",
        "#             i = parent[i]\n",
        "#         return i\n",
        "#     def union(i, j):\n",
        "#         ri, rj = find(i), find(j)\n",
        "#         if ri != rj:\n",
        "#             parent[rj] = ri\n",
        "\n",
        "#     # cluster any pairs that overlap or are close\n",
        "#     for i in range(n):\n",
        "#         for j in range(i+1, n):\n",
        "#             if iou(boxes[i], boxes[j]) > iou_thresh or distance(boxes[i], boxes[j]) < prox_thresh:\n",
        "#                 union(i, j)\n",
        "\n",
        "#     # collect clusters\n",
        "#     clusters = {}\n",
        "#     for i in range(n):\n",
        "#         r = find(i)\n",
        "#         clusters.setdefault(r, []).append(boxes[i])\n",
        "\n",
        "#     # collapse each cluster\n",
        "#     def collapse_group(group):\n",
        "#         xs, ys, ws, hs = zip(*group)\n",
        "#         areas = [w*h for w,h in zip(ws, hs)]\n",
        "#         total_area = sum(areas)\n",
        "\n",
        "#         # weighted center if possible, else simple average\n",
        "#         if total_area > 0:\n",
        "#             new_x = sum(x*a for x,a in zip(xs, areas)) / total_area\n",
        "#             new_y = sum(y*a for y,a in zip(ys, areas)) / total_area\n",
        "#         else:\n",
        "#             # fallback: equal‐weight average\n",
        "#             new_x = sum(xs) / len(xs)\n",
        "#             new_y = sum(ys) / len(ys)\n",
        "\n",
        "#         # minimal enclosing box\n",
        "#         xmins = [x - w/2 for x,w in zip(xs, ws)]\n",
        "#         xmaxs = [x + w/2 for x,w in zip(xs, ws)]\n",
        "#         ymins = [y - h/2 for y,h in zip(ys, hs)]\n",
        "#         ymaxs = [y + h/2 for y,h in zip(ys, hs)]\n",
        "#         new_w = max(xmaxs) - min(xmins)\n",
        "#         new_h = max(ymaxs) - min(ymins)\n",
        "\n",
        "#         return (new_x, new_y, new_w, new_h)\n",
        "\n",
        "#     return [collapse_group(g) for g in clusters.values()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54d1011a",
      "metadata": {
        "id": "54d1011a"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def generate_yolo_boxes(mask, min_area=1, max_frac_area=0.6, min_aspect=1.5, max_aspect=1/1.5):\n",
        "    # mask is uint8 0/1\n",
        "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
        "    H, W = mask.shape\n",
        "    total = H*W\n",
        "    boxes = []\n",
        "    for lbl in range(1, num_labels):\n",
        "        x, y, w, h, area = stats[lbl]\n",
        "        if area < min_area or area > max_frac_area*total: continue\n",
        "        ar = w/h if h>0 else 0\n",
        "        #if ar < min_aspect and ar > max_aspect: continue\n",
        "        cx = (x + w/2)/W\n",
        "        cy = (y + h/2)/H\n",
        "        boxes.append((cx, cy, w/W, h/H))\n",
        "    return boxes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37e12fd6",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_tasks(df):\n",
        "    \"\"\"\n",
        "    Build a flat list of (h5_path, channel_idx) from your DataFrame,\n",
        "    skipping any channels that fall into known notch filter frequency ranges.\n",
        "    \"\"\"\n",
        "    GBT_NOTCH_FILTERS = {\n",
        "        \"L\": [(1200, 1340)],\n",
        "        \"S\": [(2300, 2360)],\n",
        "    }\n",
        "\n",
        "    tasks = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        h5 = row[\".h5 path\"]\n",
        "        band = row[\"Band\"]  # e.g., 'L', 'S', etc.\n",
        "        fb = bl.Waterfall(h5, load_data=False)\n",
        "        nfreq = fb.header.get(\"nchans\")\n",
        "        nfpc = fb.header.get(\"nfpc\", 1024)\n",
        "        fch1 = fb.header[\"fch1\"]\n",
        "        foff = fb.header[\"foff\"]\n",
        "        n_coarse = nfreq // nfpc\n",
        "\n",
        "        for ch in range(n_coarse):\n",
        "            f0 = fch1 + ch * nfpc * foff\n",
        "            f1 = fch1 + (ch + 1) * nfpc * foff\n",
        "            f_min, f_max = sorted([f0, f1])\n",
        "\n",
        "            # Check against notch filter exclusion ranges\n",
        "            skip = False\n",
        "            if band in GBT_NOTCH_FILTERS:\n",
        "                for lo, hi in GBT_NOTCH_FILTERS[band]:\n",
        "                    if lo <= f_min <= hi or lo <= f_max <= hi:\n",
        "                        skip = True\n",
        "                        break\n",
        "            if not skip:\n",
        "                tasks.append((h5, ch))\n",
        "\n",
        "    return tasks\n",
        "\n",
        "\n",
        "def split_tasks(tasks, train_frac=0.8, seed=42):\n",
        "    \"\"\"\n",
        "    Shuffle & split the flat task list into train vs. val sets.\n",
        "    Returns two sets of (h5_path, channel_idx).\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    shuffled = tasks.copy()\n",
        "    random.shuffle(shuffled)\n",
        "    cut = int(train_frac * len(shuffled))\n",
        "    train = set(shuffled[:cut])\n",
        "    val   = set(shuffled[cut:])\n",
        "    return train, val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "882a3870",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from scipy.stats import kurtosis\n",
        "\n",
        "# def detect_boxes_with_patch_kurtosis(\n",
        "#     block,               # raw 2D power array (ntime × nfreq)\n",
        "#     fused,               # your fused MoE map, same shape\n",
        "#     threshold,           # global threshold you already compute\n",
        "#     kurt_thresh=3.5,     # min kurtosis inside a patch to even try detection\n",
        "#     tile_size=64,        # patch size in pixels\n",
        "#     step=None           # stride between patches (defaults to 50% overlap)\n",
        "# ):\n",
        "#     H, W = block.shape\n",
        "#     if step is None:\n",
        "#         step = tile_size // 2\n",
        "\n",
        "#     all_boxes = []\n",
        "#     for y0 in range(0, H, step):\n",
        "#         for x0 in range(0, W, step):\n",
        "#             y1 = min(H, y0 + tile_size)\n",
        "#             x1 = min(W, x0 + tile_size)\n",
        "\n",
        "#             # 1) compute patch‐local kurtosis\n",
        "#             patch_blk = block[y0:y1, x0:x1]\n",
        "#             flat = patch_blk.ravel()\n",
        "#             if flat.size < 2:\n",
        "#                 continue\n",
        "#             k_loc = kurtosis(flat, fisher=False)\n",
        "#             if k_loc < kurt_thresh:\n",
        "#                 continue\n",
        "\n",
        "#             # 2) detect boxes in this patch\n",
        "#             patch_fused = fused[y0:y1, x0:x1]\n",
        "#             boxes_patch = generate_yolo_boxes(patch_fused, threshold=threshold)\n",
        "\n",
        "#             # 3) convert each box to global normalized coords\n",
        "#             ph, pw = y1 - y0, x1 - x0\n",
        "#             for cx_p, cy_p, w_p, h_p in boxes_patch:\n",
        "#                 # patch‐pixel center\n",
        "#                 xc_pix = cx_p * pw  \n",
        "#                 yc_pix = cy_p * ph\n",
        "#                 # convert to absolute pixel coords, then normalize\n",
        "#                 xc = (x0 + xc_pix) / W\n",
        "#                 yc = (y0 + yc_pix) / H\n",
        "#                 w  = (w_p * pw) / W\n",
        "#                 h  = (h_p * ph) / H\n",
        "#                 all_boxes.append((xc, yc, w, h))\n",
        "\n",
        "#     return all_boxes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58424391",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "from skimage.segmentation import slic\n",
        "from skimage.graph import rag_mean_color, merge_hierarchical\n",
        "\n",
        "\n",
        "def region_features(maps, labels):\n",
        "    \"\"\"\n",
        "    Compute mean feature vector for each label in `labels`.\n",
        "    `maps` is a list of 2D arrays (same shape as labels).\n",
        "    Returns an array of shape (n_labels, len(maps)).\n",
        "    \"\"\"\n",
        "    n_labels = int(labels.max()) + 1\n",
        "    feats = np.zeros((n_labels, len(maps)), dtype=np.float32)\n",
        "    counts = np.bincount(labels.ravel(), minlength=n_labels).astype(np.float32)\n",
        "    for i, fmap in enumerate(maps):\n",
        "        sums = np.bincount(labels.ravel(), weights=fmap.ravel(), minlength=n_labels)\n",
        "        feats[:, i] = sums / (counts + 1e-8)\n",
        "    return feats\n",
        "\n",
        "\n",
        "import cv2\n",
        "\n",
        "def pyramid_fusion(sf_map, ued_map, canny_map, hough_map, levels=4, window_size=3):\n",
        "    \"\"\"\n",
        "    Multi-resolution (Laplacian pyramid) fusion of four feature maps.\n",
        "\n",
        "    Args:\n",
        "        sf_map, ued_map, canny_map, hough_map: 2D numpy arrays (same shape)\n",
        "        levels: number of pyramid levels\n",
        "        window_size: size for local energy filter (e.g. variance) when computing weights\n",
        "    Returns:\n",
        "        fused: 2D array, same shape as inputs\n",
        "    \"\"\"\n",
        "    maps = [sf_map, ued_map, canny_map, hough_map]\n",
        "\n",
        "    # 1) Build Gaussian pyramids\n",
        "    G = [maps]\n",
        "    for _ in range(levels):\n",
        "        prev = G[-1]\n",
        "        down = [cv2.pyrDown(m) for m in prev]\n",
        "        G.append(down)\n",
        "\n",
        "    # 2) Build Laplacian pyramids\n",
        "    L = []\n",
        "    for lvl in range(levels):\n",
        "        lap = []\n",
        "        for i, m in enumerate(G[lvl]):\n",
        "            up = cv2.pyrUp(G[lvl+1][i], dstsize=(m.shape[1], m.shape[0]))\n",
        "            lap.append(m.astype(np.float32) - up.astype(np.float32))\n",
        "        L.append(lap)\n",
        "    # Add the smallest Gaussian level at the top\n",
        "    L.append([m.astype(np.float32) for m in G[-1]])\n",
        "\n",
        "    # 3) Fuse at each level by local energy weighting\n",
        "    fused_pyr = []\n",
        "    for lvl_maps in L:\n",
        "        # compute local energy (variance) per map\n",
        "        energies = [cv2.blur(m*m, (window_size, window_size)) for m in lvl_maps]\n",
        "        sum_e = sum(energies) + 1e-8\n",
        "        # weighted sum\n",
        "        fused_lvl = sum((energies[i] / sum_e) * lvl_maps[i] for i in range(len(lvl_maps)))\n",
        "        fused_pyr.append(fused_lvl)\n",
        "\n",
        "    # 4) Collapse pyramid\n",
        "    fused = fused_pyr[-1]\n",
        "    for lvl in range(levels-1, -1, -1):\n",
        "        fused = cv2.pyrUp(fused, dstsize=(fused_pyr[lvl].shape[1], fused_pyr[lvl].shape[0]))\n",
        "        fused = fused + fused_pyr[lvl]\n",
        "\n",
        "    return fused\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d65f16e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def shrink_large_boxes(\n",
        "    boxes: list[tuple[float, float, float, float]],\n",
        "    fused: np.ndarray,\n",
        "    w_max: float = 0.9,\n",
        "    h_max: float = 0.9,\n",
        "    global_thresh: float = None,\n",
        "    local_frac: float = 0.1,\n",
        "    min_coverage: float = 0.05\n",
        ") -> list[tuple[float, float, float, float]]:\n",
        "    \"\"\"\n",
        "    For any box whose normalized width >= w_max OR height >= h_max,\n",
        "    re-extract the patch in `fused`, threshold it at `mask_thr` and\n",
        "    only shrink if the mask covers at least `min_coverage` fraction\n",
        "    of the patch.  Otherwise, keep the original box.\n",
        "\n",
        "    Parameters:\n",
        "    - boxes: YOLO boxes (xc, yc, w, h) normalized coords\n",
        "    - fused: 2D fused map\n",
        "    - w_max, h_max: thresholds for deciding \"large\" boxes\n",
        "    - global_thresh: if provided, used as local mask threshold;\n",
        "                     otherwise mask_thr = local_frac * fused.max()\n",
        "    - local_frac: fraction of fused.max() used if global_thresh is None\n",
        "    - min_coverage: minimum fraction of patch pixels above mask_thr\n",
        "                     to allow shrinking\n",
        "    \"\"\"\n",
        "    H, W = fused.shape\n",
        "    # Determine local mask threshold\n",
        "    if global_thresh is None:\n",
        "        mask_thr = local_frac * fused.max()\n",
        "    else:\n",
        "        mask_thr = global_thresh\n",
        "\n",
        "    shrunk = []\n",
        "    for xc, yc, w, h in boxes:\n",
        "        # only shrink boxes that exceed size\n",
        "        if w < w_max and h < h_max:\n",
        "            shrunk.append((xc, yc, w, h))\n",
        "            continue\n",
        "\n",
        "        # map normalized center/size → pixel coords\n",
        "        x0 = max(0, int((xc - w/2) * W))\n",
        "        x1 = min(W, int((xc + w/2) * W))\n",
        "        y0 = max(0, int((yc - h/2) * H))\n",
        "        y1 = min(H, int((yc + h/2) * H))\n",
        "\n",
        "        patch = fused[y0:y1, x0:x1]\n",
        "        if patch.size == 0:\n",
        "            shrunk.append((xc, yc, w, h))\n",
        "            continue\n",
        "\n",
        "        # binarize and check coverage\n",
        "        mask = patch > mask_thr\n",
        "        cov = mask.sum() / mask.size\n",
        "        if cov < min_coverage:\n",
        "            # not enough core pixels: skip shrinking\n",
        "            shrunk.append((xc, yc, w, h))\n",
        "            continue\n",
        "\n",
        "        ys, xs = np.nonzero(mask)\n",
        "        y_min, y_max = ys.min(), ys.max()\n",
        "        x_min, x_max = xs.min(), xs.max()\n",
        "\n",
        "        # convert back to normalized coords\n",
        "        new_w = (x_max - x_min + 1) / W\n",
        "        new_h = (y_max - y_min + 1) / H\n",
        "        new_xc = (x0 + (x_min + x_max + 1)/2) / W\n",
        "        new_yc = (y0 + (y_min + y_max + 1)/2) / H\n",
        "\n",
        "        shrunk.append((new_xc, new_yc, new_w, new_h))\n",
        "\n",
        "    return shrunk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01f15cf9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import scipy.ndimage as ndi\n",
        "\n",
        "def remove_small_regions(mask, min_size):\n",
        "    \"\"\"\n",
        "    Remove any connected component in `mask` smaller than `min_size` pixels.\n",
        "    `mask` is a boolean array. Returns a new boolean mask.\n",
        "    \"\"\"\n",
        "    labeled, num = ndi.label(mask)\n",
        "    sizes = np.bincount(labeled.ravel())\n",
        "    out = np.zeros_like(mask, dtype=bool)\n",
        "    # keep any label with size >= min_size\n",
        "    for lbl, sz in enumerate(sizes):\n",
        "        if lbl == 0:\n",
        "            continue\n",
        "        if sz >= min_size:\n",
        "            out[labeled == lbl] = True\n",
        "    return out\n",
        "\n",
        "def fill_small_holes(mask, hole_size):\n",
        "    \"\"\"\n",
        "    Fill any background hole (zeros) in `mask` of area <= `hole_size`.\n",
        "    Returns a new boolean mask.\n",
        "    \"\"\"\n",
        "    inv = ~mask\n",
        "    labeled, num = ndi.label(inv)\n",
        "    sizes = np.bincount(labeled.ravel())\n",
        "    out = mask.copy()\n",
        "    # for any hole label with size <= hole_size, set those pixels to True\n",
        "    for lbl, sz in enumerate(sizes):\n",
        "        if lbl == 0:\n",
        "            continue\n",
        "        if sz <= hole_size:\n",
        "            out[labeled == lbl] = True\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FwocEh2jdjRX",
      "metadata": {
        "id": "FwocEh2jdjRX"
      },
      "outputs": [],
      "source": [
        "# The MoE: Structured Forest (SF), Sobel (UED), Canny, HOG (Histogram of Oriented Gradients)\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "from torch import nn\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageDraw\n",
        "import blimpy as bl\n",
        "from skimage.segmentation import slic\n",
        "from skimage.feature import hog\n",
        "from skimage.transform import probabilistic_hough_line\n",
        "from scipy.stats import kurtosis\n",
        "import skimage.filters as filt\n",
        "import scipy.ndimage as ndi\n",
        "from skimage.measure import label, regionprops\n",
        "\n",
        "%pip install imageio\n",
        "import imageio\n",
        "\n",
        "\n",
        "# --- Define RuleGate  ------------------------------------------------------\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class RuleGate(nn.Module):\n",
        "    def __init__(self, in_feats=3, hidden=16):\n",
        "        super().__init__()\n",
        "        # in_feats = number of heuristics per map (e.g. 3: density, alignment, linearity)\n",
        "        # We’ll concatenate all four maps’ heuristics → 4*in_feats inputs\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(4*in_feats, hidden),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden, 4)      # one logit per detector\n",
        "        )\n",
        "\n",
        "    def forward(self,\n",
        "                h_sf:    torch.Tensor,  # (B,in_feats)\n",
        "                h_ued:   torch.Tensor,  # (B,in_feats)\n",
        "                h_canny: torch.Tensor,  # (B,in_feats)\n",
        "                h_hough: torch.Tensor   # (B,in_feats)\n",
        "               ):\n",
        "        # 1) concatenate all heuristics\n",
        "        x = torch.cat([h_sf, h_ued, h_canny, h_hough], dim=1)      # (B,4*in_feats)\n",
        "        logits = self.net(x)                                        # (B,4)\n",
        "        weights = torch.softmax(logits, dim=1)                      # (B,4) sums to 1\n",
        "        return weights[:,0], weights[:,1], weights[:,2], weights[:,3]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -- 2) Heuristic helper -------------------------------------------------\n",
        "def compute_heuristics(edge_map, gray):\n",
        "    th = filt.threshold_otsu(edge_map)\n",
        "    mask = edge_map > th\n",
        "    density = float(mask.mean())\n",
        "    if density > 0:\n",
        "        gx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, 3)\n",
        "        gy = cv2.Sobel(gray, cv2.CV_32F, 0, 1, 3)\n",
        "        alignment = float(np.hypot(gx, gy)[mask].mean())\n",
        "    else:\n",
        "        alignment = 0.0\n",
        "    bw = mask.astype(np.uint8)\n",
        "    n, labels = cv2.connectedComponents(bw)\n",
        "    ratios = []\n",
        "    for L in range(1, n):\n",
        "        ys, xs = np.where(labels == L)\n",
        "        if ys.size:\n",
        "            h, w = np.ptp(ys)+1, np.ptp(xs)+1\n",
        "            ratios.append(float(w)/h if h else 0.0)\n",
        "    linearity = float(np.mean(ratios)) if ratios else 0.0\n",
        "    if density < 0.01:\n",
        "        return [0.0, 0.0, 0.0]\n",
        "    return [density, alignment, linearity]\n",
        "\n",
        "\n",
        "# -------- 3) process_file --------------------------------------------\n",
        "def process_file(job):\n",
        "    (h5_path, channels, gidxs,\n",
        "     base_dir, class_id, train_set, val_set,\n",
        "     pad_width) = job\n",
        "\n",
        "    fb   = bl.Waterfall(h5_path, load_data=True)\n",
        "    data = 10*np.log10(fb.data.squeeze())\n",
        "\n",
        "    EDGE_MODEL = \"/home/jliang/gbt-rfi/model.yml.gz\"\n",
        "    sf_det     = cv2.ximgproc.createStructuredEdgeDetection(EDGE_MODEL)\n",
        "    gate = RuleGate()\n",
        "\n",
        "    for ch_idx, gidx in zip(channels, gidxs):\n",
        "        subset = \"train\" if (h5_path,ch_idx) in train_set else \"val\"\n",
        "        img_dir = Path(base_dir)/subset/\"images\"\n",
        "        lbl_dir = Path(base_dir)/subset/\"labels\"\n",
        "        vis_dir = Path(base_dir)/\"visualization\"/subset\n",
        "        for d in (img_dir,lbl_dir,vis_dir): d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        cw = fb.header.get(\"nfpc\",1024)\n",
        "        f0, f1 = ch_idx*cw, (ch_idx+1)*cw\n",
        "        block = data[:,f0:f1]\n",
        "        low, high = int(0.15*cw), int(0.85*cw)\n",
        "        block = block[:,low:high]\n",
        "        h_img, w_img = block.shape\n",
        "\n",
        "        # Remove vertical line artifact\n",
        "        rows, cols = block.shape\n",
        "        vert_means = block.mean(axis=0)\n",
        "        center = np.argmax(vert_means)\n",
        "        left_col = center - 1\n",
        "        right_col = center + 1\n",
        "        if left_col >= 0 and right_col < cols:\n",
        "            block[:, center] = (block[:, left_col] + block[:, right_col]) / 2\n",
        "        elif left_col >= 0:\n",
        "            block[:, center] = block[:, left_col]\n",
        "        elif right_col < cols:\n",
        "            block[:, center] = block[:, right_col]\n",
        "\n",
        "\n",
        "        # Structured Forest\n",
        "        norm = (block - block.min())/(np.ptp(block)+1e-6)\n",
        "        img3 = np.stack([norm]*3, axis=-1).astype(np.float32)\n",
        "        sf_map = sf_det.detectEdges(img3).squeeze()\n",
        "        gray8  = (255*norm).astype(np.uint8)\n",
        "\n",
        "        # Sobel\n",
        "        gx = cv2.Sobel(gray8, cv2.CV_32F, 1,0,3)\n",
        "        gy = cv2.Sobel(gray8, cv2.CV_32F, 0,1,3)\n",
        "        ued_map = np.hypot(gx, gy)\n",
        "        ued_map = cv2.normalize(ued_map, None, 0,1, cv2.NORM_MINMAX)\n",
        "\n",
        "        # Canny\n",
        "        low_thresh, high_thresh = 30, 100\n",
        "        gray_denoised = cv2.medianBlur(gray8, 3)\n",
        "        edges = cv2.Canny(gray_denoised, low_thresh, high_thresh)\n",
        "        canny_map = edges.astype(np.float32) / 255.0\n",
        "\n",
        "        # Hough\n",
        "        hough_map = np.zeros_like(canny_map, dtype=np.float32)\n",
        "        lines = probabilistic_hough_line(\n",
        "            (edges > 0).astype(np.uint8),\n",
        "            threshold=5,\n",
        "            line_length=10,\n",
        "            line_gap=2\n",
        "        )\n",
        "        for (y0, x0), (y1, x1) in lines:\n",
        "            cv2.line(hough_map, (x0, y0), (x1, y1), 1.0, 1)\n",
        "        hough_map = cv2.GaussianBlur(hough_map, (3,3), 0)\n",
        "\n",
        "        bk = float(kurtosis(gray8.flatten(), fisher=False))\n",
        "\n",
        "        # # 1) Pick your parameters\n",
        "        # n_init          = 800                   # number of initial superpixels\n",
        "        # compactness     = 10                    # SLIC compactness\n",
        "        # thresholds      = [0.1, 0.3, 0.6]       # RAG merge-thresholds (fine→coarse)\n",
        "        # min_region_size = 50                    # skip very small regions\n",
        "\n",
        "        # —————————————————————————————————————————————\n",
        "        # 2) Multi‐scale pyramid fusion\n",
        "        # —————————————————————————————————————————————\n",
        "        fused_multi = pyramid_fusion(\n",
        "            sf_map, ued_map, canny_map, hough_map,\n",
        "            levels=4, window_size=5\n",
        "        )\n",
        "\n",
        "        # —————————————————————————————————————————————\n",
        "        # 3) Flatten out the background plane\n",
        "        # —————————————————————————————————————————————\n",
        "        y, x = np.mgrid[:h_img, :w_img]\n",
        "        A = np.column_stack([x.ravel(), y.ravel(), np.ones(h_img*w_img)])\n",
        "        b = fused_multi.ravel()\n",
        "        coeff, *_ = np.linalg.lstsq(A, b, rcond=None)\n",
        "        plane     = (coeff[0]*x + coeff[1]*y + coeff[2]).astype(np.float32)\n",
        "        fused_flat = fused_multi - plane\n",
        "\n",
        "        # —————————————————————————————————————————————\n",
        "        # 4) Local Z‐score thresholding\n",
        "        # —————————————————————————————————————————————\n",
        "        # (ensure at top: import scipy.ndimage as ndi)\n",
        "        local_mean = ndi.uniform_filter(fused_flat, size=51)\n",
        "        sq_mean    = ndi.uniform_filter(fused_flat**2, size=51)\n",
        "        local_std  = np.sqrt(np.clip(sq_mean - local_mean**2, 0, None))\n",
        "        zmap       = (fused_flat - local_mean) / (local_std + 1e-8)\n",
        "\n",
        "\n",
        "        # # 1) threshold your zmap\n",
        "        # binary    = (zmap > 1.5)            # bool array\n",
        "        # imageio.imwrite(\"1_binary.png\", (binary*255).astype(np.uint8))\n",
        "\n",
        "        # # 2) remove small speckles\n",
        "        # mask1     = remove_small_regions(binary, min_size=20)\n",
        "        # imageio.imwrite(\"2_mask1.png\",  (mask1*255).astype(np.uint8))\n",
        "\n",
        "        # # 3) fill small holes\n",
        "        # final_mask= fill_small_holes(mask1, hole_size=5)\n",
        "        # imageio.imwrite(\"3_final.png\",  (final_mask*255).astype(np.uint8))\n",
        "\n",
        "        # # 4) (optionally) thicken lines so boxes have area\n",
        "        # final_mask_thick = ndi.binary_dilation(final_mask, structure=np.ones((3,3),bool))\n",
        "        # imageio.imwrite(\"4_thick.png\",  (final_mask_thick*255).astype(np.uint8))\n",
        "\n",
        "        # # 5) generate boxes\n",
        "        # boxes = generate_yolo_boxes(final_mask_thick.astype(np.uint8),\n",
        "        #                             min_area=1,\n",
        "        #                             max_frac_area=0.6,\n",
        "        #                             min_aspect=1.5,\n",
        "        #                             max_aspect=1/1.5)\n",
        "        # # print(\"Boxes:\", boxes)\n",
        "\n",
        "        # # 6) draw them on the original image\n",
        "        # vis = cv2.cvtColor((norm*255).astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
        "        # H, W = final_mask_thick.shape\n",
        "        # for cx,cy,w_n,h_n in boxes:\n",
        "        #     x0 = int((cx - w_n/2)*W)\n",
        "        #     y0 = int((cy - h_n/2)*H)\n",
        "        #     x1 = int((cx + w_n/2)*W)\n",
        "        #     y1 = int((cy + h_n/2)*H)\n",
        "        #     cv2.rectangle(vis, (x0,y0), (x1,y1), (0,0,255), 1)\n",
        "        # cv2.imwrite(\"5_debug_boxes.png\", vis)\n",
        "\n",
        "\n",
        "        # —————————————————————————————————————————————\n",
        "        # 4) Z‐map → binary (bool)\n",
        "        # —————————————————————————————————————————————\n",
        "        binary = (zmap > 2.0)\n",
        "\n",
        "        # # —————————————————————————————————————————————\n",
        "        # # 5) Directed opening to keep both orientations\n",
        "        # # —————————————————————————————————————————————\n",
        "        # k = 3  # minimum line length to preserve\n",
        "        # se_v = np.ones((k, 1), bool)  # vertical line SE\n",
        "        # se_h = se_v.T                 # horizontal line SE\n",
        "\n",
        "        # # open in each direction\n",
        "        # bin_v = ndi.binary_opening(binary, structure=se_v)\n",
        "        # bin_h = ndi.binary_opening(binary, structure=se_h)\n",
        "\n",
        "        # # union: anything that survives either pass\n",
        "        # opened = bin_v | bin_h\n",
        "\n",
        "        # —————————————————————————————————————————————\n",
        "        # 6) Remove small regions & fill holes\n",
        "        # —————————————————————————————————————————————\n",
        "        def remove_small_regions(mask, min_size):\n",
        "            lbl, _ = ndi.label(mask)\n",
        "            sizes  = np.bincount(lbl.ravel())\n",
        "            out    = np.zeros_like(mask)\n",
        "            for lab, sz in enumerate(sizes):\n",
        "                if lab>0 and sz>=min_size:\n",
        "                    out[lbl==lab] = True\n",
        "            return out\n",
        "\n",
        "        def fill_small_holes(mask, hole_size):\n",
        "            inv    = ~mask\n",
        "            lbl, _ = ndi.label(inv)\n",
        "            sizes  = np.bincount(lbl.ravel())\n",
        "            out    = mask.copy()\n",
        "            for lab, sz in enumerate(sizes):\n",
        "                if lab>0 and sz <= hole_size:\n",
        "                    out[lbl==lab] = True\n",
        "            return out\n",
        "\n",
        "        mask1     = fill_small_holes(binary, hole_size=5)\n",
        "        final_mask= mask1.copy()\n",
        "\n",
        "        # —————————————————————————————————————————————\n",
        "        # 7) Shape filter: keep only very elongated CCs MAYBE COMMENT THIS OUT\n",
        "        # —————————————————————————————————————————————\n",
        "        lbl   = label(final_mask)\n",
        "        keep  = np.zeros_like(final_mask)\n",
        "        for p in regionprops(lbl):\n",
        "            y0,x0,y1,x1 = p.bbox\n",
        "            h, w = y1-y0, x1-x0\n",
        "            ar   = w/h if h>0 else 0\n",
        "            # allow both tall (ar≤1/2) and wide (ar≥2) components\n",
        "            if not (ar>=2 or ar<=0.5):\n",
        "                continue\n",
        "            if p.solidity < 0.9:\n",
        "                continue\n",
        "            keep[p.coords[:,0], p.coords[:,1]] = True\n",
        "\n",
        "        final_mask = keep\n",
        "\n",
        "        # —————————————————————————————————————————————\n",
        "        # 8) Box it\n",
        "        # —————————————————————————————————————————————\n",
        "        H, W = final_mask.shape\n",
        "        lbl_img = label(final_mask)          # integer label image\n",
        "        boxes = []                           # will hold (class_id, x_c, y_c, w, h)\n",
        "        for region in regionprops(lbl_img):\n",
        "            # skip tiny debris if you like:\n",
        "            # if region.area < 5:\n",
        "            #     continue\n",
        "\n",
        "            minr, minc, maxr, maxc = region.bbox\n",
        "            h_pix = maxr - minr\n",
        "            w_pix = maxc - minc\n",
        "            # center in pixel coords\n",
        "            cy = minr + h_pix/2\n",
        "            cx = minc + w_pix/2\n",
        "            # normalize to [0,1]\n",
        "            boxes.append((\n",
        "                cx / W,\n",
        "                cy / H,\n",
        "                w_pix / W,\n",
        "                h_pix / H\n",
        "            ))\n",
        "\n",
        "\n",
        "        # 2) run patch‐based pre‐filter + detection\n",
        "        filtered = []\n",
        "        H, W = block.shape\n",
        "        for xc, yc, w_n, h_n in boxes:\n",
        "            # map back to pixel coords\n",
        "            x0 = max(0, int((xc - w_n/2) * W))\n",
        "            x1 = min(W-1, int((xc + w_n/2) * W))\n",
        "            y0 = max(0, int((yc - h_n/2) * H))\n",
        "            y1 = min(H-1, int((yc + h_n/2) * H))\n",
        "\n",
        "            patch = block[y0:y1, x0:x1].ravel()\n",
        "            k_loc = kurtosis(patch, fisher=False) if patch.size >= 2 else 0.0\n",
        "\n",
        "            filtered.append((xc, yc, w_n, h_n))\n",
        "\n",
        "        # 3) continue with your existing scoring/NMS on boxes\n",
        "        if len(filtered) == 0:\n",
        "            boxes = []\n",
        "        else:\n",
        "            areas = [w*h for (_,_,w,h) in boxes]\n",
        "            H, W = fused_multi.shape\n",
        "            kurt_vals = []\n",
        "            for (cx, cy, w_n, h_n) in boxes:\n",
        "                # convert normalized coords back to pixel indices\n",
        "                x0 = max(0, int((cx - w_n/2) * W))\n",
        "                x1 = min(W, int((cx + w_n/2) * W))\n",
        "                y0 = max(0, int((cy - h_n/2) * H))\n",
        "                y1 = min(H, int((cy + h_n/2) * H))\n",
        "\n",
        "                patch = block[y0:y1, x0:x1].flatten()\n",
        "                if patch.size < 2:\n",
        "                    kurt_vals.append(0.0)\n",
        "                else:\n",
        "                    # use excess‐kurtosis (Gaussian = 0)\n",
        "                    kurt_vals.append(kurtosis(patch, fisher=True))\n",
        "                    # 4) Convert to numpy arrays\n",
        "            a_arr = np.array(areas, dtype=float)\n",
        "            k_arr = np.array(kurt_vals, dtype=float)\n",
        "\n",
        "            # 5) Normalize safely\n",
        "            a_norm = (a_arr - a_arr.min()) / (np.ptp(a_arr) + 1e-6)\n",
        "            k_norm = (k_arr - k_arr.min()) / (np.ptp(k_arr) + 1e-6)\n",
        "\n",
        "            # 6) Composite score & NMS\n",
        "            scores = (0.9 * k_norm + 0.1 * a_norm).tolist()\n",
        "            assert len(scores) == len(boxes), f\"scores({len(scores)})!=boxes({len(boxes)})\"\n",
        "            # boxes = non_max_suppression(boxes, scores, iou_thresh=0.3)\n",
        "            # boxes = shrink_large_boxes(\n",
        "            #     boxes,\n",
        "            #     fused_multi,\n",
        "            #     w_max=0.8,      # only shrink boxes ≥80% wide\n",
        "            #     h_max=0.8,      # or ≥80% tall\n",
        "            #     global_thresh=0.2   # threshold inside each patch\n",
        "            # )\n",
        "\n",
        "            boxes, scores = remove_nested_boxes(boxes, scores)\n",
        "\n",
        "        f_start = fb.header['fch1'] + f0 * fb.header['foff']\n",
        "        f_stop  = fb.header['fch1'] + (f1 - 1) * fb.header['foff']\n",
        "        kurt_val = kurtosis(gray8.flatten(), fisher=False)\n",
        "        fn = f\"img_{kurt_val:0{pad_width}.2f}_f_{f_start:.4f}_{f_stop:.4f}.png\"\n",
        "        img_path = img_dir / fn\n",
        "        txt_path = lbl_dir / fn.replace(\".png\", \".txt\")\n",
        "\n",
        "        arr8 = (255 * (block - block.min()) / (np.ptp(block) + 1e-6)).astype(np.uint8)\n",
        "        img = Image.fromarray(np.stack([arr8]*3, axis=-1))\n",
        "        img.save(img_path)\n",
        "\n",
        "        full_image_threshold = 0.95\n",
        "        min_norm_area        = 0.005\n",
        "        # boxes is List[(x_c, y_c, w_n, h_n)]\n",
        "        boxes = [\n",
        "            (x_c, y_c, w_n, h_n)\n",
        "            for x_c, y_c, w_n, h_n in boxes\n",
        "            if min_norm_area <= (w_n * h_n) <= full_image_threshold\n",
        "        ]\n",
        "\n",
        "        with open(txt_path, \"w\") as f:\n",
        "            for x_c, y_c, w_n, h_n in boxes:\n",
        "                f.write(f\"{class_id} {x_c:.6f} {y_c:.6f} {w_n:.6f} {h_n:.6f}\\n\")\n",
        "\n",
        "\n",
        "        if not boxes:\n",
        "            (lbl_dir/\"empty_labels.csv\").open(\"a\").write(f\"{fn},{h5_path},{ch_idx}\\n\")\n",
        "\n",
        "        vis_img = img.convert(\"RGB\")\n",
        "        draw    = ImageDraw.Draw(vis_img)\n",
        "        for x_c, y_c, w_n, h_n in boxes:\n",
        "            xc, yc = x_c*w_img, y_c*h_img\n",
        "            bw, bh = w_n*w_img, h_n*h_img\n",
        "            x0, y0 = int(xc - bw/2), int(yc - bh/2)\n",
        "            x1, y1 = int(xc + bw/2), int(yc + bh/2)\n",
        "            draw.rectangle([x0, y0, x1, y1], outline=\"red\", width=2)\n",
        "        vis_img.save(vis_dir/fn)\n",
        "\n",
        "        debug_dir = vis_dir/\"debug_masks\"\n",
        "        debug_dir.mkdir(exist_ok=True)\n",
        "        imageio.imwrite(debug_dir/f\"binary_{kurt_val}_{f_start}_{f_stop}.png\",   (binary*255).astype(np.uint8))\n",
        "        imageio.imwrite(debug_dir/f\"mask1_{kurt_val}_{f_start}_{f_stop}.png\",   (mask1*255).astype(np.uint8))\n",
        "        # imageio.imwrite(debug_dir/f\"cleaned_{kurt_val}_{f_start}_{f_stop}.png\",  (cleaned*255).astype(np.uint8))\n",
        "        imageio.imwrite(debug_dir/f\"final_{kurt_val}_{f_start}_{f_stop}.png\",    (final_mask*255).astype(np.uint8))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    tasks = build_tasks(df)\n",
        "    train_set, val_set = split_tasks(tasks)\n",
        "\n",
        "    # 2) build job tuples of exactly what process_file unpacks:\n",
        "    job_args = []\n",
        "    BASE_DIR = \"/datax/scratch/jliang/dataset_moe_gate-pyramid-newgate-test2\"\n",
        "    NUM_WORKERS = 2\n",
        "    class_id = 0  # Assuming a single class for simplicity\n",
        "    pad_width = 4  # Zero-padding width for gidx in filenames\n",
        "    for idx, (h5_path, ch_idx) in enumerate(tasks):\n",
        "        job = (\n",
        "            h5_path,\n",
        "            [ch_idx],        # channels\n",
        "            [idx],           # gidxs\n",
        "            BASE_DIR,\n",
        "            class_id,\n",
        "            train_set,\n",
        "            val_set,\n",
        "            pad_width\n",
        "        )\n",
        "        job_args.append(job)\n",
        "\n",
        "    # 3) submit each job as a single argument\n",
        "    with ProcessPoolExecutor(max_workers=NUM_WORKERS) as exe:\n",
        "        futures = {\n",
        "            exe.submit(process_file, job): (job[0], job[1])\n",
        "            for job in job_args\n",
        "        }\n",
        "\n",
        "        for future in tqdm(as_completed(futures), total=len(futures)):\n",
        "            h5, ch_list = futures[future]\n",
        "            try:\n",
        "                future.result()\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {h5} channel {ch_list}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48e59983",
      "metadata": {
        "id": "48e59983"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import cv2\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from skimage.segmentation import slic\n",
        "# from scipy import ndimage\n",
        "\n",
        "# # ─── 1) HEURISTIC COMPUTATION ─────────────────────────────────────────\n",
        "\n",
        "# def compute_heuristics(edge_map, gray_image):\n",
        "#     # edge_map: 2D float32 [0,1], gray_image: 2D uint8\n",
        "#     # 1) gradient magnitude\n",
        "#     gx = cv2.Sobel(gray_image, cv2.CV_32F, 1, 0, ksize=3)\n",
        "#     gy = cv2.Sobel(gray_image, cv2.CV_32F, 0, 1, ksize=3)\n",
        "#     grad = np.hypot(gx, gy)\n",
        "\n",
        "#     # 2) statistics\n",
        "#     density   = np.mean(edge_map > 0.2)\n",
        "#     align     = np.mean(grad[edge_map > 0.2]) if density>0 else 0.0\n",
        "#     entropy   = -np.sum(edge_map * np.log2(edge_map + 1e-8))\n",
        "#     # 3) linearity via eccentricity of components\n",
        "#     bw   = edge_map > 0.2\n",
        "#     lbl, n = ndimage.label(bw)\n",
        "#     props = ndimage.find_objects(lbl)\n",
        "#     eccs = []\n",
        "#     for i, sl in enumerate(props, start=1):\n",
        "#         region = (lbl[sl] == i).astype(np.uint8)\n",
        "#         # approximate by second moments → skip details here\n",
        "#         eccs.append(region.sum()>0 and region.sum() / (region.shape[0]*region.shape[1]))\n",
        "#     linearity = float(np.mean(eccs)) if eccs else 0.0\n",
        "\n",
        "#     if density < 0.01:\n",
        "#         return [0.0, 0.0, 0.0, 0.0]\n",
        "#     return [density, align, entropy, linearity]\n",
        "\n",
        "\n",
        "# # ─── 2) RULE-BASED GATE MODULE ──────────────────────────────────────────\n",
        "\n",
        "# class RuleGate(nn.Module):\n",
        "#     def __init__(self, w_align=1.0, w_ent=1.0, bias=0.0):\n",
        "#         super().__init__()\n",
        "#         # wrap as parameters if you want to tune via backprop:\n",
        "#         self.w_align = nn.Parameter(torch.tensor(w_align))\n",
        "#         self.w_ent   = nn.Parameter(torch.tensor(w_ent))\n",
        "#         self.bias    = nn.Parameter(torch.tensor(bias))\n",
        "\n",
        "#     def forward(self, h_sf, h_ued):\n",
        "#         # h_*: [B,4] tensors on CUDA\n",
        "#         align = h_ued[:,1] - h_sf[:,1]      # favors UED if >0\n",
        "#         ent   = h_sf[:,2] - h_ued[:,2]      # favors UED if >0\n",
        "#         score  = self.w_align * align + self.w_ent * ent + self.bias\n",
        "#         return torch.sigmoid(score)         # [B] weights for UED\n",
        "\n",
        "\n",
        "# class MoEBlock(nn.Module):\n",
        "#     def __init__(self, gate: RuleGate):\n",
        "#         super().__init__()\n",
        "#         self.gate = gate\n",
        "\n",
        "#     def forward(self, sf_map, ued_map, h_sf, h_ued):\n",
        "#         \"\"\"\n",
        "#         sf_map, ued_map: [B,H,W] floats on CUDA\n",
        "#         h_sf, h_ued:        [B,4] heuristic tensors on CUDA\n",
        "#         \"\"\"\n",
        "#         p = self.gate(h_sf, h_ued).view(-1,1,1)  # [B,1,1]\n",
        "#         return p * ued_map + (1 - p) * sf_map\n",
        "\n",
        "\n",
        "# # ─── 3) FULL PROCESSING LOOP ───────────────────────────────────────────\n",
        "\n",
        "# def process_image_patch(patch, sf_detector, gate_block, device='cuda'):\n",
        "#     \"\"\"\n",
        "#     patch: HxWx3 BGR uint8\n",
        "#     sf_detector: cv2.ximgproc StructuredEdgeDetection\n",
        "#     gate_block:   instance of MoEBlock on device\n",
        "#     \"\"\"\n",
        "#     # 1) compute both edge maps\n",
        "#     gray    = cv2.cvtColor(patch, cv2.COLOR_BGR2GRAY)\n",
        "#     sf_edges= sf_detector.detectEdges(np.float32(patch)/255.0).squeeze()\n",
        "#     gx = cv2.Sobel(gray, cv2.CV_32F, 1,0,3)\n",
        "#     gy = cv2.Sobel(gray, cv2.CV_32F, 0,1,3)\n",
        "#     ued_edges = np.hypot(gx, gy)\n",
        "#     ued_edges = (ued_edges/ued_edges.max()).astype(np.float32)\n",
        "\n",
        "#     # 2) superpixel segmentation\n",
        "#     segments = slic(patch, n_segments=100, compactness=10)\n",
        "\n",
        "#     # 3) gather heuristics and masks\n",
        "#     feats_sf, feats_ued, masks = [], [], []\n",
        "#     for seg in np.unique(segments):\n",
        "#         mask = (segments==seg)\n",
        "#         if mask.sum()<50: continue\n",
        "#         hsf = compute_heuristics(sf_edges*mask, gray)\n",
        "#         hud = compute_heuristics(ued_edges*mask, gray)\n",
        "#         if not any(hsf) and not any(hud): continue\n",
        "#         feats_sf.append(hsf)\n",
        "#         feats_ued.append(hud)\n",
        "#         masks.append(mask)\n",
        "\n",
        "#     if not masks:\n",
        "#         return np.zeros_like(sf_edges, np.float32)\n",
        "\n",
        "#     # 4) move to GPU\n",
        "#     h_sf = torch.tensor(feats_sf, device=device)\n",
        "#     h_ued= torch.tensor(feats_ued, device=device)\n",
        "#     sf_m = torch.tensor(np.stack([sf_edges[m] for m in masks]), device=device)\n",
        "#     ue_m = torch.tensor(np.stack([ued_edges[m] for m in masks]), device=device)\n",
        "\n",
        "#     # 5) fuse with gate\n",
        "#     fused_masks = gate_block(sf_m, ue_m, h_sf, h_ued)  # [N_pixels]\n",
        "#     fused = np.zeros_like(sf_edges, np.float32)\n",
        "#     for p, m in zip(fused_masks.cpu().numpy(), masks):\n",
        "#         fused[m] = p\n",
        "\n",
        "#     # 6) generate YOLO boxes\n",
        "#     return fused\n",
        "\n",
        "\n",
        "# # ─── 4) USAGE ─────────────────────────────────────────────────────────\n",
        "\n",
        "# # Initialize:\n",
        "# EDGE_MODEL_PATH = \"model.yml\"  # your SF model\n",
        "# sf_detector = cv2.ximgproc.createStructuredEdgeDetection(EDGE_MODEL_PATH)\n",
        "# gate        = RuleGate(w_align=2.0, w_ent=1.0, bias=-0.5).cuda()\n",
        "# moe_block   = MoEBlock(gate).cuda()\n",
        "\n",
        "# # For each patch:\n",
        "# # fused_map = process_image_patch(patch, sf_detector, moe_block)\n",
        "# # then threshold fused_map, label, convert to YOLO (cx,cy,w,h) as before.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bde136f",
      "metadata": {
        "id": "8bde136f"
      },
      "outputs": [],
      "source": [
        "# def compute_heuristics(image, edge_map):\n",
        "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "#     gradient = sobel(gray)\n",
        "#     edge_density = np.mean(edge_map > 0.2)\n",
        "#     edge_gradient_alignment = np.mean(gradient[edge_map > 0.2])\n",
        "#     edge_entropy = -np.sum(edge_map * np.log2(edge_map + 1e-8))\n",
        "#     lin = linearity_score(edge_map)\n",
        "#     if edge_density < 0.01:\n",
        "#         return [0.0, 0.0, 0.0, 0.0]\n",
        "#     return [edge_density, edge_gradient_alignment, edge_entropy, lin]\n",
        "\n",
        "# def pseudo_labels(image, sf_edges, ued_edges):\n",
        "#     h_sf  = compute_heuristics(image, sf_edges)\n",
        "#     h_ued = compute_heuristics(image, ued_edges)\n",
        "#     # if UED better alignment & lower entropy, choose UED\n",
        "#     if h_ued[1] > h_sf[1] and h_ued[2] < h_sf[2]:\n",
        "#         return 0\n",
        "#     else:\n",
        "#         return 1\n",
        "\n",
        "# # PyTorch gating network (input_dim=8 for 4 heuristics each)\n",
        "# class GatingNet(nn.Module):\n",
        "#     def __init__(self, input_dim=8, hidden=16):\n",
        "#         super().__init__()\n",
        "#         self.net = nn.Sequential(\n",
        "#             nn.Linear(input_dim, hidden),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(hidden, 2)\n",
        "#         )\n",
        "#     def forward(self, x):\n",
        "#         return self.net(x)\n",
        "\n",
        "# # Train gating model in PyTorch\n",
        "# def train_gating_model_torch(images, sf_edge_maps, ued_edge_maps,\n",
        "#                              batch_size=64, epochs=10, lr=1e-3,\n",
        "#                              device='cuda'):\n",
        "#     # 1) Collect features & labels\n",
        "#     feats, labels = [], []\n",
        "#     for img, sf, ued in zip(images, sf_edge_maps, ued_edge_maps):\n",
        "#         segments = slic(img_as_float(img), n_segments=100, compactness=10)\n",
        "#         for seg_val in np.unique(segments):\n",
        "#             mask = (segments == seg_val)\n",
        "#             if mask.sum() < 50:\n",
        "#                 continue\n",
        "#             sf_patch, ued_patch = sf * mask, ued * mask\n",
        "#             if sf_patch.mean() + ued_patch.mean() < 0.01:\n",
        "#                 continue\n",
        "#             h_sf  = compute_heuristics(img, sf_patch)\n",
        "#             h_ued = compute_heuristics(img, ued_patch)\n",
        "#             feats.append(np.array(h_sf + h_ued, dtype=np.float32))\n",
        "#             labels.append(pseudo_labels(img, sf_patch, ued_patch))\n",
        "#     if len(set(labels)) < 2:\n",
        "#         return None, None, None\n",
        "\n",
        "#     # 2) Build tensors & standardize\n",
        "#     X = torch.tensor(feats)  # (N, 8)\n",
        "#     y = torch.tensor(labels, dtype=torch.long)  # (N,)\n",
        "#     mean, std = X.mean(dim=0, keepdim=True), X.std(dim=0, keepdim=True) + 1e-6\n",
        "#     X = (X - mean) / std\n",
        "\n",
        "#     # 3) DataLoader\n",
        "#     dataset = TensorDataset(X, y)\n",
        "#     loader  = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#     # 4) Model, loss, optimizer\n",
        "#     model = GatingNet(input_dim=X.shape[1]).to(device)\n",
        "#     optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "#     criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#     # 5) Training loop\n",
        "#     model.train()\n",
        "#     for epoch in range(epochs):\n",
        "#         total_loss = 0.0\n",
        "#         for xb, yb in loader:\n",
        "#             xb, yb = xb.to(device), yb.to(device)\n",
        "#             logits = model(xb)\n",
        "#             loss   = criterion(logits, yb)\n",
        "#             optimizer.zero_grad()\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "#             total_loss += loss.item()\n",
        "#         print(f\"Epoch {epoch+1}/{epochs} - loss: {total_loss/len(loader):.4f}\")\n",
        "\n",
        "#     return model, mean.to(device), std.to(device)\n",
        "\n",
        "# # Apply gating model to fuse edges\n",
        "# def apply_gating_model_torch(image, sf_edges, ued_edges,\n",
        "#                              model, mean, std, device='cuda'):\n",
        "#     segments = slic(img_as_float(image), n_segments=100, compactness=10)\n",
        "#     feats, masks = [], []\n",
        "#     for seg_val in np.unique(segments):\n",
        "#         mask = (segments == seg_val)\n",
        "#         if mask.sum() < 50:\n",
        "#             continue\n",
        "#         sf_patch, ued_patch = sf_edges * mask, ued_edges * mask\n",
        "#         if sf_patch.mean() + ued_patch.mean() < 0.01:\n",
        "#             continue\n",
        "#         h_sf, h_ued = compute_heuristics(image, sf_patch), compute_heuristics(image, ued_patch)\n",
        "#         f = np.array(h_sf + h_ued, dtype=np.float32)\n",
        "#         if not np.all(np.isfinite(f)) or np.allclose(f, 0, atol=1e-3):\n",
        "#             continue\n",
        "#         feats.append(f)\n",
        "#         masks.append(mask)\n",
        "\n",
        "#     if not feats:\n",
        "#         return np.zeros_like(sf_edges, dtype=float)\n",
        "\n",
        "#     X = torch.tensor(feats).to(device)\n",
        "#     X = (X - mean) / std\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         probs = torch.softmax(model(X), dim=1)[:,1].cpu().numpy()\n",
        "\n",
        "#     gated = np.zeros_like(sf_edges, dtype=float)\n",
        "#     for p, mask in zip(probs, masks):\n",
        "#         gated[mask] = p * sf_edges[mask] + (1 - p) * ued_edges[mask]\n",
        "#     return gated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c822d4e5",
      "metadata": {
        "id": "c822d4e5"
      },
      "outputs": [],
      "source": [
        "# def edge_detection(gray, factor=6, dilation=(3, 3)):\n",
        "#         # STEP 1: apply power threshold to suppress background\n",
        "#         median = np.median(gray)\n",
        "#         mad = np.median(np.abs(gray - median))\n",
        "#         power_mask = gray > (median + factor * mad)\n",
        "\n",
        "#         # STEP 2: edge detection on filtered signal only\n",
        "#         grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "#         grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "#         magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
        "#         magnitude *= power_mask  # mask out noise\n",
        "#         magnitude = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "#         # STEP 3: binary threshold + dilation\n",
        "#         binary = magnitude > 50  # you can tune this\n",
        "#         binary = scipy.ndimage.binary_dilation(binary, structure=np.ones(dilation))\n",
        "#         labeled, n_objs = scipy.ndimage.label(binary)\n",
        "#         slices = scipy.ndimage.find_objects(labeled)\n",
        "#         return slices\n",
        "\n",
        "# EDGE_MODEL_PATH = '/home/jliang/gbt-rfi/model.yml.gz'\n",
        "# EDGE_DETECTOR = cv2.ximgproc.createStructuredEdgeDetection(EDGE_MODEL_PATH)\n",
        "\n",
        "# def detect_edges(spectrogram):\n",
        "#     img = (spectrogram - spectrogram.min()) / (spectrogram.ptp() + 1e-6)\n",
        "#     img_3ch = cv2.merge([img.astype(np.float32)] * 3)\n",
        "#     return EDGE_DETECTOR.detectEdges(img_3ch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06fea6ff",
      "metadata": {
        "id": "06fea6ff"
      },
      "outputs": [],
      "source": [
        "# def extract_one_sample(h5_path, ch, edge_model_path='/home/jliang/gbt-rfi/model.yml.gz'):\n",
        "#     try:\n",
        "#         EDGE_DETECTOR = cv2.ximgproc.createStructuredEdgeDetection(edge_model_path)\n",
        "#         fb = bl.Waterfall(h5_path, load_data=True)\n",
        "#         data = 10 * np.log10(fb.data.squeeze())\n",
        "\n",
        "#         nfpc = fb.header.get(\"nfpc\", 1024)\n",
        "#         f0, f1 = ch * nfpc, (ch + 1) * nfpc\n",
        "#         block = data[:, f0:f1]\n",
        "\n",
        "#         n_cols = block.shape[1]\n",
        "#         low, high = int(0.1 * n_cols), int(0.9 * n_cols)\n",
        "#         block_middle80 = block[:, low:high]\n",
        "\n",
        "#         vert_means = block_middle80.mean(axis=0)\n",
        "#         center = np.argmax(vert_means)\n",
        "#         left_col, right_col = center - 1, center + 1\n",
        "#         if left_col >= 0 and right_col < block_middle80.shape[1]:\n",
        "#             block_middle80[:, center] = (block_middle80[:, left_col] + block_middle80[:, right_col]) / 2\n",
        "#         elif left_col >= 0:\n",
        "#             block_middle80[:, center] = block_middle80[:, left_col]\n",
        "#         elif right_col < block_middle80.shape[1]:\n",
        "#             block_middle80[:, center] = block_middle80[:, right_col]\n",
        "\n",
        "#         img_norm = (block_middle80 - block_middle80.min()) / (block_middle80.ptp() + 1e-6)\n",
        "#         img_rgb = cv2.merge([img_norm.astype(np.float32)] * 3)\n",
        "\n",
        "#         sf_edges = EDGE_DETECTOR.detectEdges(img_rgb)\n",
        "\n",
        "#         gray = (255 * img_norm).astype(np.uint8)\n",
        "#         grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "#         grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "#         magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
        "#         magnitude = cv2.normalize(magnitude, None, 0, 1, cv2.NORM_MINMAX)\n",
        "\n",
        "#         sf_mean = np.mean(sf_edges)\n",
        "#         ued_mean = np.mean(magnitude)\n",
        "\n",
        "#         if sf_mean + ued_mean < 0.005:  # threshold to skip empty or background-only blocks\n",
        "#             return None  # skip empty or background-only blocks\n",
        "\n",
        "\n",
        "#         return (img_rgb, sf_edges, magnitude)\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error processing {h5_path} ch {ch}: {e}\")\n",
        "#         return None\n",
        "\n",
        "# def extract_samples_batched(df, total_samples=40000, batch_size=32, num_workers=4):\n",
        "#     all_tasks = []\n",
        "#     for _, row in df.iterrows():\n",
        "#         h5 = row[\".h5 path\"]\n",
        "#         fb = bl.Waterfall(h5, load_data=False)\n",
        "#         nfreq = fb.header.get(\"nchans\")\n",
        "#         nfpc = fb.header.get(\"nfpc\", 1024)\n",
        "#         for ch in range(nfreq // nfpc):\n",
        "#             all_tasks.append((h5, ch))\n",
        "\n",
        "#     shuffle(all_tasks)\n",
        "#     selected_tasks = all_tasks[:total_samples]\n",
        "\n",
        "#     train_images, train_sf_edges, train_ued_edges = [], [], []\n",
        "#     for i in tqdm(range(0, total_samples, batch_size)):\n",
        "#         batch = selected_tasks[i:i+batch_size]\n",
        "#         with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
        "#             futures = [executor.submit(extract_one_sample, h5, ch) for h5, ch in batch]\n",
        "#             for future in as_completed(futures):\n",
        "#                 result = future.result()\n",
        "#                 if result:\n",
        "#                     img_rgb, sf_edge, ued_edge = result\n",
        "#                     train_images.append(img_rgb)\n",
        "#                     train_sf_edges.append(sf_edge)\n",
        "#                     train_ued_edges.append(ued_edge)\n",
        "\n",
        "#     return train_images, train_sf_edges, train_ued_edges\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50421249",
      "metadata": {
        "id": "50421249"
      },
      "outputs": [],
      "source": [
        "# # 4) SET UP LOGGING\n",
        "# logging.basicConfig(\n",
        "#     level=logging.INFO,\n",
        "#     format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "#     datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        "# )\n",
        "\n",
        "# from gating_model import train_gating_model_torch\n",
        "\n",
        "# def build_tasks(df):\n",
        "#     \"\"\"\n",
        "#     Build a flat list of (h5_path, channel_idx) from your DataFrame,\n",
        "#     skipping any channels that fall into known notch filter frequency ranges.\n",
        "#     \"\"\"\n",
        "#     GBT_NOTCH_FILTERS = {\n",
        "#         \"L\": [(1200, 1340)],\n",
        "#         \"S\": [(2300, 2360)],\n",
        "#     }\n",
        "\n",
        "#     tasks = []\n",
        "\n",
        "#     for _, row in df.iterrows():\n",
        "#         h5 = row[\".h5 path\"]\n",
        "#         band = row[\"Band\"]  # e.g., 'L', 'S', etc.\n",
        "#         fb = bl.Waterfall(h5, load_data=False)\n",
        "#         nfreq = fb.header.get(\"nchans\")\n",
        "#         nfpc = fb.header.get(\"nfpc\", 1024)\n",
        "#         fch1 = fb.header[\"fch1\"]\n",
        "#         foff = fb.header[\"foff\"]\n",
        "#         n_coarse = nfreq // nfpc\n",
        "\n",
        "#         for ch in range(n_coarse):\n",
        "#             f0 = fch1 + ch * nfpc * foff\n",
        "#             f1 = fch1 + (ch + 1) * nfpc * foff\n",
        "#             f_min, f_max = sorted([f0, f1])\n",
        "\n",
        "#             # Check against notch filter exclusion ranges\n",
        "#             skip = False\n",
        "#             if band in GBT_NOTCH_FILTERS:\n",
        "#                 for lo, hi in GBT_NOTCH_FILTERS[band]:\n",
        "#                     if lo <= f_min <= hi or lo <= f_max <= hi:\n",
        "#                         skip = True\n",
        "#                         break\n",
        "#             if not skip:\n",
        "#                 tasks.append((h5, ch))\n",
        "\n",
        "#     return tasks\n",
        "\n",
        "\n",
        "# def split_tasks(tasks, train_frac=0.8, seed=42):\n",
        "#     \"\"\"\n",
        "#     Shuffle & split the flat task list into train vs. val sets.\n",
        "#     Returns two sets of (h5_path, channel_idx).\n",
        "#     \"\"\"\n",
        "#     random.seed(seed)\n",
        "#     shuffled = tasks.copy()\n",
        "#     random.shuffle(shuffled)\n",
        "#     cut = int(train_frac * len(shuffled))\n",
        "#     train = set(shuffled[:cut])\n",
        "#     val   = set(shuffled[cut:])\n",
        "#     return train, val\n",
        "\n",
        "# def process_file(job):\n",
        "#     \"\"\"\n",
        "#     job is a tuple:\n",
        "#       (h5_path, channels, global_indices,\n",
        "#        base_dir, factor, dilation,\n",
        "#        class_id, train_set, val_set,\n",
        "#        pad_width, model, mean, std)\n",
        "#     \"\"\"\n",
        "#     (h5_path, channels, global_indices,\n",
        "#      base_dir, factor, dilation,\n",
        "#      class_id, train_set, val_set,\n",
        "#      pad_width, model, mean, std) = job\n",
        "\n",
        "#     # 1) Prepare device & trained gate\n",
        "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#     model = model.to(device)\n",
        "#     model.eval()\n",
        "\n",
        "#     # 2) Load Structured Forest detector once\n",
        "#     EDGE_MODEL_PATH = \"/home/jliang/gbt-rfi/model.yml.gz\"\n",
        "#     sf_detector = cv2.ximgproc.createStructuredEdgeDetection(EDGE_MODEL_PATH)\n",
        "\n",
        "#     # 3) Load the .h5 file\n",
        "#     fb   = bl.Waterfall(h5_path, load_data=True)\n",
        "#     data = 10 * np.log10(fb.data.squeeze())   # (ntime, nfreq)\n",
        "\n",
        "#     # 4) Process each coarse channel\n",
        "#     for ch_idx, gidx in zip(channels, global_indices):\n",
        "#         # decide train vs val\n",
        "#         subset = \"train\" if (h5_path, ch_idx) in train_set else \"val\"\n",
        "\n",
        "#         # make sure directories exist\n",
        "#         img_dir = Path(base_dir)/subset/\"images\"\n",
        "#         lbl_dir = Path(base_dir)/subset/\"labels\"\n",
        "#         vis_dir = Path(base_dir)/\"visualization\"/subset\n",
        "#         for d in (img_dir, lbl_dir, vis_dir):\n",
        "#             d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "#         # extract the 80% middle of the block\n",
        "#         cw = fb.header.get(\"nfpc\", 1024)\n",
        "#         f0, f1 = ch_idx*cw, (ch_idx+1)*cw\n",
        "#         block = data[:, f0:f1]\n",
        "#         low, high = int(0.1*cw), int(0.9*cw)\n",
        "#         block = block[:, low:high]\n",
        "\n",
        "#         # remove single‐column artifact\n",
        "#         col_means = block.mean(axis=0)\n",
        "#         c = int(np.argmax(col_means))\n",
        "#         if 0 < c < block.shape[1]-1:\n",
        "#             block[:,c] = 0.5*(block[:,c-1] + block[:,c+1])\n",
        "\n",
        "#         # normalize & build RGB input for SF\n",
        "#         norm = (block - block.min())/(block.ptp()+1e-6)\n",
        "#         img_rgb = cv2.merge([norm.astype(np.float32)]*3)\n",
        "\n",
        "#         # compute the two expert edge‐maps\n",
        "#         sf_edge_map  = sf_detector.detectEdges(img_rgb).squeeze()\n",
        "#         gray_uint8  = (255*norm).astype(np.uint8)\n",
        "#         gx = cv2.Sobel(gray_uint8, cv2.CV_32F, 1, 0, ksize=3)\n",
        "#         gy = cv2.Sobel(gray_uint8, cv2.CV_32F, 0, 1, ksize=3)\n",
        "#         ued_edge_map = np.hypot(gx, gy)\n",
        "#         ued_edge_map = cv2.normalize(ued_edge_map, None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
        "\n",
        "#         # 5) Fuse using the PyTorch gate\n",
        "#         fused_edges = apply_gating_model_torch(\n",
        "#             img_rgb, sf_edge_map, ued_edge_map,\n",
        "#             model, mean, std,\n",
        "#             device=device\n",
        "#         )\n",
        "\n",
        "#         # 6) Generate & save YOLO boxes\n",
        "#         boxes = generate_yolo_boxes(fused_edges, threshold=0.1)\n",
        "\n",
        "#         # Dimensions for filtering\n",
        "#         h_img, w_img = block.shape\n",
        "#         min_size = 3                   # px\n",
        "#         full_image_threshold = 0.95    # normalized area\n",
        "\n",
        "#         # Filter\n",
        "#         final_boxes = []\n",
        "#         for x_c, y_c, w_n, h_n, area in boxes:\n",
        "#             if area > full_image_threshold:\n",
        "#                 continue\n",
        "#             if (w_n * w_img) < min_size or (h_n * h_img) < min_size:\n",
        "#                 continue\n",
        "#             final_boxes.append((x_c, y_c, w_n, h_n))\n",
        "\n",
        "#         # Calculate frequency range of this coarse channel\n",
        "#         f_start = fb.header['fch1'] + f0 * fb.header['foff']\n",
        "#         f_stop  = fb.header['fch1'] + (f1 - 1) * fb.header['foff']\n",
        "\n",
        "#         # Build filename\n",
        "#         fn = f\"img_{gidx:0{pad_width}d}_f_{f_start:.4f}_{f_stop:.4f}.png\"\n",
        "#         img_path = img_dir / fn\n",
        "#         txt_path = lbl_dir / fn.replace(\".png\", \".txt\")\n",
        "\n",
        "#         # Save image\n",
        "#         arr8 = (255 * (block - block.min()) / (block.ptp() + 1e-6)).astype(np.uint8)\n",
        "#         img = Image.fromarray(np.stack([arr8]*3, axis=-1))\n",
        "#         img.save(img_path)\n",
        "\n",
        "#         # Write YOLO labels\n",
        "#         with open(txt_path, \"w\") as f:\n",
        "#             for x_c, y_c, w_n, h_n in final_boxes:\n",
        "#                 f.write(f\"{class_id} {x_c:.6f} {y_c:.6f} {w_n:.6f} {h_n:.6f}\\n\")\n",
        "\n",
        "#         # If empty, log it\n",
        "#         if not final_boxes:\n",
        "#             (lbl_dir/\"empty_labels.csv\").open(\"a\").write(f\"{fn},{h5_path},{ch_idx}\\n\")\n",
        "\n",
        "#         # Draw & save visualization\n",
        "#         vis_img = img.convert(\"RGB\")\n",
        "#         draw    = ImageDraw.Draw(vis_img)\n",
        "#         for x_c, y_c, w_n, h_n in final_boxes:\n",
        "#             xc, yc = x_c*w_img, y_c*h_img\n",
        "#             bw, bh = w_n*w_img, h_n*h_img\n",
        "#             x0, y0 = int(xc - bw/2), int(yc - bh/2)\n",
        "#             x1, y1 = int(xc + bw/2), int(yc + bh/2)\n",
        "#             draw.rectangle([x0, y0, x1, y1], outline=\"red\", width=2)\n",
        "#         vis_img.save(vis_dir/fn)\n",
        "\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     # === your settings ===\n",
        "#     BASE_DIR             = \"/datax/scratch/jliang/dataset_moe\"\n",
        "#     FACTOR              = 6\n",
        "#     DILATION = (30, 30)\n",
        "#     CLASS_ID             = 0\n",
        "#     TRAIN_FRAC           = 0.8\n",
        "#     SEED                 = 42\n",
        "#     NUM_WORKERS          = 2\n",
        "\n",
        "#     # --- assume you already have a DataFrame `df` with at least 'h5_path' and optionally 'nchans' ---\n",
        "#     # df = pd.read_csv(...)  # or however you built it\n",
        "\n",
        "#     # 1) Build & split tasks\n",
        "#     tasks = build_tasks(df)\n",
        "#     train_set, val_set = split_tasks(tasks, TRAIN_FRAC, SEED)\n",
        "\n",
        "#     # 2) compute zero-pad width from total images\n",
        "#     pad_width = len(str(len(tasks) - 1))\n",
        "\n",
        "#     # 3) regroup tasks by file to load each .h5 only once\n",
        "#     jobs = {}\n",
        "#     for gidx, (h5, ch) in enumerate(tasks):\n",
        "#         jobs.setdefault(h5, {\"chs\": [], \"gidxs\": []})\n",
        "#         jobs[h5][\"chs\"].append(ch)\n",
        "#         jobs[h5][\"gidxs\"].append(gidx)\n",
        "\n",
        "#     # 4) prepare job‐tuples\n",
        "#     job_list = []\n",
        "#     for h5, info in jobs.items():\n",
        "#         job_list.append((\n",
        "#             h5,\n",
        "#             info[\"chs\"],\n",
        "#             info[\"gidxs\"],\n",
        "#             BASE_DIR,\n",
        "#             FACTOR,\n",
        "#             DILATION,\n",
        "#             CLASS_ID,\n",
        "#             train_set,\n",
        "#             val_set,\n",
        "#             pad_width\n",
        "#         ))\n",
        "\n",
        "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#     # train_images, train_sf_edges, train_ued_edges = extract_samples_batched(\n",
        "#     #     df, total_samples=40000, num_workers=2\n",
        "#     # )\n",
        "\n",
        "#     # model, mean, std = train_gating_model_torch(\n",
        "#     #     train_images,\n",
        "#     #     train_sf_edges,\n",
        "#     #     train_ued_edges,\n",
        "#     #     batch_size=64,\n",
        "#     #     epochs=10,\n",
        "#     #     lr=1e-3,\n",
        "#     #     device=device\n",
        "#     # )\n",
        "\n",
        "#     # if model is None:\n",
        "#     #     logging.warning(\"Skipping inference because gate net couldn't train.\")\n",
        "#     #     exit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae743955",
      "metadata": {
        "id": "ae743955"
      },
      "outputs": [],
      "source": [
        "# import h5py, numpy as np, torch, logging\n",
        "# from torch.utils.data import IterableDataset, DataLoader\n",
        "# import cv2\n",
        "# from skimage.segmentation import slic\n",
        "# from yolo_moe_pytorch_channel import (\n",
        "#     apply_gating_model_torch,\n",
        "#     generate_yolo_boxes,\n",
        "#     compute_heuristics,\n",
        "#     pseudo_labels\n",
        "# )\n",
        "# from PIL import Image, ImageDraw\n",
        "\n",
        "# # 1) Streaming dataset\n",
        "# class H5ChannelDataset(IterableDataset):\n",
        "#     def __init__(self, df, nfpc=1024):\n",
        "#         self.paths = df[\".h5 path\"].tolist()\n",
        "#         self.nfpc  = nfpc\n",
        "#     def __iter__(self):\n",
        "#         for p in self.paths:\n",
        "#             with h5py.File(p, \"r\") as f:\n",
        "#                 d = f[\"data\"]\n",
        "#                 n_coarse = d.shape[1] // self.nfpc\n",
        "#                 for ch in range(n_coarse):\n",
        "#                     yield d[:, ch*self.nfpc:(ch+1)*self.nfpc].astype(np.float32)\n",
        "\n",
        "# # 2) Pre- and post-processing helpers\n",
        "# EDGE_MODEL_PATH = \"/home/jliang/gbt-rfi/model.yml.gz\"\n",
        "# sf_detector    = cv2.ximgproc.createStructuredEdgeDetection(EDGE_MODEL_PATH)\n",
        "\n",
        "# def preprocess(block):\n",
        "#     norm = (block - block.min())/(block.ptp()+1e-6)\n",
        "#     img_rgb = np.stack([norm]*3, axis=-1).astype(np.float32)\n",
        "#     sf_map   = sf_detector.detectEdges(img_rgb).squeeze()\n",
        "#     gray8    = (255*norm).astype(np.uint8)\n",
        "#     gx = cv2.Sobel(gray8, cv2.CV_32F, 1,0,3)\n",
        "#     gy = cv2.Sobel(gray8, cv2.CV_32F, 0,1,3)\n",
        "#     ued_map = np.hypot(gx, gy)\n",
        "#     ued_map = cv2.normalize(ued_map, None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
        "#     return img_rgb, sf_map, ued_map\n",
        "\n",
        "# def segment_patches(img, sf, ued):\n",
        "#     segs = slic(img, n_segments=100, compactness=10)\n",
        "#     for v in np.unique(segs):\n",
        "#         m = segs==v\n",
        "#         if m.sum()<50: continue\n",
        "#         sf_p, ued_p = sf*m, ued*m\n",
        "#         if sf_p.mean()+ued_p.mean()<0.01: continue\n",
        "#         yield sf_p, ued_p\n",
        "\n",
        "# # 3) Collate: build feature / label tensors\n",
        "# def collate_fn(batch):\n",
        "#     feats, labs = [], []\n",
        "#     for block in batch:\n",
        "#         img, sf, ued = preprocess(block)\n",
        "#         for sf_p, ued_p in segment_patches(img, sf, ued):\n",
        "#             h_sf = compute_heuristics(sf_p, img)\n",
        "#             h_ued= compute_heuristics(ued_p, img)\n",
        "#             feats.append(h_sf + h_ued)\n",
        "#             labs.append(pseudo_labels(img, sf_p, ued_p))\n",
        "#     if not feats: return None\n",
        "#     return torch.tensor(feats), torch.tensor(labs)\n",
        "\n",
        "# # 4) Training\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# dataset = H5ChannelDataset(df)\n",
        "# loader  = DataLoader(dataset,\n",
        "#                      batch_size=4,\n",
        "#                      num_workers=4,\n",
        "#                      persistent_workers=True,\n",
        "#                      collate_fn=collate_fn)\n",
        "\n",
        "# from your_module import GatingNet  # the BatchNorm version\n",
        "# net   = GatingNet().to(device)\n",
        "# opt   = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
        "# crit  = nn.CrossEntropyLoss()\n",
        "\n",
        "# for epoch in range(10):\n",
        "#     for batch in loader:\n",
        "#         if batch is None: continue\n",
        "#         X, y = batch\n",
        "#         X, y = X.to(device), y.to(device)\n",
        "#         logits = net(X)\n",
        "#         loss   = crit(logits, y)\n",
        "#         opt.zero_grad()\n",
        "#         loss.backward()\n",
        "#         opt.step()\n",
        "#     print(f\"Epoch {epoch+1}/10 done\")\n",
        "\n",
        "# # 5) Build job_list as before, but append (net) instead of (mean,std)\n",
        "# # and in process_file call apply_gating_model_torch(img, sf, ued, net, device=...)\n",
        "\n",
        "# # 6) Inference uses your existing process_file, no further change needed.\n",
        "\n",
        "\n",
        "# # ─── 3) Build job list for inference ────────────────────────────────────\n",
        "\n",
        "# # your existing build_tasks(), split_tasks(), jobs grouping...\n",
        "# tasks    = build_tasks(df)\n",
        "# train_set, val_set = split_tasks(tasks, TRAIN_FRAC, SEED)\n",
        "# pad_width = len(str(len(tasks)))\n",
        "\n",
        "# jobs = {}\n",
        "# for gidx,(h5,ch) in enumerate(tasks):\n",
        "#     jobs.setdefault(h5, {\"chs\":[], \"gidxs\":[]})\n",
        "#     jobs[h5][\"chs\"].append(ch)\n",
        "#     jobs[h5][\"gidxs\"].append(gidx)\n",
        "\n",
        "# job_list = []\n",
        "# for h5,info in jobs.items():\n",
        "#     job_list.append((h5,\n",
        "#                      info[\"chs\"],\n",
        "#                      info[\"gidxs\"],\n",
        "#                      BASE_DIR,\n",
        "#                      FACTOR,\n",
        "#                      DILATION,\n",
        "#                      CLASS_ID,\n",
        "#                      train_set,\n",
        "#                      val_set,\n",
        "#                      pad_width,\n",
        "#                      gate_net, mean, std))\n",
        "\n",
        "# # ─── 4) Run inference in parallel ───────────────────────────────────────\n",
        "# from concurrent.futures import ProcessPoolExecutor\n",
        "\n",
        "# with ProcessPoolExecutor(max_workers=NUM_WORKERS) as exe:\n",
        "#     for _ in exe.map(process_file, job_list):\n",
        "#         pass\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
